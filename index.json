[{"categories":["Art of Labbing"],"content":" Intro Cisco IOL, aka IOU, and I go back a long way. Back in the day, when I decided to sit for the CCIE R\u0026S v4 exam, there weren‚Äôt many options to get hands on on the cli other than having access to real devices or using dynamips and GNS3 for simulating routers and switches, but with limited feature support, especially on the S side. Hence, since I have also been known as a big time pack rat, I decided to go for a real LAB. So, after spending nearly over $6k, I managed to build a real home lab with all the quirks. Terminal server, AUI converters , x-over and serial cables, remote managed PSUs, I remember being so happy! The joy went on for a couple of months, while I was setting up the scenarios, practicing the theory, re-configuring and starting over. Then one day, as I was googling for something, I bumped to some news that Cisco IOS-on-Unix has been leaked to the public and people were already using it to build virtual labs. Then an IOS-on-Linux version was also leaked and you can imagine how stupid I felt after this. I, of course, ended up in using it and even got a refurb SPARCstation to run IOU in the interim before I could get my hands on a stable IOL version without major issues. Anyway, this was just to give you the context of my history with IOL. I never sat for the lab in the end, but that‚Äôs another story. So, imagine my excitement when the recent news of IOL support in containerlab and netlab reached my eyes. It brought back so many reminisces, that I had to write something about it. Containerlab and netlab have always been in my back-blog, and I wanted to post about them, but I feel that the community is doing such a great job on them, whilst in this case I felt that the time is right for me as well. As a bottom line here, IOL has always been the preferred choice due to its low demand on resources for the supported and relevant use cases, and the fact that it can now be supported in containerised topologies increases its network automation friendliness (NAFness :)) level, not too much though, since it is lacking some features as we will see later on. Use Case Brief Everything starts with a use case, the intent! In my case, I want to spin up topologies and test different things in Kentik. The idea came from the srl-telemetry-lab, so we will be following the same approach but for Kentik related use cases. Hence, Dynamic topology that is sending netflow to Kentik via the kproxy agent Traffic simulation using iperf3 on the devices Kentik Synthetic agents attached to the topology performing tests Devices registered in Kentik NMS for monitoring Why containerlab? Dynamic topology: support CRUDs on the infrastructure IaC model support: everything defined in structured format Integrates well with netlab as a provider Minimal effort on the above / more focus on the use cases Why netlab? Automatic provisioning of underlay connectivity details and protocols Flexibility in adding custom templates and using custom playbooks based on a common ansible inventory file Good integration with containerlab Minimal effort on the above / more focus on the use cases I think netlab is the perfect example of Automating the Boring Stuff. I never counted the times or will ever forget that I had to type those commands üòÑ : Boring Stuff conf t ‚èé no ip do lo ‚èé line con 0 ‚èé logg syn ‚èé exec-t 0 ‚èé ^Z wr ‚èé Why IOL? Demand on resources is very low Fit my use case since netflow export is supported No licensing limits on traffic volumes Seems IOL reports interface errors when traffic is pushed. A bug or a feature, don‚Äôt care at the moment since it has always been a burden to fire up synthetic errors on interface counters. Things Covered Now that we have picked up the correct tools for the job, let‚Äôs see what we are going to cover so you can assess if this is still interesting enough to carry on reading. Using netlab to provision a lab by using containerlab for spinning up the nodes Using IOL for the network device type Using various containers to integr","date":"2024-11-05","objectID":"/posts/iou-love/:0:0","tags":["netsim","netlab","containerlab","automation"],"title":"For those about to LAB...‚ö°","uri":"/posts/iou-love/"},{"categories":["network monitoring"],"content":" Intro In this post we will go through a detailed how to on executing Ansible playbooks triggered by a webhook notification event raised in Kentik Portal. The use case is to have visibility into BGP Flowspec metrics of the devices during mitigations and see the relevant counters in the Portal under Kentik‚Äôs NMS Metrics Explorer. You may find all relevant files in my repo. The Intent For the webhook receiver part, we are going to use Kentik‚Äôs ansible_eda collection that will listen for a mitigation notification event. Once the event is received and a mitigation is started, EDA will trigger the execution of a playbook to handle the event and spin-up Telegraf in order to start polling the devices for BGP Flowspec streaming telemetry counters while reporting them back to the Portal in influx line format via HTTPS. Once the mitigation is over and EDA receives the respective cease notification, a check for any active mitigations on the devices is done via Kentik‚Äôs API and if there are no active mitigations on the devices, EDA will trigger Telegraf to stop. If there are still on-going mitigations, Telegraf will continue to poll and ship metrics till we receive the last mitigation‚Äôs notification. Lab Setup Here is how the lab has been set-up for this: Two Cisco IOS XRv 9000 devices defined in the portal with established BGP sessions and Flowspec family enabled. GRPC is configured and enabled on the devices. A mitigation Platform defined in the Portal that includes both devices, and two mitigation methods attached. One will block ICMP echo-requests and the other will Rate Limit SSH protocol A notification channel of type JSON defined in the portal and attached to both mitigation methods Note I chose not to use any Alerting Policies with this and trigger all mitigations manually in order to speed things up An Ubuntu VM (jammy) with docker installed EDA will run inside a docker container with Traefik proxying the webhook events Once an actionable event is received, EDA will control a Telegraf docker container accordingly through a playbook Discovery We will start by exploring what we see on the devices during a running flowspec mitigation. We have triggered two manual mitigations in the Portal and those are currently active on the devices: RP/0/RP0/CPU0:ATH-POP1-XRV1#show flowspec afi-all detail AFI: IPv4 Flow :Dest:10.10.10.11/32,ICMPType:=8 Actions :Traffic-rate: 0 bps (bgp.1) Flow :Source:10.10.10.12/32,Proto:=6,DPort:=22 Actions :Traffic-rate: 160000 bps (bgp.1) XRv9k limitations Unfortunatelly the XRv has a limited data plane, so we do not get any action counters on the mitigations - this and also no netflow out of this virtual device üò¢. In case of a real XR device the output would be similar to this: REAL-XR#show flowspec afi-all detail AFI: IPv4 Flow :Dest:10.10.10.11/32,ICMPType:=8 Actions :Traffic-rate: 0 bps (bgp.1) Statisctics (packets/bytes) Matched : 10/640 Dropped : 10/640 So we have two mitigations as expected. Let‚Äôs find out which YANG model those are defined under. After trying some show commands for the xpath, there it is: RP/0/RP0/CPU0:ATH-POP1-XRV1#schema-describe \"show flowspec afi-all detail\" Action: get Path: RootCfg.ASNFormat Action: get_children Path: RootOper.FlowSpec.VRF({'VRFName': 'default'}).AF Action: get Path: RootOper.FlowSpec.VRF({'VRFName': 'default'}).AF({'AFName': 'IPv4'}).Flow RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath \"show flowspec afi-all detail\" Error: Invalid input RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath \"show flowspec afi-all\" Error: Invalid input RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath \"show flowspec summary\" Cisco-IOS-XR-flowspec-oper:flow-spec/summary RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal json Cisco-IOS-XR-flowspec-oper:flow-spec | include path \"encoding_path\": \"Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow\", \"encoding_path\": \"Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/nlris/nlri\", \"encoding_path\": \"","date":"2024-06-01","objectID":"/posts/modern-nms/:0:0","tags":["network monitoring","telemetry","ansible","automation"],"title":"If this ain't a modern NMS, then what is?","uri":"/posts/modern-nms/"},{"categories":["network monitoring"],"content":" Intro Since the launch of Kentik NMS, it it is possible to ingest and display custom metrics in the Portal. In this post we will be going over a walkthrough of how we can enable Kentik‚Äôs Universal Agent to poll custom SNMP and Streaming Telemetry metrics from devices and report them back to the Portal. The use case is about having visibility into BGP Flowspec counters to see what our mitigations are reporting on the devices. We are going to address this through SNMP as well as ST for both Junos and IOS-XR devices. For Junos, the flowspec rules are translated into firewall filters which have counters and policers depending on the action. We have two possible ways to extract those, either via SNMP or via streaming telemetry and we are going to use both. For IOS-XR, on the other-hand, there are no SNMP flowspec related OIDs, but there is a dedicated flowspec YANG model we can use to extract the counters via streaming telemetry. The various tools and device versions used throughout the use case are listed below: Kentik kagent docker container snmpwalk and snmptable gnmic Junos vMX on 21.3R1.9 Cisco IOS-XRv 9000 on 7.9.1 You may find all relevant files in my repo. Kentik Universal Agent (kagent) In order to use the custom metrics feature on the kagent we need some local configuration to be picked up by the agent on startup so it can be processed. In summary, we need three configuration files to exist localy in a specific directory structure that we can call the override directory. Below is the structure along with a brief explanation on the purpose of each one. /opt/kentik/components/ranger/local/ ‚îî‚îÄ‚îÄ config ‚îú‚îÄ‚îÄ profiles # Holds the configuration yaml files for 'binding' the sources to specific 'device' types ‚îú‚îÄ‚îÄ reports # Holds the configuration yaml files for 'how' we want to report what is collected from the sources in the portal ‚îî‚îÄ‚îÄ sources # Holds the configuration yaml files for 'what' we want to poll from the deviceSo once kagent starts it looks for the local folder and it processes those files in the structure. For example, if we want to poll an SNMP OID for a device, we would need to create a configuration file under the sources directory specifying which OID to poll and how often. Then we need to bind this source to only get polled if say the device is of a specific sysObjectID, and we do that in the profiles directory. Lastly, in the reports directory we define the path to present the data in the portal, how the data is represented and polled from the MIB, i.e. metrics or dimensions, and how often to update the values in the database. Additionally, in the reports directory we can use starlark scripts to add additional logic to our reporting capabilities. Kagent container We are going to be running our kagent instance as a container through compose. Here is how our directory structure looks like: /opt/dev/kentik/ ‚îú‚îÄ‚îÄ docker-compose.yml # How to bring up the container ‚îú‚îÄ‚îÄ kagent-data # Local dir mount so kagent data persists -\u003e /opt/kentik in the container ‚îî‚îÄ‚îÄ override-data # Local overrides directory with custom definitions -\u003e /opt/kentik/components/ranger/local in the container ‚îî‚îÄ‚îÄ config ‚îú‚îÄ‚îÄ profiles ‚îú‚îÄ‚îÄ reports ‚îî‚îÄ‚îÄ sourcesAnd here is the docker compose file: --- services: kagent: hostname: kagent03 image: kentik/kagent:latest restart: unless-stopped pull_policy: always cap_add: - NET_RAW environment: - K_COMPANY_ID=\u003cREDACTED\u003e - K_API_ROOT=grpc.api.kentik.eu:443 #- K_LOG_LEVEL=debug volumes: - /opt/dev/kentik/kagent-data:/opt/kentik - /opt/dev/kentik/override-data:/opt/kentik/components/ranger/local/ Junos Firewall Filters In Junos the flowspec rules create relevant ad-hoc firewall filters and policers that are applied to the linecards and can be examined via the show firewall detail command. Here is what we get with nothing configured: netops@ATH-POP1-VMX1\u003e show configuration firewall netops@ATH-POP1-VMX1\u003e show firewall detail Filter: __default_bpdu_filter__And here is what we get if we configure a filter to count SSH","date":"2024-05-04","objectID":"/posts/kustom-metrics/:0:0","tags":["network","monitoring","telemetry","snmp"],"title":"K~ustom Metrics in Kentik NMS","uri":"/posts/kustom-metrics/"},{"categories":["telemetry"],"content":"One of the mostly raised questions when you start leveraging MDT is which YANG model and xpath to use to configure the subscription on the device. Up to now, there was little to none help from the box itself, and a lot of searching and experimentation on the models was needed. Apparently this has changed now, and there are two sets of commands that will help in your quest. Let‚Äôs jump on DevNet‚Äôs always-on XRv9000 sandbox and issue some commands. $ ssh admin@sandbox-iosxr-1.cisco.com Password: RP/0/RP0/CPU0:ansible-iosxr# RP/0/RP0/CPU0:ansible-iosxr#show version Sun Jul 10 22:02:49.475 UTC Cisco IOS XR Software, Version 7.3.2 Copyright (c) 2013-2021 by Cisco Systems, Inc. Build Information: Built By : ingunawa Built On : Wed Oct 13 20:00:36 PDT 2021 Built Host : iox-ucs-017 Workspace : /auto/srcarchive17/prod/7.3.2/xrv9k/ws Version : 7.3.2 Location : /opt/cisco/XR/packages/ Label : 7.3.2-0 cisco IOS-XRv 9000 () processor System uptime is 2 weeks 5 days 10 hours 35 minutesLet‚Äôs say we want to find out which model and xpath will give us the sensors for show interfaces. There was the old command schema-describe, but now there is a new kid in town called show telemetry internal that does the trick. RP/0/RP0/CPU0:ansible-iosxr#schema-describe \"show interfaces\" Sun Jul 10 22:09:54.304 UTC Action: get Path: RootOper.Interfaces.Interface RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal xpath \"show interfaces\" Sun Jul 10 22:11:04.759 UTC Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interfaceSo now, we‚Äôve got the model and xpath, let‚Äôs see what will be streamed for just the Bundle interfaces RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal json Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface[interface-name='Bundle-*'] Sun Jul 10 22:24:38.169 UTC { \"encoding_path\": \"Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface\", \"subscription_id_str\": \"app_TEST_200000001\", \"collection_start_time\": \"1657491878258\", \"msg_timestamp\": \"1657491878577\", \"collection_end_time\": \"1657491878577\", \"node_id_str\": \"ansible-iosxr\", \"data_json\": [ { \"keys\": [ { \"interface-name\": \"Bundle-Ether10\" } ], \"timestamp\": \"1657491878321\", \"content\": { \"bandwidth64-bit\": \"0\", \"data-rates\": { \"peak-output-data-rate\": \"0\", \"input-load\": 0, \"input-packet-rate\": \"0\", \"output-data-rate\": \"0\", \"peak-input-packet-rate\": \"0\", \"bandwidth\": \"0\", \"load-interval\": 9, \"output-packet-rate\": \"0\", \"input-data-rate\": \"0\", \"peak-output-packet-rate\": \"0\", \"reliability\": 255, \"peak-input-data-rate\": \"0\", \"output-load\": 0 }, \"interface-type\": \"IFT_ETHERBUNDLE\", \"bandwidth\": 0, \"fast-shutdown\": false, \"is-intf-logical\": true, \"speed\": 0, \"interface-type-information\": { \"bundle-information\": {}, \"interface-type-info\": \"bundle\" }, \"loopback-configuration\": \"no-loopback\", \"state-transition-count\": 0, \"last-state-transition-time\": \"0\", \"interface-handle\": \"Bundle-Ether10\", \"is-dampening-enabled\": false, \"state\": \"im-state-down\", \"mac-address\": { \"address\": \"00:08:20:78:ff:1d\" }, \"hardware-type-string\": \"Aggregated Ethernet interface(s)\", \"is-l2-looped\": false, \"line-state\": \"im-state-down\", \"encapsulation\": \"ether\", \"encapsulation-type-string\": \"ARPA\", \"is-l2-transport-enabled\": true, \"duplexity\": \"im-attr-duplex-full\", \"mtu\": 1514, \"max-bandwidth64-bit\": \"0\", \"if-index\": 28, \"max-bandwidth\": 0 } } ], \"collection_id\": \"54\" },Or, by using the old method: RP/0/RP0/CPU0:ansible-iosxr#run mdt_exec -s Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface[interface-name='Bundle-*'] Sun Jul 10 22:26:48.133 UTC Enter any key to exit... Sub_id 200000001, flag 0, len 0 Sub_id 200000001, flag 4, len 1440 -------- {\"node_id_str\":\"ansible-iosxr\",\"subscription_id_str\":\"app_TEST_200000001\", \"encoding_path\":\"Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface\", \"collection_id\":\"55\",\"collection_start_time\":\"1657492008249\",\"msg_timestamp\":\"1657492008548\", \"data_json\":[{\"timestamp\":\"1657492008306\",\"keys\":[{\"interface-name\":\"Bundle-Ether10\"}], \"content\":{\"int","date":"2022-07-11","objectID":"/posts/xr-get-xpath/:0:0","tags":["ios-xr","telemetry"],"title":"IOS-XR :: Get Your XPATHs, Get Your XPATHs Honey","uri":"/posts/xr-get-xpath/"},{"categories":["ansible"],"content":"Intro Throughout this post, I am documenting my ansible orientation and ramping-up process towards automating the provisioning of a k8s cluster on ubuntu linux. I believe it is not something too fancy or something that has not been visited over and over again in various other posts, but this is the scrub of my exposure with ansible automation. I tried to make it modular with several playbook imports and task includes executed from a parent playbook file, rather than having a single long playbook. Ansible roles are not leveraged üòÅ. The code for this project can be found here. The Intent Let‚Äôs begin by setting the in-scope items for the project: Ubuntu 20.04 VMs based on cloud images provisioned with a known username/passwd and assigned DHCP IPv4 addresses. (Setting up the VMs reference) Kubernetes single node cluster version 1.22 Docker CRI Flannel CNI Single playbook which calls subsequent playbooks and task lists at runtime Kubeadm for cluster setup Playbook Overview The following mindmap diagram represents the automation tasks flows. Red lines represent imported playbook files. Green lines are included task lists files, and blue lines are the actual tasks to be executed. k8s Ansible Playbook Flow In short, we start from a single playbook file called start.yml and we have broken down our flow in three phases. The init phase covers Steps 01 and 02, and refer to assigning static IPs to our dynamic VMs. Step 01 is about building the mapping from DHCP to Static IPs of our nodes and generating the relevant netplan configuration files using a jinja2 template. Step 02 covers the application of these configuration files to the VMs. Next, is the pre-deployment phase, or Step 03, which is about preparing the VMs for k8s deployment, i.e. setting hostnames, establishing SSH key authentication with ansible, upgrading, etc. The final phase is the deployment one, where we call our tasks to deploy the k8s cluster upon the relevant control and worker nodes. The check phase, although not depicted in the flow, is a very important one during which we do our environment pre-checks in order for the playbook to be executed successfully, i.e. are all hosts declared properly in the ansible hosts file, are all variables declared as they should be,etc. Let‚Äôs expand on the directory structure in order to make things more explicit. Directory Layout Here is how the tree of our ansible playbook home directory looks like: . ‚îú‚îÄ‚îÄ .secrets -------------------\u003c Custom directory to hold sensitive data ‚îÇ¬†‚îú‚îÄ‚îÄ passwd.yml -------------\u003c Encrypted secrets file ‚îÇ¬†‚îî‚îÄ‚îÄ vault_passwd -----------\u003c Ansible-vault clear text password ‚îú‚îÄ‚îÄ ansible.cfg ----------------\u003c ansible configuration file ‚îú‚îÄ‚îÄ checks.yml -----------------\u003c \"Pre-checks\" playbook - Step 00 ‚îú‚îÄ‚îÄ configs --------------------\u003c Directory to store generated static ip netplan files ‚îú‚îÄ‚îÄ deployment.yml -------------\u003c \"Deploy\" phase playbook - Step 04 ‚îú‚îÄ‚îÄ hosts ----------------------\u003c ansible inventory file in ini format ‚îú‚îÄ‚îÄ init_play.yml --------------\u003c \"Init\" phase playbook - Step 01 ‚îú‚îÄ‚îÄ pre_deploy.yml -------------\u003c \"Pre-deploy\" phase playbook - Step 03 ‚îú‚îÄ‚îÄ start.yml ---------------\u003e\u003e\u003e\u003e \"Master\" playbook ‚îú‚îÄ‚îÄ tasks ----------------------\u003c Folder to hold all task lists files arranged per phase ‚îÇ¬†‚îú‚îÄ‚îÄ deploy ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ boot_control.yml ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ cni.yml ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ cri.yml ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ packages_general.yml ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ packages_kube.yml ‚îÇ¬†‚îÇ¬†‚îú‚îÄ‚îÄ swap.yml ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ workers.yml ‚îÇ¬†‚îú‚îÄ‚îÄ init ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ apply_netplan.yml --\u003c Step 02 playbook ‚îÇ¬†‚îî‚îÄ‚îÄ pre ‚îÇ¬†‚îú‚îÄ‚îÄ cloud-init.yml ‚îÇ¬†‚îú‚îÄ‚îÄ hostname.yml ‚îÇ¬†‚îú‚îÄ‚îÄ hosts.yml ‚îÇ¬†‚îú‚îÄ‚îÄ reboot.yml ‚îÇ¬†‚îú‚îÄ‚îÄ sshkeys.yml ‚îÇ¬†‚îú‚îÄ‚îÄ sudo.yml ‚îÇ¬†‚îî‚îÄ‚îÄ upgrade.yml ‚îú‚îÄ‚îÄ templates ------------------\u003c Templates default folder ‚îÇ¬†‚îî‚îÄ‚îÄ netplan.j2 ‚îî‚îÄ‚îÄ vars -----------------------\u003c Custom directory to host variables ‚îî‚îÄ‚îÄ netplan.ymlBelow is the ansible configuration file where we define which file contains the inventory. We instruct ansible not complain if the SSH target hosts are not known. For facts gathering, we only need the network facts and not","date":"2022-07-06","objectID":"/posts/k8s-ansible/:0:0","tags":["k8s","ansible","automation"],"title":"k8s Ansible","uri":"/posts/k8s-ansible/"},{"categories":["Linux"],"content":"There has been a need sometimes that you are on a system that is not permanently set to use a proxy server for internet access and you just want to give one or two curl or wget commands to fetch some files, or vice versa üòÑ. In order to avoid exporting the appropriate environment variables in the correct place, you can use the following two methods to enable or disable ad-hoc usage of the proxy server in linux bash. Method One - as an executable preceding your actual command Just put the following commands in a bash script, make it executable and put it in your path somewhere on the system. becos@fossa:~$ cat proxy #!/bin/bash -eu ########### ## Adjust to your environment ## HTTP_PROXY=\"http://10.10.10.10:8080\" HTTPS_PROXY=\"http://10.10.10.10:8080\" NO_PROXY=\"localhost,127.0.0.1,$(hostname -i),.domain.com\" ########### http_proxy=\"$HTTP_PROXY\" https_proxy=\"$HTTPS_PROXY\" no_proxy=\"$NO_PROXY\" export HTTP_PROXY HTTPS_PROXY NO_PROXY http_proxy https_proxy no_proxy exec \"$@\" becos@fossa:~$ chmod +x proxy \u0026\u0026 sudo mv !$ /usr/local/bin/ chmod +x proxy \u0026\u0026 sudo mv proxy /usr/local/bin/Now you can precede the proxy command just before calling your command that needs the proxy environment variables. becos@fossa:~$ proxy curl -sv http://www.google.com \u003e /dev/null * Uses proxy env variable no_proxy == 'localhost,127.0.0.1,192.168.1.5,.domain.com' * Uses proxy env variable http_proxy == 'http://10.10.10.10:8080' * Trying 10.10.10.10:8080... * TCP_NODELAY set ^C becos@fossa:~$Method Two - as functions to the user profile You can add these two functions in say your .profile function proxyoff { unset http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY } function proxyon { http_proxy=\"http://10.10.10.10:8080\" HTTP_PROXY=\"$http_proxy\" https_proxy=\"http://10.10.10.10:8080\" HTTPS_PROXY=\"$http_proxy\" no_proxy=\"localhost,127.0.0.1,$(hostname -i),.domain.com\" NO_PROXY=\"$no_proxy\" export http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY }So, after a new shell, you can use the on and off functions according to your intent. becos@fossa:~$ env | grep -i proxy becos@fossa:~$ proxyon becos@fossa:~$ env | grep -i proxy no_proxy=localhost,127.0.0.1,192.168.1.5,.domain.com https_proxy=http://10.10.10.10:8080 NO_PROXY=localhost,127.0.0.1,192.168.1.5,.domain.com HTTPS_PROXY=http://10.10.10.10:8080 HTTP_PROXY=http://10.10.10.10:8080 http_proxy=http://10.10.10.10:8080 becos@fossa:~$ proxyoff becos@fossa:~$ env | grep -i proxyThat‚Äôs it, I hope it finds a use case. ...till next time...have fun! ","date":"2022-06-14","objectID":"/posts/proxy-or-not/:0:0","tags":["bash"],"title":"Proxy or not...here I come...","uri":"/posts/proxy-or-not/"},{"categories":["Art of Labbing"],"content":" Intro Part One - Setting up the k8s VMs in EVE-NG Part Two - Deploying the k8s cluster with kubeadm Last Part - Installing and testing KNE The Intent Install Google‚Äôs KNE on the k8s control node Use KNE to create sample topologies Test with Nokia srlinux Test with Arista cEOS The time has come to install Google‚Äôs KNE!!!. We are going to use the k8s control node for KNEs ‚Äúcontrol‚Äù server, so everything will be installed on it. Prepare for KNE installation We need go so we are going to install it. # Download go ubuntu@kates-control:~$ wget -q https://go.dev/dl/go1.18.2.linux-amd64.tar.gz # Install it under our HOME directory ubuntu@kates-control:~$ tar -xvzf go1.18.2.linux-amd64.tar.gz # Put it in your PATH ubuntu@kates-control:~$ export PATH=$PATH:~/go/bin ubuntu@kates-control:~$ echo !! \u003e\u003e ~/.profile echo export PATH=$PATH:~/go/bin \u003e\u003e ~/.profile # Check if it's working ubuntu@kates-control:~$ go version go version go1.18.2 linux/amd64 Deploy KNE Use of kind KNE requires kind if you are going to use it in a single node. KNE can also deploy a single node k8s using kind and have it run inside a container. Then all the labs will be deployed into this containerised k8s node. OK! We are now ready to install KNE. There are two ways, either install it via go $ go install github.com/google/kne/kne_cli@latestor, clone the repo from github and build it locally, which is what I did. ubuntu@kates-control:~$ git clone https://github.com/google/kne.git Cloning into 'kne'... remote: Enumerating objects: 2146, done. remote: Counting objects: 100% (154/154), done. remote: Compressing objects: 100% (89/89), done. remote: Total 2146 (delta 66), reused 145 (delta 62), pack-reused 1992 Receiving objects: 100% (2146/2146), 41.28 MiB | 200.00 KiB/s, done. Resolving deltas: 100% (1052/1052), done. ubuntu@kates-control:~$ ubuntu@kates-control:~$ cd kne/kne_cli/ ubuntu@kates-control:~/kne/kne_cli$ GOPATH=~/go go install ubuntu@kates-control:~/kne/kne_cli$ cd ubuntu@kates-control:~$ kne_cli Kubernetes Network Emulation CLI. Works with meshnet to create layer 2 topology used by containers to layout networks in a k8s environment. Usage: kne_cli [command] Available Commands: completion Generate the autocompletion script for the specified shell create Create Topology delete Delete Topology deploy Deploy cluster. help Help about any command show Show Topology topology Topology commands. Flags: -h, --help help for kne_cli --kubecfg string kubeconfig file (default \"/home/ubuntu/.kube/config\") -v, --verbosity string log level (default \"info\") Use \"kne_cli [command] --help\" for more information about a command. ubuntu@kates-control:~$ Prepare k8s cluster for KNE We need to install meshnet CNI. # Install meshnet from local manifests ubuntu@kates-control:~$ kubectl apply -k kne/manifests/meshnet/base/ namespace/meshnet created customresourcedefinition.apiextensions.k8s.io/topologies.networkop.co.uk created serviceaccount/meshnet created clusterrole.rbac.authorization.k8s.io/meshnet-clusterrole created clusterrolebinding.rbac.authorization.k8s.io/meshnet-clusterrolebinding created daemonset.apps/meshnet created # Check for any issues ubuntu@kates-control:~$ kubectl get events -n meshnet LAST SEEN TYPE REASON OBJECT MESSAGE 15m Normal Scheduled pod/meshnet-72zz4 Successfully assigned meshnet/meshnet-72zz4 to kates-node-02 15m Normal Pulling pod/meshnet-72zz4 Pulling image \"hfam/meshnet:latest\" 15m Normal Pulled pod/meshnet-72zz4 Successfully pulled image \"hfam/meshnet:latest\" in 9.581184132s 15m Normal Created pod/meshnet-72zz4 Created container meshnet 15m Normal Started pod/meshnet-72zz4 Started container meshnet 15m Normal Scheduled pod/meshnet-9vqr2 Successfully assigned meshnet/meshnet-9vqr2 to kates-node-01 15m Normal Pulling pod/meshnet-9vqr2 Pulling image \"hfam/meshnet:latest\" 15m Normal Pulled pod/meshnet-9vqr2 Successfully pulled image \"hfam/meshnet:latest\" in 9.716760651s 15m Normal Created pod/meshnet-9vqr2 Created container meshnet 15m Normal Started po","date":"2022-06-06","objectID":"/posts/kube-my-router-pt3/:0:0","tags":["k8s","kne","netsim"],"title":"Kube my router up! - Last Part","uri":"/posts/kube-my-router-pt3/"},{"categories":["Art of Labbing"],"content":"Intro Part One - Setting up the k8s VMs in EVE-NG Part Two - Deploying the k8s cluster with kubeadm The Intent Deploy k8s cluster with kubeadm Single control plane, two workers Use containerd as the container runtime Flannel as network overlay CNI plugin The main question points while preparing the k8s cluster for KNE where which CRI and which CNI to use, since I am not very deep in to k8s. A brief research done on the kind container that KNE uses to deploy the cluster and run the simulations in it revealed that it uses containerd as the CRI. ‚ùØ kubectl get nodes -owide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME kne-control-plane Ready control-plane,master 14d v1.22.1 172.19.0.2 \u003cnone\u003e Ubuntu Impish Indri (development branch) 5.4.0-107-generic containerd://1.5.5Kindnet as the primary the CNI. ‚ùØ kubectl get ds -n kube-system NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kindnet 1 1 1 1 1 \u003cnone\u003e 14d kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 14dIn terms of network configuration: ‚ùØ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a099e5c3f7d3 kindest/node:v1.22.1 \"/usr/local/bin/entr‚Ä¶\" 2 weeks ago Up 2 weeks 127.0.0.1:34459-\u003e6443/tcp kne-control-plane ‚ùØ docker exec -it a099e5c3f7d3 bash root@kne-control-plane:/# root@kne-control-plane:/# ll /etc/cni/net.d/ total 16 drwx------ 2 root root 4096 May 22 22:16 ./ drwx------ 3 root root 4096 May 22 22:14 ../ -r--r--r-- 1 root root 518 May 22 22:16 00-meshnet.conflist -rw-r--r-- 1 root root 409 May 22 22:15 10-kindnet.conflist root@kne-control-plane:/# cat /etc/cni/net.d/10-kindnet.conflist { \"cniVersion\": \"0.3.1\", \"name\": \"kindnet\", \"plugins\": [ { \"type\": \"ptp\", \"ipMasq\": false, \"ipam\": { \"type\": \"host-local\", \"dataDir\": \"/run/cni-ipam-state\", \"routes\": [ { \"dst\": \"0.0.0.0/0\" } ], \"ranges\": [ [ { \"subnet\": \"10.244.0.0/24\" } ] ] } , \"mtu\": 1500 }, { \"type\": \"portmap\", \"capabilities\": { \"portMappings\": true } } ] } root@kne-control-plane:/# cat /etc/cni/net.d/00-meshnet.conflist { \"cniVersion\": \"0.3.1\", \"name\": \"kindnet\", \"plugins\": [ { \"ipMasq\": false, \"ipam\": { \"dataDir\": \"/run/cni-ipam-state\", \"ranges\": [ [ { \"subnet\": \"10.244.0.0/24\" } ] ], \"routes\": [ { \"dst\": \"0.0.0.0/0\" } ], \"type\": \"host-local\" }, \"mtu\": 1500, \"type\": \"ptp\" }, { \"capabilities\": { \"portMappings\": true }, \"type\": \"portmap\" }, { \"name\": \"meshnet\", \"type\": \"meshnet\", \"ipam\": {}, \"dns\": {} } ] }root@kne-control-plane:/#So it is a simple Layer 3 CNI, and meshnet will be installed on top of it. Let‚Äôs use a more common CNI, like flannel for our use case. Using flannel When using flannel, the main drawback was the interface MTU inside the device container, seen on srlinux. Flannel, since it uses VXLAN, will inherit the MTU of the main ethernet interface of the host and create its bridge interface flannel.1 with an MTU of minus 50, i.e. 1450 by default. When spinning up the containers, they use this MTU and from what I saw, srlinux cannot bring up its interfaces that need a minimum of 1500 MTU. The only way of mitigating this easily is to use higher MTU on the host interface, so flannel can inherit this, which I presume in a production environment should be something common and the network underlay would of course support jumbo‚Äôs. More on this during final part. Let‚Äôs change gears now and deploy the k8s cluster on the three VMs that are running on the two EVE-NG servers. Here‚Äôs what we have up and running: EVE-NG node Role VM name IP address CPU RAM eve-01 control-node kates-control 192.168.1.30 4 4096 eve-01 worker kates-node-01 192.168.1.31 8 28672 eve-02 worker kates-node-02 192.168.1.32 8 28672 We are going to deploy a single control node with two workers using kubeadm and also use the containerd container runtime. Prepare all nodes for kubeadm In all nodes, fix the /etc/hosts since we are not using proper DNS resolution and we need to statically be able to resolve. $ diff /etc/hosts.orig /etc/hosts -p *** /etc/hosts.orig 2022-05-30","date":"2022-05-31","objectID":"/posts/kube-my-router-pt2/:0:0","tags":["k8s","kubeadm","Ubuntu"],"title":"Kube my router up! - Part Two","uri":"/posts/kube-my-router-pt2/"},{"categories":["Art of Labbing"],"content":"Intro While I was ramping up my skills in k8s, I bumped into google‚Äôs Kubernetes based Network Emulation (KNE), and since I‚Äôve been a fool for network emulation software over the last twenty years, I knew I had to give it a go and see where it can get me. I first heard of KNE during episode #015 of this podcast and it seemed very promising to me since it is a way to spin up network topologies from devices running in containers orchestrated by a kubernetes cluster that, guess what, can span more than one host. So, in these series of posts I will try to document my experiences setting it up and having fun with it üòÑ since up to now there is too little documentation around it and also I think this blog post was the first to cover a basic orientation but still it covers running it inside a kind k8s node, i.e. in a container, where as my intent was to have the k8s spanning more than one machine since network devices are expensive in resources and my home lab is limited to 2x32GB EVE-NG servers. Part One - Setting up the k8s VMs in EVE-NG Part Two - Deploying the k8s cluster with kubeadm Last Part - Installing and testing KNE Part One - Setting up the VMs The Intent EVE-NG for hosting linux VMs Ubuntu 20.04 cloud image as base 2xEVE-NG servers, 2.0.3-112 community edition - 3 VMs in total Deployment of 3xLinux VMs for our k8s cluster Well the first step towards testing KNE is to set up a k8s cluster. I have two EVE-NG bare metal servers at home so I could spin up three VMs split in those two servers of 32GM RAM each. I‚Äôve chosen Ubuntu 20.04 linux flavor and decided to start by deploying the VMs using the cloud-image files. The approach followed here is to download the cloud image in both EVE-NG servers and create a seed file in order to pass the user password during first boot. This will be used as the base ubuntu image for all VMs. Finally, once the base VM is ready, the topology can be created and all the VMs can be brought up and configured with the appropriate settings. Prepare Ubuntu base image in EVE-NG Download Ubuntu 20.04 cloud image and place it into a temporary directory on the first server, optionally, verifying the md5sum. root@eve-01# mkdir -p /opt/cloud \u0026\u0026 cd !$ mkdir -p /opt/cloud \u0026\u0026 cd /opt/cloud/ root@eve-01# wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img \u003c ...omitted... \u003e root@eve-01# ll total 581388 drwxr-xr-x 2 root root 4096 May 29 21:19 ./ drwxr-xr-x 16 root root 4096 May 29 21:19 ../ -rw-r--r-- 1 root root 595329024 May 24 01:51 focal-server-cloudimg-amd64.img root@eve-01# curl -ks https://cloud-images.ubuntu.com/focal/current/MD5SUMS | md5sum -c --ignore-missing focal-server-cloudimg-amd64.img: OKCopy the image to the appropriate linux- directory of EVE-NG in so that is categorised as a linux image. You can resize the image to your linking as well. root@eve-01# mkdir -p /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/ root@eve-01# cp focal-server-cloudimg-amd64.img !$hda.qcow2 cp focal-server-cloudimg-amd64.img /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/hda.qcow2 root@eve-01# cd /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/ root@eve-01# ll total 581384 drwxr-xr-x 2 root root 4096 May 29 21:46 ./ drwxr-xr-x 12 root root 4096 May 29 21:45 ../ -rw-r--r-- 1 root root 595329024 May 29 21:46 hda.qcow2 root@eve-01# qemu-img info hda.qcow2 image: hda.qcow2 file format: qcow2 virtual size: 2.2G (2361393152 bytes) disk size: 568M cluster_size: 65536 Format specific information: compat: 0.10 refcount bits: 16 root@eve-01# qemu-img resize hda.qcow2 50G Image resized. root@eve-01# qemu-img info hda.qcow2 image: hda.qcow2 file format: qcow2 virtual size: 50G (53687091200 bytes) disk size: 568M cluster_size: 65536 Format specific information: compat: 0.10 refcount bits: 16 Install cloud-image utilities and prepare the seed file Install the required package. root@eve-01# cd /opt/cloud/ root@eve-01# apt install cloud-image-utils \u003c ...omitted...\u003ePrepare the seed file ","date":"2022-05-28","objectID":"/posts/kube-my-router-pt1/:0:0","tags":["EVE-NG","Ubuntu"],"title":"Kube my router up! - Part One","uri":"/posts/kube-my-router-pt1/"},{"categories":["humour"],"content":"Have you noticed that in some parts of the world, in some cafeterias, especially when the weather is hot, after you take your seat, a waiter comes and serves you a glass of water? Furthermore, in these places, the waiter has a frequent task to have this glass filled several times during your stay. Hence, we could say that the waiter has a task every once in a while to take a jug of water and re-fill the glasses of those customers that are not full, even if they are half-empty or half-full. We can say that the glass of water, in that case, is a mutable object, i.e. the glass is brought full at first and then its status can be changed by refilling it again. In addition, the task is idempotent because every time it is executed, the result would be the same, i.e. all glasses are full - unless someone asks no to have it filled üòÑ. This drinking water idempotency task can also be seen in expensive restaurants, where again there is a waiter (maybe call him idempotent) that takes care of re-filling your glass and in such places it happens much more often and usually it happens per-table rather than for all customers at the same time üòÑ. Now, this glass idempotency thing does not only apply to drinking water, but also to the wine glasses if you have ordered a bottle of wine, that is. But, what happens if you have only ordered and consumed a single glass of wine? Your glass is empty and the waiter will come and ask you if you‚Äôd like another one. You say yes, and then it happens. The waiter will take the empty glass and will go and fetch a new glass of wine for you, i.e. replacing the previous one. At this moment, you realize that the wine glass is not a mutable object, but it is immutable üòÑ. It cannot be re-filled, it cannot be changed and it has to be replaced by another glass of wine that could be the same or some other type, or something completely different, but they all will refer to the object you drink. You enjoyed your wine, it fulfilled its purpose, but if you want it to serve it‚Äôs purpose again, it has to be replaced with a new one or a new drink üòÑ ","date":"2022-04-30","objectID":"/posts/mutable-immutable/:0:0","tags":["automation"],"title":"Mutable vs. Immutable","uri":"/posts/mutable-immutable/"},{"categories":["humour"],"content":"Imagine a beautiful sunny morning you walk into a dinner to have some brunch. You take a seat on a free table and the waitress comes over to take your order while filling a glass of water for you. -\u003e May I have two eggs, sunny side up, and some crispy bacon, please? =\u003e Sure darling, anything to drink? -\u003e I‚Äôd like some orange juice - no ice, please. =\u003e Coming right up! The waitress takes down your order in a peace of paper, goes over to the kitchen service area and hands in the paper to the chef. The chef reads the order and starts shouting to his newbie cooks: -\u003e Miguel, Heat a pan with four bacon strips in it Take two eggs out of the fridge When the bacon is crisp enough, move it from the pan to a plate Crack the two eggs as close to the pan as you can and lower the heat When the eggs are ready, remove the pan from the stove and put the eggs on a plate -\u003e Karla, Lay some butter on both sides on two toast bread slices Put the toast in a heated oven for 6 minutes When done and the bread is crisp enough, remove them from the oven and put them on a plate Poor a glass of orange juice from the fridge with no ice Eventually, after Karla and Miguel have followed the chef‚Äôs instructions and prepared all the components, the chef can assemble them on a plate, season the eggs with salt and pepper, check if all is ok and along with the orange juice pass them to the waitress who will bring them over to your table and you will enjoy your brunch. Well I guess by now you would have noticed the difference of what declarative versus imperative means üòÑ Your order is the declarative way of doing things. You just describe what you want to be done, the end result. On the other hand, what the chef is doing, could be though of as the imperative way. He is giving commands, instructions on how to do individual things and tasks in order to achieve the end result. Now, if we want to take it one step further, let‚Äôs say Karla and Miguel are, by now, much more experienced and the chef does not have to explicitly tell them how to prepare every step of the recipe. In plain, they can automate the tasks and the chef has just to say: eggs - bacon - bread - orange juice, and that‚Äôs it. It all happens faster. So, the chef is able to orchesrtate the automated tasks that the cooks can perform to produce the result. Now, let‚Äôs go back to the top and say that you just order the sunny sunday morning from the menu, i.e. the service catalog, won‚Äôt the whole process be faster and more clear? Yes, as long as the waitress tells the chef and he does not forget to instruct Karla not to put ice in the orange juice üòÑ Now I am getting hungry‚Ä¶ ","date":"2022-04-28","objectID":"/posts/declarative-imperative/:0:0","tags":["automation"],"title":"Declarative vs. Imperative","uri":"/posts/declarative-imperative/"},{"categories":["humour"],"content":" Œ†œéœÇ ŒªŒ≠Œ≥ŒµœÑŒ±Œπ œåœÑŒ±ŒΩ œáœÅŒ∑œÉŒπŒºŒøœÄŒøŒπŒøœçŒºŒµ terraform ŒºŒµ œÑŒø Cisco ACI; TF-ACI‚Ä¶Œ§Œπ œÜŒ¨Œ±Œ±œÉŒ∑! üëé üëø \u003cclick again to collapse and let‚Äôs pretend you didn‚Äôt read the joke at all\u003e ","date":"2022-04-21","objectID":"/posts/tf-aci/:0:0","tags":["bad-jokes"],"title":"TF-ACI","uri":"/posts/tf-aci/"}]