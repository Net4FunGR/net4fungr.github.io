<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Becos :: Back Blog</title><link>https://net4fungr.github.io/</link><description>Becos :: Back Blog</description><generator>Hugo 0.157.0 &amp; FixIt v0.4.2</generator><language>en</language><managingEditor>mkaliotis(at)gmail(dot)com (becos76)</managingEditor><webMaster>mkaliotis(at)gmail(dot)com (becos76)</webMaster><lastBuildDate>Sun, 08 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://net4fungr.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>For those about to LAB...⚡</title><link>https://net4fungr.github.io/posts/iou-love/</link><pubDate>Tue, 05 Nov 2024 00:00:00 +0000</pubDate><guid>https://net4fungr.github.io/posts/iou-love/</guid><category domain="https://net4fungr.github.io/categories/art-of-labbing/">Art of Labbing</category><description>&lt;hr&gt;
&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;Intro&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Cisco IOL, aka IOU, and I go back a long way. Back in the day, when I decided to sit for the CCIE R&amp;amp;S v4 exam, there weren&amp;rsquo;t many options to get hands on on the cli other than having access to real devices or using dynamips and GNS3 for simulating routers and switches, but with limited feature support, especially on the S side.&lt;/p&gt;
&lt;p&gt;Hence, since I have also been known as a big time pack rat, I decided to go for a real LAB. So, after spending nearly over $6k, I managed to build a real home lab with all the quirks. Terminal server, AUI converters , x-over and serial cables, remote managed PSUs, I remember being so happy!&lt;/p&gt;
&lt;p&gt;The joy went on for a couple of months, while I was setting up the scenarios, practicing the theory, re-configuring and starting over. Then one day, as I was googling for something, I bumped to some news that Cisco IOS-on-Unix has been leaked to the public and people were already using it to build virtual labs. Then an IOS-on-Linux version was also leaked and you can imagine how stupid I felt after this.&lt;/p&gt;
&lt;p&gt;I, of course, ended up in using it and even got a refurb SPARCstation to run IOU in the interim before I could get my hands on a &lt;em&gt;stable&lt;/em&gt; IOL version without major issues. Anyway, this was just to give you the context of my history with IOL. I never sat for the lab in the end, but that&amp;rsquo;s another story.&lt;/p&gt;
&lt;p&gt;So, imagine my excitement when the recent news of IOL support in &lt;a href="https://containerlab.dev/rn/0.58/#cisco-iol" target="_blank" rel="external nofollow noopener noreferrer"&gt;containerlab&lt;/a&gt; and &lt;a href="https://netlab.tools/release/1.9/#release-1-9-2" target="_blank" rel="external nofollow noopener noreferrer"&gt;netlab&lt;/a&gt; reached my eyes. It brought back so many reminisces, that I had to write something about it. Containerlab and netlab have always been in my back-blog, and I wanted to post about them, but I feel that the community is doing such a great job on them, whilst in this case I felt that the time is right for me as well.&lt;/p&gt;
&lt;p&gt;As a bottom line here, IOL has always been the preferred choice due to its low demand on resources for the supported and relevant use cases, and the fact that it can now be supported in containerised topologies increases its network automation friendliness (NAFness :)) level, not too much though, since it is lacking some features as we will see later on.&lt;/p&gt;
&lt;h2 class="heading-element" id="use-case-brief"&gt;&lt;span&gt;Use Case Brief&lt;/span&gt;
 &lt;a href="#use-case-brief" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Everything starts with a use case, the intent! In my case, I want to spin up topologies and test different things in Kentik. The idea came from the &lt;a href="https://github.com/srl-labs/srl-telemetry-lab" target="_blank" rel="external nofollow noopener noreferrer"&gt;srl-telemetry-lab&lt;/a&gt;, so we will be following the same approach but for Kentik related use cases. Hence,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dynamic topology that is sending netflow to Kentik via the kproxy agent&lt;/li&gt;
&lt;li&gt;Traffic simulation using iperf3 on the devices&lt;/li&gt;
&lt;li&gt;Kentik Synthetic agents attached to the topology performing tests&lt;/li&gt;
&lt;li&gt;Devices registered in Kentik NMS for monitoring&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="heading-element" id="why-containerlab"&gt;&lt;span&gt;Why containerlab?&lt;/span&gt;
 &lt;a href="#why-containerlab" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Dynamic topology: support CRUDs on the infrastructure&lt;/li&gt;
&lt;li&gt;IaC model support: everything defined in structured format&lt;/li&gt;
&lt;li&gt;Integrates well with netlab as a provider&lt;/li&gt;
&lt;li&gt;Minimal effort on the above / more focus on the use cases&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="heading-element" id="why-netlab"&gt;&lt;span&gt;Why netlab?&lt;/span&gt;
 &lt;a href="#why-netlab" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Automatic provisioning of underlay connectivity details and protocols&lt;/li&gt;
&lt;li&gt;Flexibility in adding custom templates and using custom playbooks based on a common ansible inventory file&lt;/li&gt;
&lt;li&gt;Good integration with containerlab&lt;/li&gt;
&lt;li&gt;Minimal effort on the above / more focus on the use cases&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think netlab is the perfect example of &lt;em&gt;Automating the Boring Stuff&lt;/em&gt;. I never counted the times or will ever forget that I had to type those commands &amp;#x1f604; :
&lt;div class="details admonition quote open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-quote-right" aria-hidden="true"&gt;&lt;/i&gt;Boring Stuff&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;conf t ⏎ no ip do lo ⏎ line con 0 ⏎ logg syn ⏎ exec-t 0 ⏎ ^Z wr ⏎&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;h3 class="heading-element" id="why-iol"&gt;&lt;span&gt;Why IOL?&lt;/span&gt;
 &lt;a href="#why-iol" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Demand on resources is very low&lt;/li&gt;
&lt;li&gt;Fit my use case since netflow export is supported&lt;/li&gt;
&lt;li&gt;No licensing limits on traffic volumes&lt;/li&gt;
&lt;li&gt;Seems IOL reports interface errors when traffic is pushed. A bug or a feature, don&amp;rsquo;t care at the moment since it has always been a burden to fire up synthetic errors on interface counters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="heading-element" id="things-covered"&gt;&lt;span&gt;Things Covered&lt;/span&gt;
 &lt;a href="#things-covered" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Now that we have picked up the correct tools for the job, let&amp;rsquo;s see what we are going to cover so you can assess if this is still interesting enough to carry on reading.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using &lt;em&gt;netlab&lt;/em&gt; to provision a lab by using &lt;em&gt;containerlab&lt;/em&gt; for spinning up the nodes&lt;/li&gt;
&lt;li&gt;Using IOL for the network device type&lt;/li&gt;
&lt;li&gt;Using various containers to integrate with the topology as the linux device type&lt;/li&gt;
&lt;li&gt;Using &lt;em&gt;iperf3&lt;/em&gt; for generating traffic load on the topology&lt;/li&gt;
&lt;li&gt;Using OSPF, BGP, MPLS and VRF modules in &lt;em&gt;netlab&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Using jinja templates to provision additional commands to the nodes either ad-hoc or during lab bring-up.&lt;/li&gt;
&lt;li&gt;Defining custom variables in the topology so we can use them later on either in the templates or in &lt;em&gt;ansible&lt;/em&gt; plays.&lt;/li&gt;
&lt;li&gt;We will be using &lt;em&gt;Windows Subsystem for Linux&lt;/em&gt; (WSL) for this use case.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So by using all the above we can deploy a topology like the one depicted in the following section, register the devices in Kentik, produce traffic and explore how to visualise, monitor, and run synthetic tests on it via Kentik. And all this by using automated tasks on the way.&lt;/p&gt;
&lt;h3 class="heading-element" id="topology-walk-through"&gt;&lt;span&gt;Topology Walk-through&lt;/span&gt;
 &lt;a href="#topology-walk-through" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/iou-love/topology.png" title="/posts/iou-love/topology.png" data-thumbnail="/posts/iou-love/topology.png" data-sub-html="&lt;h2&gt;LAB Topology&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/iou-love/topology.png' alt="/posts/iou-love/topology.png" height="722" width="1213"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;LAB Topology&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;p&gt;As you see, the topology is rather simple. We have four core devices (rcX) running an MPLS-LDP backbone and offering L3VPN services over MP-BGP to four CE devices (ceX). The PC nodes are used to generate traffic and the &lt;em&gt;ksynth&lt;/em&gt; nodes are Kentik private synthetics agents. As you may have guessed, we have two VPNs, &lt;strong style="color: red;"&gt;&lt;em&gt;red&lt;/em&gt;&lt;/strong&gt; and &lt;strong style="color: blue;"&gt;&lt;em&gt;blue&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Network devices are IOL containers and PC&amp;rsquo;s are based on the &lt;a href="https://github.com/srl-labs/network-multitool/pkgs/container/network-multitool" target="_blank" rel="external nofollow noopener noreferrer"&gt;network-multitool&lt;/a&gt; container image. Of course, we also have additional containers running and I like to call them service containers, since they are there to interact with the topology and report data back to Kentik, realising our use case.&lt;/p&gt;
&lt;p&gt;The basic idea behind connectivity in &lt;em&gt;netlab/containerlab&lt;/em&gt; is that there is a &lt;em&gt;management&lt;/em&gt; docker bridge network that all nodes connect. Each node connects to the management network, usually by its first interface, and &lt;em&gt;netlab&lt;/em&gt; uses this to provision commands to it. All other node links are formed based on the desired configuration by bridging the relevant node interfaces.&lt;/p&gt;
&lt;p&gt;Hence, the service containers, do not have to connect in-line to the topology and all communications go via the management network. But, let&amp;rsquo;s see them one by one:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;kproxy&lt;/strong&gt;: Kentik agent that listens to netflow from the devices and reports to Kentik. This agent also polls devices for SNMP metrics and metadata. All communications are going via the management network, from/to the devices in the isolated management VRF. In addition, since this is a container attached to a docker network inside the host machine, it has access to the Internet by default, so it is able to go out to Kentik and report the data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kbgp&lt;/strong&gt;: Kentik agent that tunnels bgp sessions from the devices all the way up to Kentik. This agent actually needs an inline connection so all other nodes can form the session. In our case, it is connected to &lt;strong&gt;rc1&lt;/strong&gt; so all others can reach it. Communication with Kentik is done via the container&amp;rsquo;s first interface that belongs to the management network, the same way as &lt;strong&gt;kproxy&lt;/strong&gt; does.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kagent&lt;/strong&gt;: Kentik&amp;rsquo;s Universal Agent that is part of the Kentik NMS product and is polling the devices for SNMP data and reporting it into the NMS part. Here, I have chosen to deploy this as a standard container on the host machine (WSL) and it is not included in the topology. Thus, &lt;em&gt;netlab&lt;/em&gt; is not aware of it at all, but still &lt;strong&gt;kagent&lt;/strong&gt; can communicate with the devices via the management network since they are part of the same host, just in a different docker bridge network. So communication is possible since this agent is only polling the devices via their management interfaces and there is no need to expose anything (or should I say ingress path) from its side.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will expand more on the connectivity details as we build the topology further on, but for now, the three basic things to ask yourself regarding how to run your service containers are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do they need to be &lt;em&gt;controlled&lt;/em&gt; somehow via &lt;em&gt;netlab&lt;/em&gt;?&lt;/li&gt;
&lt;li&gt;Does &lt;em&gt;netlab&lt;/em&gt; need to know any detail about them?&lt;/li&gt;
&lt;li&gt;Are your devices capable to communicate with them via their management VRF for their purpose?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="heading-element" id="setting-things-up"&gt;&lt;span&gt;Setting Things Up&lt;/span&gt;
 &lt;a href="#setting-things-up" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;In this section we are going to focus on how to set things up in WSL. We will start by building the IOL containers for our use case and then see a typical installation of &lt;em&gt;netlab&lt;/em&gt;.&lt;/p&gt;
&lt;h3 class="heading-element" id="building-the-iol-containers"&gt;&lt;span&gt;Building the IOL containers&lt;/span&gt;
 &lt;a href="#building-the-iol-containers" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;IOL containers are supported in &lt;em&gt;containerlab&lt;/em&gt; via their &lt;a href="https://containerlab.dev/manual/vrnetlab/#vrnetlab" target="_blank" rel="external nofollow noopener noreferrer"&gt;&lt;em&gt;vrnetlab&lt;/em&gt;&lt;/a&gt; fork. The current IOL &lt;a href="https://developer.cisco.com/docs/modeling-labs/iol/" target="_blank" rel="external nofollow noopener noreferrer"&gt;images&lt;/a&gt; are those included with the Cisco CML image reference collection (refplat), so you have to get hold of them and copy them to the relevant build directory in &lt;em&gt;vrnetlab&lt;/em&gt; in order to build them. Here are the steps:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; Clone the repo:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· git clone https://github.com/hellt/vrnetlab
Cloning into &amp;#39;vrnetlab&amp;#39;...
remote: Enumerating objects: 5363, done.
remote: Counting objects: 100% (2011/2011), done.
remote: Compressing objects: 100% (660/660), done.
remote: Total 5363 (delta 1542), reused 1649 (delta 1348), pack-reused 3352 (from 1)
Receiving objects: 100% (5363/5363), 2.27 MiB | 664.00 KiB/s, done.
Resolving deltas: 100% (3245/3245), done.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; Copy the images to the appropriate folder and rename them according to the README. I chose to make links to them instead:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· cd vrnetlab/cisco/iol/
(wsl)&amp;lt;&amp;lt;· lll
total 516920
-rw-r--r-- 1 289 Makefile
-rw-r--r-- 1 1721 README.md
lrwxrwxrwx 1 35 cisco_iol-17.12.1.bin -&amp;gt; x86_64_crb_linux-adventerprisek9-ms
lrwxrwxrwx 1 38 cisco_iol-L2-17.12.1.bin -&amp;gt; x86_64_crb_linux_l2-adventerprisek9-ms
drwxr-xr-x 2 4096 docker
-rwxr-xr-x 1 288947184 x86_64_crb_linux-adventerprisek9-ms
-rwxr-xr-x 1 240355720 x86_64_crb_linux_l2-adventerprisek9-ms&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; Build with &lt;code&gt;make docker-image&lt;/code&gt; and check in docker. You should end up having the two IOL images in the registry. One for the &lt;em&gt;router&lt;/em&gt; and one for the &lt;em&gt;switch&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· make docker-image
&amp;lt; build output &amp;gt;

(wsl)&amp;lt;&amp;lt;· docker images vrnetlab/cisco_iol*
REPOSITORY TAG IMAGE ID CREATED SIZE
vrnetlab/cisco_iol L2-17.12.1 15d363218573 About a minute ago 607MB
vrnetlab/cisco_iol 17.12.1 1d44f7fa6252 About a minute ago 704MB&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; You can test with the following command to see if they are &lt;em&gt;booting&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· docker run -it --rm -e IOL_PID=1 \
	--mount type=bind,source=/dev/null,target=/iol/NETMAP vrnetlab/cisco_iol:17.12.1

Launching IOL with PID 1
Failed to send flush request: Operation not permitted
Flushed eth0 addresses
/entrypoint.sh: line 14: /usr/bin/iouyap: Operation not permitted
/entrypoint.sh: line 14: /usr/bin/iouyap: Success
IOS On Unix - Cisco Systems confidential, internal use only

 IOURC: Could not open iourc file
Warning: configuration file (config.txt) does not exist

Warning: Abnormal ciscoversion string, please notify the IOU team
with the name of this branch
Warning: we parsed - NULL

 Restricted Rights Legend

Use, duplication, or disclosure by the Government is
subject to restrictions as set forth in subparagraph
(c) of the Commercial Computer Software - Restricted
Rights clause at FAR sec. 52.227-19 and subparagraph
(c) (1) (ii) of the Rights in Technical Data and Computer
Software clause at DFARS sec. 252.227-7013.

 Cisco Systems, Inc.
 170 West Tasman Drive
 San Jose, California 95134-1706



Cisco IOS Software [Dublin], Linux Software (X86_64BI_LINUX-ADVENTERPRISEK9-M), Version 17.12.1, RELEASE SOFTWARE (fc5)
Technical Support: http://www.cisco.com/techsupport
Copyright (c) 1986-2023 by Cisco Systems, Inc.
Compiled Thu 27-Jul-23 22:33 by mcpre


PM unix notify udp ports APP_ID:0 DISABLE Port1:0 Port2:0
PM unix notify udp ports APP_ID:1 DISABLE Port1:0 Port2:0Linux Unix (i686) processor with 550115K bytes of memory.
Processor board ID 1
4 Ethernet interfaces
1024K bytes of NVRAM.

No startup-config, starting autoinstall/pnp/ztp...

Autoinstall will terminate if any input is detected on console

Autoinstall trying DHCPv4 on Ethernet0/0,Ethernet0/1,Ethernet0/2,Ethernet0/3

&amp;lt; snipped &amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;They are based on XE 17.12.1 release so they are more feature rich than the past IOL ones (IOS 15.x), they do &lt;strong&gt;not&lt;/strong&gt; support any of the automation goodies as well as streaming telemetry, but they can push traffic without any licensing restriction.&lt;/p&gt;
&lt;h3 class="heading-element" id="installing-netlab-in-wsl"&gt;&lt;span&gt;Installing Netlab in WSL&lt;/span&gt;
 &lt;a href="#installing-netlab-in-wsl" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Now that we have our devices, let&amp;rsquo;s go ahead and install &lt;em&gt;netlab&lt;/em&gt; in WSL. I am using the following versions and linux flavour:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)·&amp;gt;&amp;gt; wsl.exe -v
WSL version: 2.3.26.0
Kernel version: 5.15.167.4-1
WSLg version: 1.0.65
MSRDC version: 1.2.5620
Direct3D version: 1.611.1-81528511
DXCore version: 10.0.26100.1-240331-1435.ge-release
Windows version: 10.0.19045.5131

(wsl)&amp;lt;&amp;lt;· cat /etc/os-release
PRETTY_NAME=&amp;#34;Ubuntu 22.04.5 LTS&amp;#34;
NAME=&amp;#34;Ubuntu&amp;#34;
VERSION_ID=&amp;#34;22.04&amp;#34;
VERSION=&amp;#34;22.04.5 LTS (Jammy Jellyfish)&amp;#34;
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL=&amp;#34;https://www.ubuntu.com/&amp;#34;
SUPPORT_URL=&amp;#34;https://help.ubuntu.com/&amp;#34;
BUG_REPORT_URL=&amp;#34;https://bugs.launchpad.net/ubuntu/&amp;#34;
PRIVACY_POLICY_URL=&amp;#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&amp;#34;
UBUNTU_CODENAME=jammy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; I chose to install &lt;em&gt;netlab&lt;/em&gt; in a virtual env:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· sudo apt install python-is-python3 python3-pip python3-venv
&amp;lt; snipped &amp;gt;

(wsl)&amp;lt;&amp;lt;· mkdir -p netlab/iol
(wsl)&amp;lt;&amp;lt;· cd netlab/iol
(wsl)&amp;lt;&amp;lt;· python -m venv .venv
(wsl)&amp;lt;&amp;lt;· source .venv/bin/activate&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; Install &lt;em&gt;netlab&lt;/em&gt; via pip and then all dependencies:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· pip install networklab
&amp;lt; snipped &amp;gt;

(wsl)&amp;lt;&amp;lt;· netlab install ubuntu ansible containerlab
&amp;lt; snipped &amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; Open another terminal to cause re-login and bring up the test topology to verify everything is set up correctly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· cd netlab/iol
(wsl)&amp;lt;&amp;lt;· source .venv/bin/activate
(wsl)&amp;lt;&amp;lt;· netlab test clab
&amp;lt; snipped &amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Netalab&lt;/em&gt; will provision a 3 node topology based on &lt;em&gt;frr&lt;/em&gt; and test if everything is working as expected. Finally it will cleanup after itself.&lt;/p&gt;
&lt;h2 class="heading-element" id="topology-definition"&gt;&lt;span&gt;Topology Definition&lt;/span&gt;
 &lt;a href="#topology-definition" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s now start the fun part by exploring how to define our LAB so &lt;em&gt;netlab&lt;/em&gt; can spin it up and provision it the way we want it. &lt;em&gt;Netlab&lt;/em&gt; expects us to define everything in a single topology definition file, by default &lt;code&gt;topology.yml&lt;/code&gt;. We are going to build the base topology that includes just the routers and the PC&amp;rsquo;s, and then move on with adding the service containers.&lt;/p&gt;
&lt;h3 class="heading-element" id="building-the-base-topology---step-by-step"&gt;&lt;span&gt;Building the Base Topology - Step-by-step&lt;/span&gt;
 &lt;a href="#building-the-base-topology---step-by-step" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;The first thing to do in the topology file is to declare which virtualisation provider we are going to be using. For our case this is &lt;code&gt;clab&lt;/code&gt; and here is how to check what others are supported along with their status in the current installation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab show providers
Supported virtualization providers

┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃ provider ┃ description ┃ status ┃
┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ clab │ containerlab with Docker │ OK │
│ external │ External devices │ OK │
│ libvirt │ Vagrant with libvirt/KVM │ N/A │
│ virtualbox │ Vagrant with Virtualbox │ N/A │
└────────────┴──────────────────────────┴────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The minimum sections that &lt;em&gt;netlab&lt;/em&gt; expects to find in the topology file is the &lt;code&gt;provider&lt;/code&gt;, the &lt;code&gt;nodes&lt;/code&gt; and the &lt;code&gt;links&lt;/code&gt;. And the minimum attributes that it needs to know about a node before provisioning it is the device type we want to use. Here are the supported device types:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab show devices
Virtual network devices supported by netlab

┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ device ┃ description ┃
┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ arubacx │ ArubaOS-CX │
│ asav │ Cisco ASAv │
│ cat8000v │ Cisco CSR 1000v │
│ csr │ Cisco CSR 1000v │
│ cumulus │ Cumulus VX 4.x or 5.x configured without NVUE │
│ cumulus_nvue │ Cumulus VX 5.x configured with NVUE │
│ dellos10 │ Dell OS10 │
│ eos │ Arista vEOS VM or cEOS container │
│ fortios │ Fortinet FortiOS firewall │
│ frr │ FRR container │
│ iol │ Cisco IOL │
│ ioll2 │ IOSv L2 image │
│ iosv │ Cisco IOSv │
│ iosvl2 │ IOSv L2 image │
│ iosxr │ Cisco IOS XRv │
│ linux │ Generic Linux host │
│ nxos │ Cisco Nexus 9300v │
│ routeros │ Mikrotik RouterOS version 6 │
│ routeros7 │ Mikrotik RouterOS version 7 │
│ sonic │ Sonic VM │
│ srlinux │ Nokia SR Linux container │
│ sros │ Nokia SR OS container │
│ vjunos-switch │ vJunos Switch │
│ vmx │ Juniper vMX container │
│ vptx │ Juniper vPTX │
│ vsrx │ Juniper vSRX 3.0 │
│ vyos │ VyOS VM/container │
└───────────────┴───────────────────────────────────────────────┘

Networking daemons supported by netlab

┏━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ daemon ┃ description ┃
┡━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ bird │ BIRD Internet Routing Daemon │
│ dnsmasq │ BIRD Internet Routing Daemon │
└─────────┴──────────────────────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So &lt;code&gt;iol&lt;/code&gt; for the routers and &lt;code&gt;linux&lt;/code&gt; for the PC&amp;rsquo;s and as you may have guessed &lt;em&gt;netlab&lt;/em&gt; has a &lt;code&gt;defaults&lt;/code&gt; &lt;em&gt;dictionary&lt;/em&gt; that is pre-populated for us that we can of course override with custom values. For example, let&amp;rsquo;s see which images will be used if we specify device type as &lt;code&gt;iol&lt;/code&gt; and &lt;code&gt;linux&lt;/code&gt; by using the &lt;code&gt;netlab show&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab show images -d iol
iol image names by virtualization provider

┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━┓
┃ device ┃ clab ┃ libvirt ┃ virtualbox ┃
┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━┩
│ iol │ vrnetlab/cisco_iol:17.12.01 │ │ │
└────────┴─────────────────────────────┴─────────┴────────────┘

(wsl)&amp;lt;&amp;lt;· netlab show images -d linux
linux image names by virtualization provider

┏━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓
┃ device ┃ clab ┃ libvirt ┃ virtualbox ┃
┡━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩
│ linux │ python:3.9-alpine │ generic/ubuntu2004 │ generic/ubuntu2004 │
└────────┴───────────────────┴────────────────────┴────────────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So these container images will be picked up by default if we specify the respective device type in the topology. Of course, we want to override those since our images are different, and here is how we can do this in the topology file by utilising a separate &lt;code&gt;defaults&lt;/code&gt; section prior to defining our &lt;code&gt;nodes&lt;/code&gt; and their interconnection &lt;code&gt;links&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;provider: clab
defaults:
  device: iol
  devices.iol.clab.image: vrnetlab/cisco_iol:17.12.1
  devices.linux.clab.image: ghcr.io/srl-labs/network-multitool

nodes:
  rc1:
    device: iol
  rc2:
    device: iol
  rc3:
    device: iol
  rc4:
    device: iol
  pc1:
    device: linux
  pc2:
    device: linux
  pc3:
    device: linux
  pc4:
    device: linux

links:
  - rc1-rc2
  - rc1-rc3
  - rc2-rc4
  - rc3-rc4
  - rc1-pc1
  - rc2-pc2
  - rc3-pc3
  - rc4-pc4&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let&amp;rsquo;s bring up the topology to see the real power of &lt;em&gt;netlab&lt;/em&gt;. To start the lab we can use the &lt;code&gt;netlab up&lt;/code&gt; command and after some scripts are executed and some ansible plays, everything is up and running. We can check this with &lt;code&gt;netlab status&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab status

┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ node ┃ device ┃ image ┃ mgmt IPv4 ┃ connection ┃ provider ┃ VM/container ┃ status ┃
┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ pc1 │ linux │ ghcr.io/srl-labs/network-mult… │ 192.168.121.105 │ docker │ clab │ clab-iol-pc1 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc2 │ linux │ ghcr.io/srl-labs/network-mult… │ 192.168.121.106 │ docker │ clab │ clab-iol-pc2 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc3 │ linux │ ghcr.io/srl-labs/network-mult… │ 192.168.121.107 │ docker │ clab │ clab-iol-pc3 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc4 │ linux │ ghcr.io/srl-labs/network-mult… │ 192.168.121.108 │ docker │ clab │ clab-iol-pc4 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc1 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.101 │ network_cli │ clab │ clab-iol-rc1 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc2 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.102 │ network_cli │ clab │ clab-iol-rc2 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc3 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.103 │ network_cli │ clab │ clab-iol-rc3 │ Up 2 minutes │
├──────┼────────┼────────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc4 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.104 │ network_cli │ clab │ clab-iol-rc4 │ Up 2 minutes │
└──────┴────────┴────────────────────────────────┴─────────────────┴─────────────┴──────────┴──────────────┴──────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Seems everything is up and running, but how is this different than just bringing up the topology with &lt;em&gt;containerlab&lt;/em&gt;? Well, &lt;em&gt;netlab&lt;/em&gt; goes one step further and configures the devices with basic ip connectivity and also with any other protocol that is supported as we will see later on. We can check on a device for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab exec rc1 show ip int br
Connecting to clab-iol-rc1 using SSH port 22, executing show ip int br



Interface IP-Address OK? Method Status Protocol
Ethernet0/0 192.168.121.101 YES TFTP up up
Ethernet0/1 10.1.0.1 YES manual up up
Ethernet0/2 10.1.0.5 YES manual up up
Ethernet0/3 172.16.0.1 YES manual up up
Loopback0 10.0.0.1 YES manual up up Connection to clab-iol-rc1 closed by remote host.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or on a PC:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab exec pc1 ip -c -br a
Connecting to container clab-iol-pc1, executing ip -c -br a
lo UNKNOWN 127.0.0.1/8 ::1/128
eth0@if1052 UP 192.168.121.105/24 fe80::42:c0ff:fea8:7969/64
eth1@if1065 UP 172.16.0.5/24 fe80::a8c1:abff:fe5d:19e2/64


(wsl)&amp;lt;&amp;lt;· netlab exec pc1 ip -c -br r
Connecting to container clab-iol-pc1, executing ip -c -br r
default via 192.168.121.1 dev eth0
10.0.0.0/24 via 172.16.0.1 dev eth1
10.1.0.0/16 via 172.16.0.1 dev eth1
10.2.0.0/24 via 172.16.0.1 dev eth1
172.16.0.0/24 dev eth1 proto kernel scope link src 172.16.0.5
172.16.0.0/16 via 172.16.0.1 dev eth1
192.168.121.0/24 dev eth0 proto kernel scope link src 192.168.121.105&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So apart from bringing up the nodes, &lt;em&gt;netlab&lt;/em&gt; using its defaults dictionary and attributes, parsed the topology and provisioned IP addresses for every link and also configured the routing in linux to point to the blocks used in the topology via the containers&amp;rsquo; second interface attached to the router. In this way, we can define our topology and protocols and &lt;em&gt;netlab&lt;/em&gt; will take care of the commands needed to be provisioned and pushed to the nodes.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see now the default addressing scheme:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)·&amp;gt;&amp;gt; netlab show defaults addressing

netlab default settings within the addressing subtree
=============================================================================

l2only: null
lan:
 ipv4: 172.16.0.0/16
loopback:
 ipv4: 10.0.0.0/24
mgmt:
 ipv4: 192.168.121.0/24
 mac: 08-4F-A9-00-00-00
 start: 100
p2p:
 ipv4: 10.1.0.0/16
router_id:
 ipv4: 10.0.0.0/24
 prefix: 32
vrf_loopback:
 ipv4: 10.2.0.0/24
 prefix: 32&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you see, for any p2p link the 10.1/16 block will be used, whereas for any lan, &lt;em&gt;netlab&lt;/em&gt; will use the 172.16/16 one. 10.0.0/24 is used for the loopbacks and 10.2.0/24 for any loopback that belongs in a vrf and, of course, you may modify these as per your liking.&lt;/p&gt;
&lt;p&gt;Furthermore, in order to understand this behaviour a bit more, check on the directory structure to see the different directories and files created since we brought up the lab:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· tree . -L 1
.
├── ansible.cfg &amp;lt;- Ansible configuration file
├── clab-iol &amp;lt;- clab related runtime directory
├── clab.yml &amp;lt;- Respective clab topology file
├── clab_files &amp;lt;- hosts files to mount at /etc/hosts for every linux container
├── group_vars &amp;lt;- Ansible group_vars after merging the defaults and topology specific variables
├── host_vars &amp;lt;- same for each host
├── hosts.yml &amp;lt;- Ansible inventory file
├── netlab.lock &amp;lt;- lock file when netlab is running
├── netlab.snapshot.yml &amp;lt;- snapshot of the whole dictionary
└── topology.yml &amp;lt;- Original topology file that we started with&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we ended up having a full blown ansible structure for this lab that &lt;em&gt;netlab&lt;/em&gt; is using to provision commands and, guess what, we can also use it with our own plays.&lt;/p&gt;
&lt;p&gt;Two additional commands to help you in exploring the data structure and ansible variables available in the topology are &lt;code&gt;netlab inspect&lt;/code&gt; and &lt;code&gt;ansible-inventory&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab inspect --node rc1 loopback
ifindex: 0
ifname: Loopback0
ipv4: 10.0.0.1/32
neighbors: []
type: loopback
virtual_interface: true

(wsl)&amp;lt;&amp;lt;· ansible-inventory --host rc1 | jq .loopback
{
 &amp;#34;ifindex&amp;#34;: 0,
 &amp;#34;ifname&amp;#34;: &amp;#34;Loopback0&amp;#34;,
 &amp;#34;ipv4&amp;#34;: &amp;#34;10.0.0.1/32&amp;#34;,
 &amp;#34;neighbors&amp;#34;: [],
 &amp;#34;type&amp;#34;: &amp;#34;loopback&amp;#34;,
 &amp;#34;virtual_interface&amp;#34;: true
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;OK, now that we got the hang of it, let&amp;rsquo;s bring down the topology and cleanup our directory structure in order to complete the basic topology definition.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab down --cleanup
[SUCCESS] Read transformed lab topology from snapshot file netlab.snapshot.yml

┌──────────────────────────────────────────────────────────────────────────────────┐
│ CHECKING virtualization provider installation │
└──────────────────────────────────────────────────────────────────────────────────┘
[SUCCESS] clab installed and working correctly

┌──────────────────────────────────────────────────────────────────────────────────┐
│ STOPPING clab nodes │
└──────────────────────────────────────────────────────────────────────────────────┘
INFO[0000] Parsing &amp;amp; checking topology file: clab.yml
INFO[0000] Parsing &amp;amp; checking topology file: clab.yml
WARN[0000] errors during iptables rules install: not available
INFO[0000] Destroying lab: iol
INFO[0001] Removed container: clab-iol-pc4
INFO[0001] Removed container: clab-iol-rc2
INFO[0002] Removed container: clab-iol-pc1
INFO[0002] Removed container: clab-iol-pc3
INFO[0002] Removed container: clab-iol-pc2
INFO[0002] Removed container: clab-iol-rc4
INFO[0002] Removed container: clab-iol-rc1
INFO[0002] Removed container: clab-iol-rc3
INFO[0002] Removing containerlab host entries from /etc/hosts file
INFO[0002] Removing ssh config for containerlab nodes
WARN[0003] errors during iptables rules removal: not available

┌──────────────────────────────────────────────────────────────────────────────────┐
│ CLEANUP configuration files │
└──────────────────────────────────────────────────────────────────────────────────┘
... removing clab.yml
... removing directory tree clab_files
... removing ansible.cfg
... removing hosts.yml
... removing directory tree group_vars
... removing directory tree host_vars
... removing netlab.snapshot.yml

(wsl)&amp;lt;&amp;lt;· tree .
.
└── topology.yml&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="base-topology---complete"&gt;&lt;span&gt;Base Topology - Complete&lt;/span&gt;
 &lt;a href="#base-topology---complete" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Here is the complete basic topology file with adding some extra quirks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;provider: clab
defaults:
  device: iol
  devices.iol.clab.image: vrnetlab/cisco_iol:17.12.1
  devices.linux.clab.image: ghcr.io/srl-labs/network-multitool
  providers.clab.lab_prefix: &amp;#34;&amp;#34;
  groups._auto_create: True
  paths.append.custom.dirs: [ templates ]
  vrf.as: 65515
 
groups:
  core:
    members: [ rc1, rc2, rc3, rc4 ]
    module: [ ospf, bgp, mpls, vrf ]
    bgp.as: 65515
    mpls.vpn: [ ibgp ]
    vrf.loopback: true
    config: [ core_extras ]
  ces:
    members: [ ce1, ce2, ce3, ce4 ]
    module: [ bgp ]
  pcs:
    members: [ pc1, pc2, pc3, pc4, pc11, pc12, pc13, pc14 ]
    device: linux
    config: [ iperf3_server ]
    vars:
      IPERF3_TESTS: [
                { &amp;#34;src&amp;#34;:&amp;#34;pc1&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc4&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc2&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc1&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc3&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc2&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc4&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc3&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc1&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc3&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5202&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc2&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc4&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5202&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc11&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc14&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc14&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc11&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc12&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc13&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
                { &amp;#34;src&amp;#34;:&amp;#34;pc13&amp;#34;, &amp;#34;dst&amp;#34;: &amp;#34;pc12&amp;#34;, &amp;#34;port&amp;#34;: &amp;#34;5201&amp;#34; },
      ]        
vrfs:
  blue:
    rd: &amp;#39;65515:101&amp;#39;
nodes:
  rc1:
  rc2:
    vrfs:
      red:
       rd: &amp;#34;10.0.0.2:102&amp;#34;
       import: &amp;#39;65515:102&amp;#39;
       export: &amp;#39;65515:102&amp;#39;
  rc3:
    vrfs:
      red:
       rd: &amp;#34;10.0.0.3:102&amp;#34;
       import: &amp;#39;65515:102&amp;#39;
       export: &amp;#39;65515:102&amp;#39;
  rc4:
  ce1:
    id: 11
    bgp.as: 65101
  ce2:
    id: 12
    bgp.as: 65201
  ce3:
    id: 13
    bgp.as: 65202
  ce4:
    id: 14
    bgp.as: 65102
 
links:
  - rc1-rc2
  - rc1-rc3
  - rc2-rc4
  - rc3-rc4
  - rc1-pc1
  - rc2-pc2
  - rc3-pc3
  - rc4-pc4
  - rc1: { vrf: blue }
    ce1:
  - rc2: { vrf: red }
    ce2:
  - rc3: { vrf: red }
    ce3:
  - rc4: { vrf: blue }
    ce4:
  - ce1-pc11
  - ce2-pc12
  - ce3-pc13
  - ce4-pc14&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;OK, we have now added some things or two here that we will expand on.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all, we have used the &lt;code&gt;groups&lt;/code&gt; section to group our nodes and apply attributes to them rather than having to replicate them for each one in the &lt;code&gt;nodes&lt;/code&gt; section.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;groups._auto_create: True&lt;/code&gt; allows for not having to define each node under the node section and create them ad-hoc from the members list under the &lt;code&gt;groups&lt;/code&gt;, but this does not guarantee the &lt;code&gt;id&lt;/code&gt; each node will have. Since the addressing considers those &lt;code&gt;id's&lt;/code&gt; and the order of specifying them under the &lt;code&gt;nodes&lt;/code&gt; section matters, we can have a mix of those two ways to auto-define nodes and also pin some to specific &lt;code&gt;ids&lt;/code&gt;. So rc&amp;rsquo;s get 1 to 4, ce&amp;rsquo;s 11 to 14 and for pc&amp;rsquo;s we don&amp;rsquo;t care.&lt;/li&gt;
&lt;li&gt;The desired protocols to be enabled on each node is done via the &lt;code&gt;module&lt;/code&gt; structure.&lt;/li&gt;
&lt;li&gt;We have used the &lt;code&gt;defaults.providers.clab.lab_prefix: &amp;quot;&amp;quot;&lt;/code&gt; in order for the containers not to include the default &lt;code&gt;clab-&amp;lt;directoty&amp;gt;&lt;/code&gt; prefix in their name.&lt;/li&gt;
&lt;li&gt;We are using jinja templates to provision additional commands to the nodes during start up and we define them in the &lt;code&gt;config&lt;/code&gt; section of our &lt;code&gt;groups&lt;/code&gt; definition. I have all my templates under a &lt;code&gt;templates&lt;/code&gt; folder in the directory structure, so we need a way to let &lt;em&gt;netlab&lt;/em&gt; &lt;em&gt;know&lt;/em&gt; where to search for them. This is done by the &lt;code&gt;defaults.paths.append.custom.dirs: [ templates ]&lt;/code&gt; key.&lt;/li&gt;
&lt;li&gt;For core devices, we are enabling dns server on them via the &lt;code&gt;core_extras&lt;/code&gt; template&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· cat templates/core_extras.j2
{# Enable DNS server in both GRT and mgmt vrf #}
!
ip dns server
ip dns view vrf clab-mgmt
!&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For the PCs, we want them to run &lt;em&gt;iperf3&lt;/em&gt; as server and also have the ability to start and stop traffic generation after the lab is up. So here, we have defined all the tests in a structure as a variable, that we can decompose in jinja to get either the server ports that need to be listening on, or the actual client tests to be performed. The server template is executed during bring up and for each PC we are looking to listen to all target ports:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;{% for test in IPERF3_TESTS %}{% if test.dst == hostname %}
iperf3 -s -p {{ test.port }} -D
{% endif %}{% endfor %}```&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For the client tests we use the &lt;code&gt;netlab config&lt;/code&gt; command to render the template ad-hoc and run or stop the tests after the topology is brought up:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;{% if ACTION is not defined or ACTION not in [&amp;#39;run&amp;#39;,&amp;#39;stop&amp;#39;] %}
 {{_|mandatory(&amp;#34;ACTION is mandatoy - run or stop&amp;#34;)}}
{% elif ACTION == &amp;#34;run&amp;#34; %}
{% for test in IPERF3_TESTS %}{% if test.src == hostname %}
iperf3 -c {{ test.dst }} -p {{ test.port}} -t0 -P 5 -b 5M  &amp;gt; iperf-{{ test.dst }}.log &amp;amp;
{% endif %}{% endfor %}
{% elif ACTION == &amp;#34;stop&amp;#34; %}
ps aux | grep &amp;#39;iperf3 -c&amp;#39; | grep -v grep | awk &amp;#39;{print $2}&amp;#39; | xargs kill -9
{% endif %}&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;ANSIBLE_NOCOWS=1 netlab config iperf3_clients -l pc1 -e ACTION=run --check -v
&amp;lt; snipped &amp;gt; 

TASK [Process template /home/netlab/iol/templates/iperf3_clients.j2 for pc1] **********
ok: [pc1] =&amp;gt;
 msg: |-
 /home/netlab/iol/templates/iperf3_clients.j2 configuration for pc1
 =========================================
 iperf3 -c pc4 -p 5201 -t0 -P 5 -b 5M &amp;gt; iperf-pc4.log &amp;amp;
 iperf3 -c pc3 -p 5202 -t0 -P 5 -b 5M &amp;gt; iperf-pc3.log &amp;amp;

&amp;lt; snipped &amp;gt; &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We could be more granular here on the parallel streams, time, bandwidth or whatever else is required.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lastly, for the &lt;code&gt;vrf&lt;/code&gt; module, we wanted one VPN to use IPv4:Number format so we had to manually specify the RDs/RTs under the nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s issue a &lt;code&gt;netlab create&lt;/code&gt; first to check if we are syntactically correct or we missed some logic, and then bring it up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab create
[CREATED] provider configuration file: clab.yml
[MAPPED] clab_files/pc1/hosts to pc1:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc2/hosts to pc2:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc3/hosts to pc3:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc4/hosts to pc4:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc11/hosts to pc11:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc12/hosts to pc12:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc13/hosts to pc13:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc14/hosts to pc14:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[CREATED] transformed topology dump in YAML format in netlab.snapshot.yml
[GROUPS] group_vars for all
[GROUPS] group_vars for modules
[GROUPS] group_vars for custom_configs
[GROUPS] group_vars for iol
[HOSTS] host_vars for rc1
[HOSTS] host_vars for rc2
[HOSTS] host_vars for rc3
[HOSTS] host_vars for rc4
[HOSTS] host_vars for ce1
[HOSTS] host_vars for ce2
[HOSTS] host_vars for ce3
[HOSTS] host_vars for ce4
[GROUPS] group_vars for linux
[HOSTS] host_vars for pc1
[HOSTS] host_vars for pc2
[HOSTS] host_vars for pc3
[HOSTS] host_vars for pc4
[HOSTS] host_vars for pc11
[HOSTS] host_vars for pc12
[HOSTS] host_vars for pc13
[HOSTS] host_vars for pc14
[GROUPS] group_vars for pcs
[CREATED] minimized Ansible inventory hosts.yml
[CREATED] Ansible configuration file: ansible.cfg&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· ANSIBLE_NOCOWS=1 netlab up
&amp;lt; snipped &amp;gt;

PLAY RECAP ****************************************************************************************************************
ce1 : ok=25 changed=4 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce2 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce3 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce4 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
pc1 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc11 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc12 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc13 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc14 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc2 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc3 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc4 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
rc1 : ok=42 changed=7 unreachable=0 failed=0 skipped=8 rescued=0 ignored=0
rc2 : ok=42 changed=7 unreachable=0 failed=0 skipped=8 rescued=0 ignored=0
rc3 : ok=42 changed=7 unreachable=0 failed=0 skipped=8 rescued=0 ignored=0
rc4 : ok=42 changed=7 unreachable=0 failed=0 skipped=8 rescued=0 ignored=0

[SUCCESS] Lab devices configured

(wsl)&amp;lt;&amp;lt;· netlab status


┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ node ┃ device ┃ image ┃ mgmt IPv4 ┃ connection ┃ provider ┃ VM/container ┃ status ┃
┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ ce1 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.111 │ network_cli │ clab │ ce1 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ ce2 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.112 │ network_cli │ clab │ ce2 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ ce3 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.113 │ network_cli │ clab │ ce3 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ ce4 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.114 │ network_cli │ clab │ ce4 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc1 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.105 │ docker │ clab │ pc1 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc11 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.109 │ docker │ clab │ pc11 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc12 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.110 │ docker │ clab │ pc12 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc13 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.115 │ docker │ clab │ pc13 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc14 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.116 │ docker │ clab │ pc14 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc2 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.106 │ docker │ clab │ pc2 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc3 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.107 │ docker │ clab │ pc3 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ pc4 │ linux │ ghcr.io/srl-labs/network… │ 192.168.121.108 │ docker │ clab │ pc4 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ rc1 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.101 │ network_cli │ clab │ rc1 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ rc2 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.102 │ network_cli │ clab │ rc2 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ rc3 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.103 │ network_cli │ clab │ rc3 │ Up About a minute │
├──────┼────────┼───────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼───────────────────┤
│ rc4 │ iol │ vrnetlab/cisco_iol:17.12… │ 192.168.121.104 │ network_cli │ clab │ rc4 │ Up About a minute │
└──────┴────────┴───────────────────────────┴─────────────────┴─────────────┴──────────┴──────────────┴───────────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All our nodes are up and as you can see from their management IP, their &lt;code&gt;id's&lt;/code&gt; are following either the order of their definition in the topology file or the &lt;code&gt;id&lt;/code&gt; value defined for them.&lt;/p&gt;
&lt;h3 class="heading-element" id="service-containers"&gt;&lt;span&gt;Service Containers&lt;/span&gt;
 &lt;a href="#service-containers" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Let&amp;rsquo;s add now our additional containers based on our use case. We are going to be defining them in the topology as we did for our &lt;code&gt;PC's&lt;/code&gt;, but here we also need to pass some &lt;code&gt;env&lt;/code&gt; variables to them in order for &lt;em&gt;containerlab&lt;/em&gt; to bring them up properly. Some of these variables have common values for all but some have specific one&amp;rsquo;s. Hence, we are going to use the hierarchy to define them accordingly.&lt;/p&gt;
&lt;p&gt;Here is how the relevant &lt;code&gt;groups&lt;/code&gt; section looks like in the topology:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;groups:
 ksynth:
 members: [ ksynth1, ksynth2, ksynth3, ksynth4 ]
 device: linux
 clab:
 image: kentik/ksynth-agent:latest
 kentik:
 members: [ kproxy, kbgp, ksynth1, ksynth2, ksynth3, ksynth4 ]
 clab:
 env:
 KENTIK_COMPANY: &amp;lt; Kentik Company ID &amp;gt;
 KENTIK_REGION: EU
 KENTIK_API_TOKEN: &amp;lt; Kentik User Token &amp;gt;
 KENTIK_API_EMAIL: &amp;lt; Kentik User Email &amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here we have used one group to define the &lt;strong&gt;ksynth&lt;/strong&gt; agents that are based on the relevant image, and also, used the &lt;strong&gt;kentik&lt;/strong&gt; group to define the common variables that all the service containers need in order to communicate with Kentik.&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s look at the &lt;code&gt;nodes&lt;/code&gt; section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nodes:
 kproxy:
 device: linux
 clab:
 image: kentik/kproxy:latest
 cmd: &amp;gt;-
 -api_email=&amp;lt; Kentik kproxy agent email address &amp;gt;
 -region=EU
 -healthcheck=0.0.0.0
 -dns internal:192.168.121.101:53
 ksynth1:
 clab.binds:
 - mounts/ksynth1:/var/lib/ksynth-agent
 ksynth2:
 clab.binds:
 - mounts/ksynth2:/var/lib/ksynth-agent
 ksynth3:
 clab.binds:
 - mounts/ksynth3:/var/lib/ksynth-agent
 ksynth4:
 clab.binds:
 - mounts/ksynth4:/var/lib/ksynth-agent
 kbgp:
 device: linux
 clab:
 image: kentik/kbgp:latest
 env:
 KENTIK_REGION: fra1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here we can observe the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For &lt;strong&gt;kproxy&lt;/strong&gt;: We define the image and pass along the command line to be run on the container. All other &lt;code&gt;env&lt;/code&gt; variables defined in the &lt;code&gt;groups&lt;/code&gt; section are going to be available to the container as well. Unfortunately, I could not find a way to dynamically pass variables in the &lt;code&gt;clab.cmd&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;ksynth&lt;/strong&gt;: Since we want the agents to persist, we have to preserve the relevant directory across deployments, so we bind mount a local directory path for every instance. The relevant directories have to exist in our directory structure.&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;kbgp&lt;/strong&gt;: We specify the image and re-define the region variable to override the one defined in the &lt;code&gt;groups&lt;/code&gt; section since only &lt;strong&gt;kbgp&lt;/strong&gt; needs it to be like that.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also create the additional connections in our &lt;code&gt;links&lt;/code&gt; section:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;links:
 - rc1-ksynth1
 - rc2-ksynth2
 - rc3-ksynth3
 - rc4-ksynth4
 - rc1-kbgp&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, for our last agent that will be part of Kentik NMS, we are going to bring this up as a standalone container not controlled via &lt;em&gt;netlab&lt;/em&gt;, and here is how the &lt;em&gt;compose&lt;/em&gt; file looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;services:
 kagent:
 container_name: kagent
 hostname: iol_kagent
 image: kentik/kagent:latest
 restart: unless-stopped
 network_mode: host
 environment:
 K_COMPANY_ID: &amp;lt; Kentik Company ID &amp;gt;
 K_API_ROOT: grpc.api.kentik.eu:443
 cap_add:
 - NET_RAW
 volumes:
 - kagent-data:/opt/kentik

volumes:
 kagent-data:
 driver: local&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Two points here worth exploring:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;kagent&lt;/strong&gt; is not part of the topology since currently there is no way to pass the capability to &lt;em&gt;containerlab&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The agent is going to poll the devices for SNMP so connectivity wise, this works by default since both agent network (host) and topology management networks are on the same host (WSL)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, this seems the case also for the &lt;strong&gt;kproxy&lt;/strong&gt; container, but here, &lt;em&gt;netlab&lt;/em&gt; is going to need its&amp;rsquo; IP address in order to add additional configuration to the devices exporting flows as we are going to see in the following paragraphs.&lt;/p&gt;
&lt;p&gt;One last part to cover here is the fact that we have to provision our network devices accordingly in order to be ready to integrate with Kentik. This means that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;They need to be sending netflow to &lt;strong&gt;kproxy&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;They need to have snmp enabled in order to be polled by &lt;strong&gt;kproxy&lt;/strong&gt; and &lt;strong&gt;kagent&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;They need to be peering with &lt;strong&gt;kbgp&lt;/strong&gt; in order to send their BGP tables to Kentik&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Well, it seems as a usual case of templating configurations and passing them on to devices via &lt;em&gt;netlab&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For the snmp part, we just re-use our &lt;code&gt;core-extras&lt;/code&gt; template to add the config:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt; snipped &amp;gt;
{# Enable SNMP #}
!
snmp-server ifindex persist
snmp-server community {{ KENTIK_SNMPV2_COMMUNITY }}
!&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For the netflow part, IOL supports a feature called Flexible netflow and can do v9 and ipfix as well as standard netflow v9 exports. I have seen that with Flexible netflow configuration, there is no way to configure the active cache settings and we need this to be 1 min. for Kentik. In any case, here are the respective templates for all three variations of the netflow configurations needed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{% if ACTION is not defined or ACTION not in [&amp;#39;push&amp;#39;,&amp;#39;remove&amp;#39;] %}
{{_|mandatory(&amp;#34;ACTION is mandatoy - push or remove&amp;#34;)}}
{% elif ACTION == &amp;#34;remove&amp;#34; %}
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 no flow-sampler KENTIK
 !
!
no ip flow-export source Ethernet0/0
no ip flow-export version 9 origin-as bgp-nexthop
no ip flow-export template options sampler
no ip flow-export template timeout-rate
no ip flow-export template refresh-rate
no ip flow-export destination {{ hostvars[&amp;#39;kproxy&amp;#39;][&amp;#39;mgmt&amp;#39;][&amp;#39;ipv4&amp;#39;] }} 9995 vrf clab-mgmt
no flow-sampler-map KENTIK
no ip flow-cache timeout inactive
no ip flow-cache timeout active
!
{% elif ACTION == &amp;#34;push&amp;#34; %}
!
ip flow-cache timeout inactive 30
ip flow-cache timeout active 1
!
flow-sampler-map KENTIK
 mode random one-out-of {{ KENTIK_SAMPLE_RATE }}
!
ip flow-export source Ethernet0/0
ip flow-export version 9 origin-as bgp-nexthop
ip flow-export template options sampler
ip flow-export template timeout-rate 1
ip flow-export template refresh-rate 50
ip flow-export destination {{ hostvars[&amp;#39;kproxy&amp;#39;][&amp;#39;mgmt&amp;#39;][&amp;#39;ipv4&amp;#39;] }} 9995 vrf clab-mgmt
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 flow-sampler KENTIK
!
{% endif %}&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;{% if ACTION is not defined or ACTION not in [&amp;#39;push&amp;#39;,&amp;#39;remove&amp;#39;] %}
 {{_|mandatory(&amp;#34;ACTION is mandatoy - push or remove&amp;#34;)}}
{% elif ACTION == &amp;#34;remove&amp;#34; %}
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 no ip flow monitor KENTIK sampler KENTIK input
 !
!
no sampler KENTIK
no flow monitor KENTIK
no flow exporter KENTIK
no flow record KENTIK
!
{% elif ACTION == &amp;#34;push&amp;#34; %}
!
flow record KENTIK
 match routing vrf input
 match ipv4 tos
 match ipv4 protocol
 match ipv4 source address
 match ipv4 destination address
 match transport source-port
 match transport destination-port
 match interface input
 collect routing source as
 collect routing destination as
 collect routing next-hop address ipv4
 collect transport tcp flags
 collect interface output
 collect counter bytes
 collect counter packets
 collect timestamp sys-uptime first
 collect timestamp sys-uptime last
!
flow exporter KENTIK
 destination {{ hostvars[&amp;#39;kproxy&amp;#39;][&amp;#39;mgmt&amp;#39;][&amp;#39;ipv4&amp;#39;] }} vrf clab-mgmt
 source Ethernet0/0
 transport udp 9995
 export-protocol netflow-v9
 template data timeout 60
 option interface-table
 option vrf-table
 option sampler-table
!
flow monitor KENTIK
 exporter KENTIK
 statistics packet protocol
 statistics packet size
 record KENTIK
!
sampler KENTIK
 mode random 1 out-of {{ KENTIK_SAMPLE_RATE }}
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 ip flow monitor KENTIK sampler KENTIK input
!
{% endif %}&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;{% if ACTION is not defined or ACTION not in [&amp;#39;push&amp;#39;,&amp;#39;remove&amp;#39;] %}
 {{_|mandatory(&amp;#34;ACTION is mandatoy - push or remove&amp;#34;)}}
{% elif ACTION == &amp;#34;remove&amp;#34; %}
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 no ip flow monitor KENTIK sampler KENTIK input
 !
!
no sampler KENTIK
no flow monitor KENTIK
no flow exporter KENTIK
no flow record KENTIK
!
{% elif ACTION == &amp;#34;push&amp;#34; %}
!
flow record KENTIK
 match routing vrf input
 match ipv4 tos
 match ipv4 protocol
 match ipv4 source address
 match ipv4 destination address
 match transport source-port
 match transport destination-port
 match interface input
 collect routing source as
 collect routing destination as
 collect routing next-hop address ipv4
 collect transport tcp flags
 collect interface output
 collect counter bytes
 collect counter packets
 collect timestamp sys-uptime first
 collect timestamp sys-uptime last
!
flow exporter KENTIK
 destination {{ hostvars[&amp;#39;kproxy&amp;#39;][&amp;#39;mgmt&amp;#39;][&amp;#39;ipv4&amp;#39;] }} vrf clab-mgmt
 source Ethernet0/0
 transport udp 9995
 export-protocol ipfix
 template data timeout 60
 option interface-table
 option vrf-table
 option sampler-table
!
flow monitor KENTIK
 exporter KENTIK
 statistics packet protocol
 statistics packet size
 record KENTIK
!
sampler KENTIK
 mode random 1 out-of {{ KENTIK_SAMPLE_RATE }}
!
interface range {% for interface in netlab_interfaces if interface.type != &amp;#39;loopback&amp;#39; -%}
{{ interface.ifname &amp;#43; &amp;#34; , &amp;#34; if not loop.last else interface.ifname }}{% endfor %}
 ip flow monitor KENTIK sampler KENTIK input
!
{% endif %}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All three templates include the respective &lt;em&gt;no&lt;/em&gt; statements so you can provision them via the &lt;code&gt;netlab config&lt;/code&gt; command and switch between them on the devices.&lt;/p&gt;
&lt;p&gt;Now, last but not least, we have the BGP configuration. Kentik acts as a route reflector and we peer with the enabled address families via &lt;strong&gt;kbgp&lt;/strong&gt; to send both tables from each device.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!
ip prefix-list PL_HOSTS seq 5 permit 0.0.0.0/0 ge 32
ip prefix-list PL_DEFAULT seq 5 permit 0.0.0.0/0
!
route-map RM_KENTIK_IN permit 5
 match ip address prefix-list PL_HOSTS
!
route-map RM_KENTIK_OUT deny 5
 match ip address prefix-list PL_DEFAULT
!
route-map RM_KENTIK_OUT permit 10
 set community {{ bgp.as }}:{{ id*100 }} additive
 set extcommunity color {{ id&amp;#43;10 }} additive
!
route-map RM_IBGP_OUT permit 5
 set community {{ bgp.as }}:{{ id*100 }} additive
 set extcommunity color {{ id&amp;#43;10 }} additive
!
router bgp {{ bgp.as }}
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} remote-as {{ bgp.as }}
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} description KENTIK
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} update-source {{ loopback.ifname }}
!
address-family ipv4
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} activate
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} route-reflector-client
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} route-map RM_KENTIK_IN in
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} route-map RM_KENTIK_OUT out
{% for nei in bgp.neighbors if nei.type == &amp;#39;ibgp&amp;#39; %}
 neighbor {{ nei.ipv4 }} route-map RM_IBGP_OUT out
{% endfor %}
!
address-family vpnv4
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} activate
 neighbor {{ hosts[&amp;#39;kbgp&amp;#39;][&amp;#39;ipv4&amp;#39;][0] }} route-reflector-client
!&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The BGP template is provisioned to the devices during lab bring up, so it is defined in the &lt;code&gt;config&lt;/code&gt; section of the core devices.&lt;/p&gt;
&lt;p&gt;You see now how we can leverage the ansible variables available to us to produce the appropriate configuration. So we define those &lt;em&gt;additional&lt;/em&gt; variables in our topology file in the appropriate section.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;groups:
 core:
 members: [ rc1, rc2, rc3, rc4 ]
 module: [ ospf, bgp, mpls, vrf ]
 bgp.as: 65515
 mpls.vpn: [ ibgp ]
 vrf.loopback: true
 config: [ core_extras, kentik_rrc ]
 vars:
 KENTIK_SNMPV2_COMMUNITY: &amp;lt; snmpv2 community &amp;gt;
 KENTIK_SAMPLE_RATE: 10
 KENTIK_REGION: EU
 KENTIK_PLAN_ID: &amp;lt; Flow Plan for devices &amp;gt;
 KENTIK_SITE_ID: &amp;lt; Site to use for the devices &amp;gt;
 KENTIK_NMS_AGENT_ID: &amp;lt; NMS agent to use for polling devices &amp;gt;
 KENTIK_NMS_CREDS_NAME: &amp;lt; Credentials vault name &amp;gt;
 KENTIK_API_TOKEN: &amp;lt; Kentik User Token &amp;gt;
 KENTIK_API_EMAIL: &amp;lt; Kentik User Email &amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We have defined some additional variables here that we do not use during &lt;em&gt;netlab&lt;/em&gt; normal operations. The reason for this is that since &lt;em&gt;netlab&lt;/em&gt; will create a full ansible structure for the lab, we can re-use this to run our own plays based on the inventory that &lt;em&gt;netlab&lt;/em&gt; created. More on this in our next section.&lt;/p&gt;
&lt;h2 class="heading-element" id="topology-bring-up-workflow"&gt;&lt;span&gt;Topology Bring-Up Workflow&lt;/span&gt;
 &lt;a href="#topology-bring-up-workflow" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;In this section we will cover the steps needed to bring up the LAB and start with our use-case. In a high-level here are the steps needed to accomplish this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Register the NMS agent&lt;/li&gt;
&lt;li&gt;Register the networking devices in the portal&lt;/li&gt;
&lt;li&gt;Bring Up the LAB&lt;/li&gt;
&lt;li&gt;Enable the desired netflow export&lt;/li&gt;
&lt;li&gt;Enable traffic&lt;/li&gt;
&lt;li&gt;Register the ksynth agents&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition, here are the additional variables we are using in the topology file along with their description and their requirement for the above steps&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;VARIABLE&lt;/th&gt;
 &lt;th&gt;USED IN&lt;/th&gt;
 &lt;th&gt;DESCRIPTION&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_SNMPV2_COMMUNITY&lt;/td&gt;
 &lt;td&gt;2,3&lt;/td&gt;
 &lt;td&gt;SNMPv2 community used to poll the devices&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_SAMPLE_RATE&lt;/td&gt;
 &lt;td&gt;2,4&lt;/td&gt;
 &lt;td&gt;Netflow sample rate configured on the devices and in the portal&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_REGION&lt;/td&gt;
 &lt;td&gt;2,3&lt;/td&gt;
 &lt;td&gt;Portal Account region - US or EU&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_PLAN_ID&lt;/td&gt;
 &lt;td&gt;2&lt;/td&gt;
 &lt;td&gt;Portal flow plan to put the devices in&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_SITE_ID&lt;/td&gt;
 &lt;td&gt;2&lt;/td&gt;
 &lt;td&gt;Portal site to put the devices in&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_NMS_AGENT_ID&lt;/td&gt;
 &lt;td&gt;2&lt;/td&gt;
 &lt;td&gt;NMS agent to poll the devices&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_NMS_CREDS_NAME&lt;/td&gt;
 &lt;td&gt;2&lt;/td&gt;
 &lt;td&gt;Portal credential vault having the snmp community&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_API_TOKEN&lt;/td&gt;
 &lt;td&gt;2,3&lt;/td&gt;
 &lt;td&gt;Portal API token to authenticate to Kentik&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;KENTIK_API_EMAIL&lt;/td&gt;
 &lt;td&gt;2,3&lt;/td&gt;
 &lt;td&gt;Portal Email account to authenticate to Kentik&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;IPERF3_TESTS&lt;/td&gt;
 &lt;td&gt;3,5&lt;/td&gt;
 &lt;td&gt;List of dictionaries describing the iperf3 tests&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 class="heading-element" id="1-register-nms-agent"&gt;&lt;span&gt;1. Register NMS Agent&lt;/span&gt;
 &lt;a href="#1-register-nms-agent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;This an once-off action and it is decoupled from &lt;em&gt;netlab&lt;/em&gt;. We just need to run the &lt;strong&gt;kagent&lt;/strong&gt; and register it in the portal. This will allow us to get the &lt;code&gt;AGENT_ID&lt;/code&gt; for the next step.&lt;/p&gt;
&lt;p&gt;So, using the docker compose we bring up the agent and then access the portal to activate it and get the ID.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· docker compose up -d
[&amp;#43;] Running 2/2
 ✔ Volume &amp;#34;iol_kagent-data&amp;#34; Created 0.0s
 ✔ Container kagent Started 0.2s&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In addition we can assign the agent to an existing site or create a new one in the portal that we will use for our LAB. This will also give us the &lt;code&gt;SITE_ID&lt;/code&gt; variable for the next step.&lt;/p&gt;
&lt;h3 class="heading-element" id="2-register-devices-in-the-portal"&gt;&lt;span&gt;2. Register Devices in the Portal&lt;/span&gt;
 &lt;a href="#2-register-devices-in-the-portal" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;This is again an once-off task and we could do it manually, but since &lt;em&gt;netlab&lt;/em&gt; is able to give us an ansible inventory structure out of the topology file we can use this and create the devices via Kentik&amp;rsquo;s device API in our own playbook.&lt;/p&gt;
&lt;p&gt;Here is a playbook that accomplishes this task:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
- name: &amp;#34;Kentik Device Onboarding&amp;#34;
 hosts: core
 gather_facts: false
 vars:
 KENTIK_API_URL: &amp;#34;https://grpc.api.kentik.{{ KENTIK_REGION|lower }}&amp;#34;
 KENTIK_DEVICE_API: &amp;#34;{{ KENTIK_API_URL }}/device/v202308beta1/device/&amp;#34;
 KENTIK_HEADERS: 
 X-CH-Auth-API-Token: &amp;#34;{{ KENTIK_API_TOKEN }}&amp;#34;
 X-CH-Auth-Email: &amp;#34;{{ KENTIK_API_EMAIL }}&amp;#34;
 Content-Type: application/json
 tasks:
 - name: Get Current Devices
 uri:
 url: &amp;#34;{{ KENTIK_DEVICE_API }}&amp;#34;
 method: GET
 headers: &amp;#34;{{ KENTIK_HEADERS }}&amp;#34;
 status_code: 200
 register: devices 
 delegate_to: localhost
 run_once: true
 
 - name: Skipped Devices
 debug:
 msg: &amp;#34;Device name or IP addresses already existed in portal&amp;#34;
 when: 
 - &amp;#34;netlab_name&amp;#43;&amp;#39;-&amp;#39;&amp;#43;hostname in devices.json | json_query(&amp;#39;devices[].deviceName&amp;#39;)
 or mgmt.ipv4 in devices.json | json_query(&amp;#39;devices[].sendingIps[]&amp;#39;)
 or bgp.router_id in devices.json | json_query(&amp;#39;devices[].deviceBgpNeighborIp&amp;#39;)&amp;#34;
 delegate_to: localhost


 - name: Create Device OR Skip If Exists
 block:
 - name: Create Device Call
 ansible.builtin.uri:
 url: &amp;#34;{{ KENTIK_DEVICE_API }}&amp;#34;
 method: POST
 headers: &amp;#34;{{ KENTIK_HEADERS }}&amp;#34;
 status_code: 200
 body: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.template&amp;#39;,&amp;#39;templates/kentik_device.j2&amp;#39;) }}&amp;#34;
 body_format: json
 timeout: 60
 register: device_created
 throttle: 1
 - name: Devices Created
 debug: 
 msg: &amp;#34;Device created with id: {{ device_created.json.device.id }}&amp;#34;
 rescue:
 - name: Cannot Create Device
 debug:
 msg: &amp;#34;Failed to create device: {{ device_created.json.message }}&amp;#34;
 when: 
 - &amp;#34;netlab_name&amp;#43;&amp;#39;-&amp;#39;&amp;#43;hostname not in devices.json | json_query(&amp;#39;devices[].deviceName&amp;#39;)&amp;#34;
 - &amp;#34;mgmt.ipv4 not in devices.json | json_query(&amp;#39;devices[].sendingIps[]&amp;#39;)&amp;#34;
 - &amp;#34;bgp.router_id not in devices.json | json_query(&amp;#39;devices[].deviceBgpNeighborIp&amp;#39;)&amp;#34;
 delegate_to: localhost
 &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We are using the built in &lt;code&gt;uri&lt;/code&gt; module to interact with the API and create the devices we are interested in, i.e. the &lt;code&gt;core&lt;/code&gt; devices. The playbook will check if there is any existing device with the same name or having any relevant IP that we use in our LAB, and if not it will create the device in the portal.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;json&lt;/em&gt; payload is templated and looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
 &amp;#34;device&amp;#34;: {
 &amp;#34;deviceName&amp;#34;: &amp;#34;{{ netlab_name }}-{{ hostname }}&amp;#34;,
 &amp;#34;deviceDescription&amp;#34;: &amp;#34;Device {{ id }} of type {{ netlab_device_type}} using {{ netlab_provider}} provider.&amp;#34;,
 &amp;#34;deviceSubtype&amp;#34;: &amp;#34;router&amp;#34;,
 &amp;#34;sendingIps&amp;#34;: [
 &amp;#34;{{ mgmt.ipv4}}&amp;#34;
 ],
 &amp;#34;deviceSampleRate&amp;#34;: &amp;#34;{{ KENTIK_SAMPLE_RATE }}&amp;#34;,
 &amp;#34;planId&amp;#34;: {{ KENTIK_PLAN_ID }},
 &amp;#34;siteId&amp;#34;: {{ KENTIK_SITE_ID }},
 &amp;#34;minimizeSnmp&amp;#34;: false,
 &amp;#34;deviceSnmpIp&amp;#34;: &amp;#34;{{ mgmt.ipv4}}&amp;#34;,
 &amp;#34;deviceSnmpCommunity&amp;#34;: &amp;#34;{{ KENTIK_SNMPV2_COMMUNITY }}&amp;#34;,
 &amp;#34;deviceBgpType&amp;#34;: &amp;#34;device&amp;#34;,
 &amp;#34;deviceBgpNeighborIp&amp;#34;: &amp;#34;{{ bgp.router_id }}&amp;#34;,
 &amp;#34;deviceBgpNeighborAsn&amp;#34;: &amp;#34;{{ bgp.as }}&amp;#34;,
 &amp;#34;nms&amp;#34;: {
 &amp;#34;agentId&amp;#34;: &amp;#34;{{ KENTIK_NMS_AGENT_ID }}&amp;#34;,
 &amp;#34;ipAddress&amp;#34;: &amp;#34;{{ mgmt.ipv4 }}&amp;#34;,
 &amp;#34;snmp&amp;#34;: {
 &amp;#34;credentialName&amp;#34;: &amp;#34;{{ KENTIK_NMS_CREDS_NAME }}&amp;#34;,
 },
 }
 }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we are going to need to provide the remaining values for the variables used in our topology file and once all variables are filled in, we can execute the &lt;code&gt;netlab create&lt;/code&gt; command in order for the ansible inventory to be produced.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab create
[CREATED] provider configuration file: clab.yml
[MAPPED] clab_files/kproxy/hosts to kproxy:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/ksynth1/hosts to ksynth1:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/ksynth2/hosts to ksynth2:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/ksynth3/hosts to ksynth3:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/ksynth4/hosts to ksynth4:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/kbgp/hosts to kbgp:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc1/hosts to pc1:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc2/hosts to pc2:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc3/hosts to pc3:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc4/hosts to pc4:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc11/hosts to pc11:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc12/hosts to pc12:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc13/hosts to pc13:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[MAPPED] clab_files/pc14/hosts to pc14:/etc/hosts (from templates/provider/clab/linux/hosts.j2)
[CREATED] transformed topology dump in YAML format in netlab.snapshot.yml
[GROUPS] group_vars for all
[GROUPS] group_vars for modules
[GROUPS] group_vars for custom_configs
[GROUPS] group_vars for iol
[HOSTS] host_vars for rc1
[HOSTS] host_vars for rc2
[HOSTS] host_vars for rc3
[HOSTS] host_vars for rc4
[HOSTS] host_vars for ce1
[HOSTS] host_vars for ce2
[HOSTS] host_vars for ce3
[HOSTS] host_vars for ce4
[GROUPS] group_vars for linux
[HOSTS] host_vars for kproxy
[HOSTS] host_vars for ksynth1
[HOSTS] host_vars for ksynth2
[HOSTS] host_vars for ksynth3
[HOSTS] host_vars for ksynth4
[HOSTS] host_vars for kbgp
[HOSTS] host_vars for pc1
[HOSTS] host_vars for pc2
[HOSTS] host_vars for pc3
[HOSTS] host_vars for pc4
[HOSTS] host_vars for pc11
[HOSTS] host_vars for pc12
[HOSTS] host_vars for pc13
[HOSTS] host_vars for pc14
[GROUPS] group_vars for core
[GROUPS] group_vars for pcs
[CREATED] minimized Ansible inventory hosts.yml
[CREATED] Ansible configuration file: ansible.cfg&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we can run our playbook to onboard the core devices into Kentik.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· ANSIBLE_NOCOWS=1 ansible-playbook kentik.yml

PLAY [Kentik Device Onboarding] *******************************************************************************************

TASK [Get Current Devices] ************************************************************************************************
ok: [rc1 -&amp;gt; localhost]

TASK [Skipped Devices] ****************************************************************************************************
skipping: [rc1]
skipping: [rc2]
skipping: [rc3]
skipping: [rc4]

TASK [Create Device Call] *************************************************************************************************
ok: [rc1 -&amp;gt; localhost]
ok: [rc2 -&amp;gt; localhost]
ok: [rc3 -&amp;gt; localhost]
ok: [rc4 -&amp;gt; localhost]

TASK [Devices Created] ****************************************************************************************************
ok: [rc1 -&amp;gt; localhost] =&amp;gt;
 msg: &amp;#39;Device created with id: 115531&amp;#39;
ok: [rc2 -&amp;gt; localhost] =&amp;gt;
 msg: &amp;#39;Device created with id: 115536&amp;#39;
ok: [rc3 -&amp;gt; localhost] =&amp;gt;
 msg: &amp;#39;Device created with id: 115541&amp;#39;
ok: [rc4 -&amp;gt; localhost] =&amp;gt;
 msg: &amp;#39;Device created with id: 115546&amp;#39;

PLAY RECAP ****************************************************************************************************************
rc1 : ok=3 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0
rc2 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0
rc3 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0
rc4 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="3-bring-up-the-lab"&gt;&lt;span&gt;3. Bring Up the LAB&lt;/span&gt;
 &lt;a href="#3-bring-up-the-lab" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;We are ready now to bring up the topology. We have seen that during &lt;code&gt;netlab create&lt;/code&gt; &lt;em&gt;netlab&lt;/em&gt; will create the required &lt;em&gt;containerlab&lt;/em&gt; topology file and populate our ansible inventory with the appropriate files and values. Using the &lt;code&gt;netlab up&lt;/code&gt; command it will execute the create phase as well as spin up the nodes and start provisioning them with the appropriate configurations we defined in the topology file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· ANSIBLE_NOCOWS=1 netlab up

&amp;lt; snipped &amp;gt;

PLAY RECAP ****************************************************************************************************************
ce1 : ok=25 changed=4 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce2 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce3 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
ce4 : ok=24 changed=3 unreachable=0 failed=0 skipped=14 rescued=0 ignored=0
kbgp : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
kproxy : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
ksynth1 : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
ksynth2 : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
ksynth3 : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
ksynth4 : ok=11 changed=3 unreachable=0 failed=0 skipped=2 rescued=0 ignored=0
pc1 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc11 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc12 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc13 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc14 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc2 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc3 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
pc4 : ok=19 changed=5 unreachable=0 failed=0 skipped=5 rescued=0 ignored=0
rc1 : ok=48 changed=8 unreachable=0 failed=0 skipped=11 rescued=0 ignored=0
rc2 : ok=48 changed=8 unreachable=0 failed=0 skipped=11 rescued=0 ignored=0
rc3 : ok=48 changed=8 unreachable=0 failed=0 skipped=11 rescued=0 ignored=0
rc4 : ok=48 changed=8 unreachable=0 failed=0 skipped=11 rescued=0 ignored=0

[SUCCESS] Lab devices configured

(wsl)&amp;lt;&amp;lt;· netlab status
Lab default in /home/netlab/iol
 status: started
 provider(s): clab

┏━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ node ┃ device ┃ image ┃ mgmt IPv4 ┃ connection ┃ provider ┃ VM/container ┃ status ┃
┡━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩
│ ce1 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.111 │ network_cli │ clab │ ce1 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ce2 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.112 │ network_cli │ clab │ ce2 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ce3 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.113 │ network_cli │ clab │ ce3 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ce4 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.114 │ network_cli │ clab │ ce4 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ kbgp │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.110 │ docker │ clab │ kbgp │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ kproxy │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.105 │ docker │ clab │ kproxy │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ksynth1 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.106 │ docker │ clab │ ksynth1 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ksynth2 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.107 │ docker │ clab │ ksynth2 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ksynth3 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.108 │ docker │ clab │ ksynth3 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ ksynth4 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.109 │ docker │ clab │ ksynth4 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc1 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.115 │ docker │ clab │ pc1 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc11 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.119 │ docker │ clab │ pc11 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc12 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.120 │ docker │ clab │ pc12 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc13 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.121 │ docker │ clab │ pc13 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc14 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.122 │ docker │ clab │ pc14 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc2 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.116 │ docker │ clab │ pc2 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc3 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.117 │ docker │ clab │ pc3 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ pc4 │ linux │ ghcr.io/srl-labs/network-m… │ 192.168.121.118 │ docker │ clab │ pc4 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc1 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.101 │ network_cli │ clab │ rc1 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc2 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.102 │ network_cli │ clab │ rc2 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc3 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.103 │ network_cli │ clab │ rc3 │ Up 3 minutes │
├─────────┼────────┼─────────────────────────────┼─────────────────┼─────────────┼──────────┼──────────────┼──────────────┤
│ rc4 │ iol │ vrnetlab/cisco_iol:17.12.1 │ 192.168.121.104 │ network_cli │ clab │ rc4 │ Up 3 minutes │
└─────────┴────────┴─────────────────────────────┴─────────────────┴─────────────┴──────────┴──────────────┴──────────────┘&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here are some connectivity tests and also notice the bitrates:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab exec pc1 iperf3 -c pc4
Connecting to container pc1, executing iperf3 -c pc4
Connecting to host pc4, port 5201
[ 5] local 172.16.0.15 port 42090 connected to 172.16.3.18 port 5201
[ ID] Interval Transfer Bitrate Retr Cwnd
[ 5] 0.00-1.00 sec 32.5 MBytes 273 Mbits/sec 498 14.1 KBytes
[ 5] 1.00-2.00 sec 30.1 MBytes 252 Mbits/sec 457 14.1 KBytes
[ 5] 2.00-3.00 sec 30.7 MBytes 258 Mbits/sec 475 12.7 KBytes
[ 5] 3.00-4.00 sec 28.0 MBytes 235 Mbits/sec 438 14.1 KBytes
[ 5] 4.00-5.00 sec 29.4 MBytes 247 Mbits/sec 458 14.1 KBytes
[ 5] 5.00-6.00 sec 29.8 MBytes 250 Mbits/sec 483 8.46 KBytes
[ 5] 6.00-7.00 sec 28.5 MBytes 239 Mbits/sec 494 22.6 KBytes
[ 5] 7.00-8.00 sec 28.4 MBytes 239 Mbits/sec 537 11.3 KBytes
[ 5] 8.00-9.00 sec 25.2 MBytes 212 Mbits/sec 410 14.1 KBytes
[ 5] 9.00-10.00 sec 24.0 MBytes 201 Mbits/sec 476 14.1 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval Transfer Bitrate Retr
[ 5] 0.00-10.00 sec 287 MBytes 241 Mbits/sec 4726 sender
[ 5] 0.00-10.00 sec 286 MBytes 240 Mbits/sec receiver

iperf Done.

(wsl)&amp;lt;&amp;lt;· netlab exec pc11 iperf3 -c pc14
Connecting to container pc11, executing iperf3 -c pc14
Connecting to host pc14, port 5201
[ 5] local 172.16.9.19 port 43696 connected to 172.16.12.22 port 5201
[ ID] Interval Transfer Bitrate Retr Cwnd
[ 5] 0.00-1.00 sec 10.5 MBytes 88.2 Mbits/sec 259 14.1 KBytes
[ 5] 1.00-2.00 sec 10.5 MBytes 88.1 Mbits/sec 257 12.7 KBytes
[ 5] 2.00-3.00 sec 11.1 MBytes 93.3 Mbits/sec 243 14.1 KBytes
[ 5] 3.00-4.00 sec 10.6 MBytes 89.2 Mbits/sec 258 15.5 KBytes
[ 5] 4.00-5.00 sec 11.4 MBytes 95.4 Mbits/sec 254 12.7 KBytes
[ 5] 5.00-6.00 sec 10.5 MBytes 88.1 Mbits/sec 252 14.1 KBytes
[ 5] 6.00-7.00 sec 11.1 MBytes 93.3 Mbits/sec 233 14.1 KBytes
[ 5] 7.00-8.00 sec 12.0 MBytes 101 Mbits/sec 276 14.1 KBytes
[ 5] 8.00-9.00 sec 11.5 MBytes 96.4 Mbits/sec 214 19.7 KBytes
[ 5] 9.00-10.00 sec 11.4 MBytes 95.4 Mbits/sec 247 15.5 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval Transfer Bitrate Retr
[ 5] 0.00-10.00 sec 111 MBytes 92.8 Mbits/sec 2493 sender
[ 5] 0.00-10.00 sec 110 MBytes 92.6 Mbits/sec receiver

iperf Done.

(wsl)&amp;lt;&amp;lt;· netlab exec pc11 mtr pc14 -r
Connecting to container pc11, executing mtr pc14 -r
Start: 2024-12-07T18:02:20&amp;#43;0000
HOST: pc11 Loss% Snt Last Avg Best Wrst StDev
 1.|-- Ethernet0-2.ce1 0.0% 10 0.5 0.6 0.5 0.7 0.1
 2.|-- Ethernet1-2.blue.rc1 0.0% 10 0.7 1.2 0.7 1.8 0.4
 3.|-- Ethernet0-1.rc2 0.0% 10 2.2 3.0 2.2 3.6 0.4
 4.|-- Ethernet1-1.blue.rc4 0.0% 10 2.4 2.4 1.9 3.0 0.3
 5.|-- Ethernet0-1.ce4 0.0% 10 1.4 2.7 1.4 3.5 0.8
 6.|-- pc14 0.0% 10 1.5 2.6 1.5 3.9 0.8&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition tip open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-regular fa-lightbulb" aria-hidden="true"&gt;&lt;/i&gt;Tip&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;host resolution works by default since &lt;em&gt;netlab&lt;/em&gt; takes care of that by producing a &lt;code&gt;hosts&lt;/code&gt; file, attaching it into the linux containers, and provisions all hosts in the network devices as well. How cool is that!!!&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;h3 class="heading-element" id="4-enable-netflow"&gt;&lt;span&gt;4. Enable Netflow&lt;/span&gt;
 &lt;a href="#4-enable-netflow" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;So now that we have our test network ready, we can enable netflow on the core routers by choosing our netflow flavour and provision the respective commands via the &lt;code&gt;netlab config&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· ANSIBLE_NOCOWS=1 netlab config kentik_flow -l core -e ACTION=push
&amp;lt; snipped &amp;gt;

PLAY RECAP ****************************************************************************************************************
rc1 : ok=7 changed=1 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0
rc2 : ok=7 changed=1 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
rc3 : ok=7 changed=1 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
rc4 : ok=7 changed=1 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can use this method to re-configure any other flow configuration ad-hoc by leveraging the &lt;code&gt;ACTION&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s check on the kproxy after a while to see that all devices are sending flows and are correctly registered with the portal:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· telnet kproxy 9996
Trying 192.168.121.105...
Connected to kproxy.
Escape character is &amp;#39;^]&amp;#39;.
GOOD

4 Connected Devices
* 29118:iol-rc3:115541 -&amp;gt; 0.0.0.0:40016 (In1: 0.116060, Out1: 0.108333, In15: 0.191401, Out15: 0.009772). Last seen 2024-12-07T18:17:32.509264 (8.195s ago). Sources: 192.168.121.103. Channel highwater: 0, 0, 0. Flow: netflow.v9
* 29118:iol-rc1:115531 -&amp;gt; 0.0.0.0:40010 (In1: 0.119930, Out1: 0.081798, In15: 0.191431, Out15: 0.008598). Last seen 2024-12-07T18:17:35.463030 (7.186s ago). Sources: 192.168.121.101. Channel highwater: 0, 0, 0. Flow: netflow.v9
* 29118:iol-rc2:115536 -&amp;gt; 0.0.0.0:40012 (In1: 0.094682, Out1: 0.027546, In15: 0.189246, Out15: 0.003203). Last seen 2024-12-07T18:17:28.505189 (12.199s ago). Sources: 192.168.121.102. Channel highwater: 0, 0, 0. Flow: netflow.v9
* 29118:iol-rc4:115546 -&amp;gt; 0.0.0.0:40014 (In1: 0.102966, Out1: 0.108333, In15: 0.190311, Out15: 0.009772). Last seen 2024-12-07T18:17:19.681646 (21.022s ago). Sources: 192.168.121.104. Channel highwater: 0, 0, 0. Flow: netflow.v9

0 Unregistered Devices

Connection closed by foreign host.&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="5-enable-traffic"&gt;&lt;span&gt;5. Enable Traffic&lt;/span&gt;
 &lt;a href="#5-enable-traffic" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Our &lt;code&gt;PC's&lt;/code&gt; are already listening to the appropriate ports for the traffic tests, so we can run the clients using the respective template:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)·&amp;gt;&amp;gt; ANSIBLE_NOCOWS=1 netlab config iperf3_clients -l pcs -e ACTION=run
&amp;lt; snipped &amp;gt;

PLAY RECAP ****************************************************************************************************************
pc1 : ok=9 changed=3 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0
pc11 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc12 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc13 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc14 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc2 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc3 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0
pc4 : ok=9 changed=3 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The same applies to this step as well. We can stop, start and reconfigure the test parameters in our template at any point using the appropriate &lt;code&gt;ACTION&lt;/code&gt; value.&lt;/p&gt;
&lt;p&gt;Here are some outputs from the devices:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)&amp;lt;&amp;lt;· netlab exec rc1 sh int e0/3 \| i rate
Connecting to rc1 using SSH port 22, executing sh int e0/3 | i rate

 Queueing strategy: fifo
 5 minute input rate 32387000 bits/sec, 3279 packets/sec
 5 minute output rate 16295000 bits/sec, 2494 packets/sec
Connection to rc1 closed by remote host.

(wsl)·&amp;gt;&amp;gt; netlab exec ce2 sh int e0/1 \| i rate
Connecting to ce2 using SSH port 22, executing sh int e0/1 | i rate


 Queueing strategy: fifo
 5 minute input rate 21226000 bits/sec, 2532 packets/sec
 5 minute output rate 22546000 bits/sec, 2651 packets/sec
Connection to ce2 closed by remote host.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here is how it looks in Kentik&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/iou-love/traffic.png" title="/posts/iou-love/traffic.png" data-thumbnail="/posts/iou-love/traffic.png" data-sub-html="&lt;h2&gt;Top Device by Average bits/s&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/iou-love/traffic.png' alt="/posts/iou-love/traffic.png" height="739" width="2023"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Top Device by Average bits/s&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;h3 class="heading-element" id="6-register-synthetics-agents"&gt;&lt;span&gt;6. Register Synthetics Agents&lt;/span&gt;
 &lt;a href="#6-register-synthetics-agents" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Now for the last step, the &lt;code&gt;ksynth&lt;/code&gt; agents, on their first run they will initialise and appear in the portal as &lt;code&gt;Pending&lt;/code&gt; until they are activated. We need to activate them in the portal, assign them to the site we are using in the lab, choose the address families enabled, and also provide their private IP address they got from &lt;em&gt;netlab&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We can get the IP address with the &lt;code&gt;netlab inspect&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(wsl)·&amp;gt;&amp;gt; for i in 1 2 3 4 ; do echo -n &amp;#34;ksynth$i &amp;#34;;\
 netlab inspect --node ksynth$i interfaces[0].ipv4 ; done
ksynth1 172.16.4.6/24

ksynth2 172.16.5.7/24

ksynth3 172.16.6.8/24

ksynth4 172.16.7.9/24&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;From this point onwards we can configure our tests in the portal.&lt;/p&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;Outro&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Well I hope you reached the end of this long post and that by now you have realised how simple it is to bring up a topology in &lt;em&gt;containerlab&lt;/em&gt; using &lt;em&gt;netlab&lt;/em&gt; to take care of the initial configuration of the underneath connectivity details and protocols running on it. The topology we used here is very small and simple, indeed, but I think that what &lt;em&gt;netlab&lt;/em&gt; has to offer does worth the effort of spending some time in getting to know it better and using it in your use cases or even pipelines.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s summarise here the key takeaways of this post:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have used &lt;em&gt;netlab&lt;/em&gt; to bring up a simple network topology via &lt;em&gt;containerlab&lt;/em&gt; and provision the initial configs on the devices based on the supported modules and features&lt;/li&gt;
&lt;li&gt;We have seen how to integrate additional containers interacting with this topology for serving our use case&lt;/li&gt;
&lt;li&gt;We have seen how to use &lt;em&gt;netlabs&amp;rsquo;&lt;/em&gt; ansible inventory to run our own plays extending the usability of the lab&lt;/li&gt;
&lt;li&gt;We have seen how to create additional configurations using templates and provision them ad-hoc to our nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of my thoughts on more back-blogs coming out of this could be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Building IOL containers out of the old images using i386 libraries and also licensing&lt;/li&gt;
&lt;li&gt;Using &lt;a href="https://netlab.tools/dev/extools/" target="_blank" rel="external nofollow noopener noreferrer"&gt;&lt;em&gt;netlab tools&lt;/em&gt;&lt;/a&gt; for the service containers&lt;/li&gt;
&lt;li&gt;Using &lt;a href="https://netlab.tools/plugins/" target="_blank" rel="external nofollow noopener noreferrer"&gt;&lt;em&gt;netlab plugins&lt;/em&gt;&lt;/a&gt; to extend the current functionality or even add a new one&lt;/li&gt;
&lt;li&gt;Handling of sensitive data, maybe ansible vault&lt;/li&gt;
&lt;li&gt;Use a wrapper on top to orchestrate the use case, like python invoke&lt;/li&gt;
&lt;li&gt;Use &lt;a href="https://netlab.tools/topology/validate/" target="_blank" rel="external nofollow noopener noreferrer"&gt;netlab validation tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Use &lt;a href="https://wemulate.github.io/wemulate/" target="_blank" rel="external nofollow noopener noreferrer"&gt;WEmulate&lt;/a&gt; to artificially impair links for my Kentik use case, like &lt;a href="https://blog.ipspace.net/2024/04/netlab-wemulate/" target="_blank" rel="external nofollow noopener noreferrer"&gt;this&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="right"&gt;&lt;br&gt;&lt;br&gt;&lt;i&gt;...till next time...have fun!!! &lt;/i&gt; &lt;/p&gt;
&lt;h2 class="heading-element" id="influences-and-reference"&gt;&lt;span&gt;Influences and Reference&lt;/span&gt;
 &lt;a href="#influences-and-reference" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://netlab.tools/" target="_blank" rel="external nofollow noopener noreferrer"&gt;netlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://containerlab.dev/" target="_blank" rel="external nofollow noopener noreferrer"&gt;containerlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/hellt/vrnetlab" target="_blank" rel="external nofollow noopener noreferrer"&gt;vrnetlab for containerlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/srl-labs/srl-telemetry-lab" target="_blank" rel="external nofollow noopener noreferrer"&gt;srl-telemetry-lab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.cisco.com/docs/modeling-labs/iol/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Cisco IOL in CML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/becos76/netlab-iol" target="_blank" rel="external nofollow noopener noreferrer"&gt;My repo for this post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>If this ain't a modern NMS, then what is?</title><link>https://net4fungr.github.io/posts/modern-nms/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://net4fungr.github.io/posts/modern-nms/</guid><category domain="https://net4fungr.github.io/categories/network-monitoring/">Network Monitoring</category><description>&lt;hr&gt;
&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;Intro&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;In this post we will go through a detailed how to on executing Ansible playbooks triggered by a webhook notification event raised in Kentik Portal. The use case is to have visibility into BGP Flowspec metrics of the devices during mitigations and see the relevant counters in the Portal under Kentik&amp;rsquo;s NMS Metrics Explorer.&lt;/p&gt;
&lt;p&gt;You may find all relevant files in my &lt;a href="https://github.com/becos76/kentik-eda" target="_blank" rel="external nofollow noopener noreferrer"&gt;repo&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="the-intent"&gt;&lt;span&gt;The Intent&lt;/span&gt;
 &lt;a href="#the-intent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;For the webhook receiver part, we are going to use &lt;a href="https://github.com/kentik/ansible_eda" target="_blank" rel="external nofollow noopener noreferrer"&gt;Kentik&amp;rsquo;s ansible_eda&lt;/a&gt; collection that will &lt;em&gt;listen&lt;/em&gt; for a mitigation notification event. Once the event is received and a mitigation is started, EDA will trigger the execution of a playbook to handle the event and spin-up Telegraf in order to start polling the devices for BGP Flowspec streaming telemetry counters while reporting them back to the Portal in influx line format via HTTPS.&lt;/p&gt;
&lt;p&gt;Once the mitigation is over and EDA receives the respective &lt;em&gt;cease&lt;/em&gt; notification, a check for any active mitigations on the devices is done via Kentik&amp;rsquo;s API and if there are no active mitigations on the devices, EDA will trigger Telegraf to stop. If there are still on-going mitigations, Telegraf will continue to poll and ship metrics till we receive the last mitigation&amp;rsquo;s notification.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="lab-setup"&gt;&lt;span&gt;Lab Setup&lt;/span&gt;
 &lt;a href="#lab-setup" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Here is how the lab has been set-up for this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two Cisco IOS XRv 9000 devices defined in the portal with established BGP sessions and Flowspec family enabled. GRPC is configured and enabled on the devices.&lt;/li&gt;
&lt;li&gt;A mitigation Platform defined in the Portal that includes both devices, and two mitigation methods attached. One will block ICMP echo-requests and the other will Rate Limit SSH protocol&lt;/li&gt;
&lt;li&gt;A notification channel of type JSON defined in the portal and attached to both mitigation methods&lt;div class="details admonition note"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Note&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;I chose not to use any Alerting Policies with this and trigger all mitigations manually in order to speed things up&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;An Ubuntu VM (jammy) with docker installed
&lt;ul&gt;
&lt;li&gt;EDA will run inside a docker container with Traefik &lt;em&gt;proxying&lt;/em&gt; the webhook events&lt;/li&gt;
&lt;li&gt;Once an &lt;em&gt;actionable&lt;/em&gt; event is received, EDA will control a Telegraf docker container accordingly through a playbook&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="discovery"&gt;&lt;span&gt;Discovery&lt;/span&gt;
 &lt;a href="#discovery" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;We will start by exploring what we see on the devices during a running flowspec mitigation. We have triggered two manual mitigations in the Portal and those are currently active on the devices:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ATH-POP1-XRV1#show flowspec afi-all detail

AFI: IPv4
 Flow :Dest:10.10.10.11/32,ICMPType:=8
 Actions :Traffic-rate: 0 bps (bgp.1)
 Flow :Source:10.10.10.12/32,Proto:=6,DPort:=22
 Actions :Traffic-rate: 160000 bps (bgp.1)&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition failure"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-xmark" aria-hidden="true"&gt;&lt;/i&gt;XRv9k limitations&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;&lt;p&gt;Unfortunatelly the XRv has a limited data plane, so we do not get any &lt;em&gt;action&lt;/em&gt; counters on the mitigations - this and also no netflow out of this virtual device &amp;#x1f622;. In case of a &lt;em&gt;real&lt;/em&gt; XR device the output would be similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REAL-XR#show flowspec afi-all detail

AFI: IPv4
 Flow :Dest:10.10.10.11/32,ICMPType:=8
 Actions :Traffic-rate: 0 bps (bgp.1)
	Statisctics (packets/bytes)
	 Matched : 10/640
	 Dropped : 10/640&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;So we have two mitigations as expected. Let&amp;rsquo;s find out which YANG model those are defined under. After trying some show commands for the xpath, there it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ATH-POP1-XRV1#schema-describe &amp;#34;show flowspec afi-all detail&amp;#34;

Action: get
Path: RootCfg.ASNFormat

Action: get_children
Path: RootOper.FlowSpec.VRF({&amp;#39;VRFName&amp;#39;: &amp;#39;default&amp;#39;}).AF

Action: get
Path: RootOper.FlowSpec.VRF({&amp;#39;VRFName&amp;#39;: &amp;#39;default&amp;#39;}).AF({&amp;#39;AFName&amp;#39;: &amp;#39;IPv4&amp;#39;}).Flow

RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath &amp;#34;show flowspec afi-all detail&amp;#34;

Error: Invalid input
RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath &amp;#34;show flowspec afi-all&amp;#34;

Error: Invalid input
RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal xpath &amp;#34;show flowspec summary&amp;#34;

Cisco-IOS-XR-flowspec-oper:flow-spec/summary

RP/0/RP0/CPU0:ATH-POP1-XRV1#show telemetry internal json Cisco-IOS-XR-flowspec-oper:flow-spec | include path

 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow&amp;#34;,
 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/nlris/nlri&amp;#34;,
 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/table-summary&amp;#34;,
 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/summary&amp;#34;,
 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/clients/client&amp;#34;,&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now we know the YANG model and the xpath, and we can get the metrics out of. We will test it with &lt;code&gt;gnmic&lt;/code&gt; to see if it works and get the details of the tags/paths returned:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ gnmic -a 10.12.255.1:57344 -u &amp;lt;device_username&amp;gt; -p &amp;lt;device_password&amp;gt; --skip-verify prompt
gnmic&amp;gt; get --path Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow -e json_ietf --format event
[
 {
 &amp;#34;name&amp;#34;: &amp;#34;get-request&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1716762517741698080,
 &amp;#34;tags&amp;#34;: {
 &amp;#34;af_af-name&amp;#34;: &amp;#34;IPv4&amp;#34;,
 &amp;#34;flow_flow-notation&amp;#34;: &amp;#34;Dest:10.10.10.11/32,ICMPType:=8&amp;#34;,
 &amp;#34;source&amp;#34;: &amp;#34;10.12.255.1:57344&amp;#34;,
 &amp;#34;vrf_vrf-name&amp;#34;: &amp;#34;default&amp;#34;
 },
 &amp;#34;values&amp;#34;: {
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/dscp&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-notation&amp;#34;: &amp;#34;Dest:10.10.10.11/32,ICMPType:=8&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/prefix&amp;#34;: &amp;#34;10.10.10.11&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/code&amp;#34;: 255,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/type&amp;#34;: 8,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/match-any&amp;#34;: false,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/value&amp;#34;: 0
 }
 },
 {
 &amp;#34;name&amp;#34;: &amp;#34;get-request&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1716762517741698080,
 &amp;#34;tags&amp;#34;: {
 &amp;#34;af_af-name&amp;#34;: &amp;#34;IPv4&amp;#34;,
 &amp;#34;flow_flow-notation&amp;#34;: &amp;#34;Source:10.10.10.12/32,Proto:=6,DPort:=22&amp;#34;,
 &amp;#34;source&amp;#34;: &amp;#34;10.12.255.1:57344&amp;#34;,
 &amp;#34;vrf_vrf-name&amp;#34;: &amp;#34;default&amp;#34;
 },
 &amp;#34;values&amp;#34;: {
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/dscp&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/rate&amp;#34;: &amp;#34;160000&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-notation&amp;#34;: &amp;#34;Source:10.10.10.12/32,Proto:=6,DPort:=22&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-port/uint16_rng_array.0/max&amp;#34;: 22,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-port/uint16_rng_array.0/min&amp;#34;: 22,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/code&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/type&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/ip-protocol/uint16_rng_array.0/max&amp;#34;: 6,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/ip-protocol/uint16_rng_array.0/min&amp;#34;: 6,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/prefix&amp;#34;: &amp;#34;10.10.10.12&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/match-any&amp;#34;: false,
 &amp;#34;/Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/value&amp;#34;: 0
 }
 }
]&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="kentik-eda"&gt;&lt;span&gt;Kentik EDA&lt;/span&gt;
 &lt;a href="#kentik-eda" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;We are going to start off by explaining the file and folder structure giving a bit of info of how this works. The idea behind this is to have EDA running as a docker container. Traefik will handle reverse proxying the webhooks to EDA and in case a new mitigation is happening, then a telegraf docker container will spin up and start collecting gnmi metrics from the devices and pushing them to the Portal. Once the mitigation is over, EDA will receive the event to stop the mitigation.&lt;/p&gt;
&lt;p&gt;Now, at this point, since more than one mitigations can be ongoing on the devices, we are going to focus on the specific mitigation Platform that will always include our devices. So any Method under the specific mitigation Platform will cause the start of the metrics collection. Upon receiving a stop event on this Platform, we just have to make sure that this event is the &lt;em&gt;last&lt;/em&gt; one on the devices, and we can verify this via Kentik API requesting all active alerts in the portal of type Mitigation. If none exists, then we can assume that the event EDA received was the last one for the Platform.&lt;/p&gt;
&lt;p&gt;In summary, here are the features delivered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Traefik is handling the proxying of webhooks to the appropriate path that Kentik EDA is set up to receive&lt;/li&gt;
&lt;li&gt;Kentik EDA processes only the relevant mitigation events coming in excluding the rest&lt;/li&gt;
&lt;li&gt;The playbook will dynamically produce the telegraf configuration file according to our defined variables in order to ship the metrics in the Portal&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="heading-element" id="directory-structure"&gt;&lt;span&gt;Directory Structure&lt;/span&gt;
 &lt;a href="#directory-structure" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;.
├── docker-compose.yaml &amp;gt;-- How to bring up our services
├── Dockerfile &amp;gt;-- How to build the EDA image
├── .env &amp;gt;-- Hidden file containing sensitive data to be passed as environment variables
├── .env.sample &amp;gt;-- Example env file
└── eda &amp;gt;-- EDA config folder to be mounted on the container
   ├── ansible.cfg &amp;gt;-- Ansible configuration file picked up by default
   ├── ansible-inventory.yml &amp;gt;-- Simple inv file including only localhost
   ├── eda_vars.yml &amp;gt;-- Definition of the related variables used in the project
   ├── mitigation.yml &amp;gt;-- Playbook to handle events received
   ├── rules.yml &amp;gt;-- Rulebook defining our EDA logic
   └── telegraf 
   ├── telegraf.conf.j2 &amp;gt;-- Jinja2 template producing the configuration dynamically
   └── telegraf.conf &amp;gt;-- Actual config to be used with the telegraf container
  &lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="dockerfile"&gt;&lt;span&gt;Dockerfile&lt;/span&gt;
 &lt;a href="#dockerfile" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;We are installing the dependencies and ansible needed collections for Kentik EDA to run. We are going to run everything under the &lt;code&gt;/app&lt;/code&gt; directory inside the container&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM quay.io/centos/centos:stream9-development

RUN dnf install -y java-17-openjdk-devel python3-pip gcc python3-devel postgresql-devel

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk

RUN pip install -U pip \
 &amp;amp;&amp;amp; pip install ansible-core \
 ansible-rulebook \
 ansible-runner \
 psycopg requests \
 &amp;amp;&amp;amp; ansible-galaxy collection install kentik.ansible_eda community.docker

ARG APP_DIR=${APP_DIR:-/app}

WORKDIR $APP_DIR

RUN chmod -R 0775 $APP_DIR&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="compose"&gt;&lt;span&gt;Compose&lt;/span&gt;
 &lt;a href="#compose" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Our compose file will bring up two services.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;traefik&lt;/strong&gt;: that will listen for HTTP and will forward everything received at the &lt;code&gt;/eda&lt;/code&gt; path to the EDA container replacing the path to &lt;code&gt;/alert&lt;/code&gt;, since this is the path that Kentik EDA webhook listens on, and port &lt;code&gt;8080&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kentik-eda&lt;/strong&gt;: Our &lt;code&gt;eda&lt;/code&gt; folder is mounted at the &lt;code&gt;/app&lt;/code&gt; path inside the container, and contains all the files needed to run our logic. We also mount the docker unix socket to the container so that we can control the containers from within the EDA one. We also pass our variables to the container environment and we instruct the container to start the rulebook passing also the variables files. &lt;div class="details admonition warning"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-exclamation-triangle" aria-hidden="true"&gt;&lt;/i&gt;Avoid using this in production!!!&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;Security wise it is not the best to have a docker container controlling the host&amp;rsquo;s containers by exposing the unix socket to it. &amp;#x1f604;&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;---
services:
 traefik:
 image: traefik
 container_name: traefik
 command: &amp;gt;
 --api.insecure=true
 --providers.docker
 --providers.docker.exposedbydefault=false
 --accesslog=true
 --entrypoints.eda.address=:80
 #--log.level=DEBUG
 ports:
 - 80:80
 - 8080:8080
 volumes:
 - /var/run/docker.sock:/var/run/docker.sock:ro
 kentik-eda:
 #scale: 2
 image: kentik-eda:0.1
 container_name: kentik-eda
 depends_on:
 - traefik
 build:
 context: .
 volumes:
 - ${PWD}/eda:/app
 - /var/run/docker.sock:/var/run/docker.sock:ro
 env_file:
 - .env
 ports:
 - 8080
 command: bash -c &amp;#34;ansible-rulebook --rulebook rules.yml -i ./ansible-inventory.yml --vars eda_vars.yml&amp;#34;
 labels:
 - &amp;#34;traefik.enable=true&amp;#34;
 - &amp;#34;traefik.http.routers.eda.rule=Host(`kentik.eda`) &amp;amp;&amp;amp; Path(`/eda`)&amp;#34;
 - &amp;#34;traefik.http.routers.eda.middlewares=eda-ratelimit,eda-path&amp;#34;
 - &amp;#34;traefik.http.middlewares.eda-path.replacepath.path=/alert&amp;#34;
 - &amp;#34;traefik.http.middlewares.eda-ratelimit.ratelimit.average=10&amp;#34;
 - &amp;#34;traefik.http.middlewares.eda-ratelimit.ratelimit.burst=50&amp;#34;
 - &amp;#34;traefik.http.routers.eda.entrypoints=eda&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is the example &lt;code&gt;.env&lt;/code&gt; file showing the variables needed to be exposed inside the EDA container environment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;KENTIK_API_TOKEN=&amp;lt;your api token&amp;gt;
KENTIK_API_EMAIL=&amp;lt;your portal email&amp;gt;
KENTIK_API_ENDPOINT=&amp;#34;https://grpc.api.kentik.eu/kmetrics/v202207/metrics/api/v2/write?bucket=&amp;amp;org=&amp;amp;precision=ns&amp;#34;
GRPC_USERNAME=&amp;lt;device username&amp;gt;
GRPC_PASSWORD=&amp;lt;device password&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can bring everything up with &lt;code&gt;docker compose up --build&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ docker compose up --build --force-recreate --dry-run
[&amp;#43;] Building 0.0s (0/0) docker:default
[&amp;#43;] Running 5/0
 ✔ DRY-RUN MODE - build service kentik-eda 0.0s
 ✔ DRY-RUN MODE - ==&amp;gt; ==&amp;gt; writing image dryRun-648b28d83dd200d4e7709ac3a5d522f8244467bd 0.0s
 ✔ DRY-RUN MODE - ==&amp;gt; ==&amp;gt; naming to kentik-eda:0.1 0.0s
 ✔ DRY-RUN MODE - Container traefik Recreated 0.0s
 ✔ DRY-RUN MODE - Container kentik-eda Recreated 0.0s
end of &amp;#39;compose up&amp;#39; output, interactive run is not supported in dry-run mode&lt;/code&gt;&lt;/pre&gt;&lt;h3 class="heading-element" id="rulebook-rules"&gt;&lt;span&gt;Rulebook rules&lt;/span&gt;
 &lt;a href="#rulebook-rules" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Here is how we have configured our rules:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
- name: Listening for Webhook Events
 hosts: localhost
 sources:
 - kentik.ansible_eda.kentik_webhook:
 host: 0.0.0.0
 port: 8080
 rules:
 - name: R1 - New Event Received
 # If it is a valid start or stop mitigation event
 condition: event.payload is defined and
 event.payload.CompanyID == vars.CompanyID and
 event.payload.EventType == vars.EventType and
 event.payload.MitigationPlatformID == vars.MitigationPlatformID and
 event.payload.MitigationState in vars.ValidMitigationStates and
 event.payload.MitigationStateNew in vars.ValidMitigationStates
 actions:
 - debug:
 msg: |
 New {{event.payload.MitigationType}}/{{event.payload.MitigationState}} event received
 ID: {{event.payload.MitigationID}}
 Platform: {{event.payload.MitigationPlatformName}}
 Method: {{event.payload.MitigationMethodName}}
 IP: {{event.payload.MitigationAlertIP}}

 # DEBUG:Dump the event
 #- print_event:
 # pretty: true

 # Call the pb to handle the mitigation event
 - run_playbook:
 name: mitigation.yml

 # Catch and ignore the rest
 - name: R2 - Not taking action
 condition: event.meta is defined
 action:
 debug:
 msg:
 - &amp;#34;Ignoring {{event.payload.EventType}} event&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;eda/rules.yml&lt;/b&gt;&lt;/p&gt;
and our variables:
&lt;pre&gt;&lt;code&gt;---
CompanyID: &amp;lt;REDACTED&amp;gt;
EventType: &amp;#34;mitigation&amp;#34;
MitigationPlatformID: &amp;#34;257&amp;#34;
ValidMitigationStates:
 - &amp;#34;manualMitigating&amp;#34;
 - &amp;#34;mitigating&amp;#34;
 - &amp;#34;archived&amp;#34;
Mitigation:
 devices:
 - name: &amp;#34;ath-pop1-xrv1&amp;#34;
 ip: &amp;#34;10.12.255.1&amp;#34;
 port: 57344
 - name: &amp;#34;ath-pop1-xrv2&amp;#34;
 ip: &amp;#34;10.13.255.1&amp;#34;
 port: 57344&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;eda/eda_vars.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;As a condition we check the event payload against certain values in order to process it further, e.g. the CompanyID , the EventType and the MitigationPlatformID must match to what we have configured and also the EventState must be one of the &lt;em&gt;actionable&lt;/em&gt; states that we have defined in our dictionary. If we have a matching event then we pass control to the &lt;code&gt;mitigation.yml&lt;/code&gt; playbook to handle the event further.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="ansible-playbook"&gt;&lt;span&gt;Ansible Playbook&lt;/span&gt;
 &lt;a href="#ansible-playbook" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;We could have had separate playbooks for the different states of the alerts received, i.e. separate conditions in the rules file, but we chose here to proceed with just one playbook to handle both cases.&lt;/p&gt;
&lt;p&gt;A brief pseudocode of the playbook could be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#IF event state is &amp;#39;mitigating&amp;#39;
	#IF Telegraf is not running
		- Generate telegraf config from template
		- Bring up the container
#ELSE IF event state is &amp;#39;archived&amp;#39;
	#IF no active mitigation alerts in portal for PlatormID
		- Stop telegraf container&lt;/code&gt;&lt;/pre&gt;
&lt;details&gt;
 &lt;summary&gt;Here is a sequence diagram showing the workflows&lt;/summary&gt;
 &lt;pre&gt;&lt;code&gt;sequenceDiagram
 autonumber
 participant Portal
 participant EDA
 Portal-&amp;gt;&amp;gt;EDA: Alerts
 loop Listen
 EDA-&amp;gt;&amp;gt;EDA: Check Platform and State (Start/Stop)
 create participant Playbook
 EDA-&amp;gt;&amp;gt;Playbook: Process Valid Alert 
 end
 alt Mitigation Started
 Playbook-&amp;gt;&amp;gt;Docker: Is Telegraf Running?
 Docker--&amp;gt;&amp;gt;Playbook: State
 alt Telegraf Running
 Playbook-&amp;gt;&amp;gt;Playbook: Do nothing
 else Telegraf Down
 Playbook-&amp;gt;&amp;gt;Playbook: Create Telegraf config
 Playbook-&amp;gt;&amp;gt;Docker: Start Telegraf
 create participant Telegraf
 Docker-&amp;gt;&amp;gt;Telegraf: Run Container
 loop
 create participant Devices
 Telegraf-&amp;gt;&amp;gt;Devices: Fetch metrics
 Telegraf-&amp;gt;&amp;gt;Portal: Ship metrics
 end
 end
 else Mitigation Finished
 Playbook-&amp;gt;&amp;gt;Portal: Get active mitigations
 Portal--&amp;gt;&amp;gt;Playbook: Active Mitigations
 alt Active Mitigations on Platform
 Playbook-&amp;gt;&amp;gt;Playbook: Do nothing
 else No Active Mitigations on Platform
 Playbook-&amp;gt;&amp;gt;Docker: Stop Telegraf
 Docker-&amp;gt;&amp;gt;Telegraf: Container Down
 destroy Telegraf
 end
 end&lt;/code&gt;&lt;/pre&gt;&lt;/details&gt;
&lt;p&gt;And here is the playbook. Two blocks were used to differentiate between the start and stop workflows. For the telegraf container the configuration file is dynamically produced through a jinja2 template and this is mounted within the container. This is achieved by specifying the full host path of the file, which is also relatively mounted within the EDA container, i.e. shared.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
- name: &amp;#34;::HANDLE MITIGATION EVENT::&amp;#34;
 gather_facts: no
 hosts: localhost
 vars_files: eda_vars.yml
 tasks:
 - name: START - NEW MITIGATION STARTING
 block: 
 
 - name: START::IS TELEGRAF RUNNING
 community.docker.docker_container_info:
 name: telegraf-eda
 register: result
 
 - name: START::GENERATE TELEGRAF CONFIG
 ansible.builtin.template:
 src: /app/telegraf/telegraf.conf.j2
 dest: /app/telegraf/telegraf.conf
 when: not result.exists|bool 
 
 - name: START::BRING UP CONTAINER
 community.docker.docker_container:
 name: telegraf-eda
 image: telegraf:latest
 state: started
 volumes:
 - &amp;#34;/opt/projects/kentik-eda/eda/telegraf/telegraf.conf:/etc/telegraf/telegraf.conf&amp;#34;
 env:
 KENTIK_API_EMAIL: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;KENTIK_API_EMAIL&amp;#39;)}}&amp;#34;
 KENTIK_API_TOKEN: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;KENTIK_API_TOKEN&amp;#39;)}}&amp;#34;
 GRPC_USERNAME: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;GRPC_USERNAME&amp;#39;)}}&amp;#34;
 GRPC_PASSWORD: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;GRPC_PASSWORD&amp;#39;)}}&amp;#34;
 when: not result.exists|bool 
 
 when: &amp;#34;&amp;#39;mitigating&amp;#39; in ansible_eda.event.payload.MitigationState|lower and 
 &amp;#39;mitigating&amp;#39; in ansible_eda.event.payload.MitigationStateNew|lower&amp;#34;
 
 - name: MITIGATION FINISHED
 block: 
 
 - name: STOP::GET ACTIVE ALERTS FROM KENTIK
 ansible.builtin.uri:
 url: https://api.kentik.eu/api/v5/alerts-active/alarms
 method: GET
 http_agent: ansible-eda-httpget
 headers:
 X-CH-Auth-API-Token: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;KENTIK_API_TOKEN&amp;#39;)}}&amp;#34; 
 X-CH-Auth-Email: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;KENTIK_API_EMAIL&amp;#39;)}}&amp;#34;
 register: alerts

 - name: STOP::CHECK KENTIK FOR ACTIVE MITIGATIONS
 ansible.builtin.debug: 
 msg: 
 - &amp;#34;Current Active Mitigations on Platform ID#{{MitigationPlatformID}}: {{alerts.json | 
 selectattr(&amp;#39;mit_platform_id&amp;#39;, &amp;#39;match&amp;#39;, ansible_eda.event.payload.MitigationPlatformID ) |
 selectattr(&amp;#39;alarm_state&amp;#39;, &amp;#39;search&amp;#39;, &amp;#39;MITIGATING&amp;#39;) | length}}&amp;#34;
 
 - name: STOP::REMOVE TELEGRAF CONTAINER
 community.docker.docker_container:
 name: telegraf-eda
 state: absent

 when: alerts.json | 
 selectattr(&amp;#39;mit_platform_id&amp;#39;, &amp;#39;match&amp;#39;, ansible_eda.event.payload.MitigationPlatformID ) |
 selectattr(&amp;#39;alarm_state&amp;#39;, &amp;#39;search&amp;#39;, &amp;#39;MITIGATING&amp;#39;) | length == 0
 
 when: &amp;#34;&amp;#39;archived&amp;#39; in ansible_eda.event.payload.MitigationState|lower and
 &amp;#39;archived&amp;#39; in ansible_eda.event.payload.MitigationStateNew|lower&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;eda/mitigation.yml&lt;/b&gt;&lt;/p&gt;
&lt;h3 class="heading-element" id="telegraf-configuration"&gt;&lt;span&gt;Telegraf configuration&lt;/span&gt;
 &lt;a href="#telegraf-configuration" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;When it comes to telegraf, we chose to have the config generated dynamically before the container starts. In this way we can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Specify the devices&amp;rsquo; attributes in the variables file and deduce the gnmi inputs from them&lt;/li&gt;
&lt;li&gt;Include the MitigationPlatformID as a tag along with all other event details&lt;/li&gt;
&lt;li&gt;Perform a &lt;em&gt;lookup&lt;/em&gt; to include DEVICE_IP and DEVICE_NAME along with the tags. This was implemented via an inline starlark script referencing a lookup dictionary that is dynamically constructed from our devices dictionary.&lt;/li&gt;
&lt;li&gt;All sensitive data are passed from the EDA container environment and instantiated via docker when the container is brought up.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is the template:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[agent]
 omit_hostname = true
 debug = true
 quiet = false

[global_tags]
 platform_id = &amp;#34;{{ MitigationPlatformID }}&amp;#34;

[[inputs.gnmi]]

 addresses = [{% for device in Mitigation.devices %}&amp;#34;{{device.ip}}:{{device.port}}&amp;#34;{% if not loop.last %},{% endif %}{% endfor %}]
 username = &amp;#34;${GRPC_USERNAME}&amp;#34;
 password = &amp;#34;${GRPC_PASSWORD}&amp;#34;
 redial = &amp;#34;10s&amp;#34;
 encoding = &amp;#34;proto&amp;#34;
 tls_enable = true
 insecure_skip_verify = true

[[inputs.gnmi.subscription]]
 name = &amp;#34;/devices/xrv9000/flowspec&amp;#34;
 origin = &amp;#34;Cisco-IOS-XR-flowspec-oper&amp;#34;
 path = &amp;#34;/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/&amp;#34;
 subscription_mode = &amp;#34;sample&amp;#34;
 sample_interval = &amp;#34;30s&amp;#34;

[[processors.rename]]
 [[processors.rename.replace]]
 tag = &amp;#34;source&amp;#34;
 dest = &amp;#34;device_ip&amp;#34;

[[processors.override]]
 [processors.override.tagpass]
 vrf_name = [&amp;#34;&amp;#34;]
 [processors.override.tags]
 vrf_name = &amp;#34;default&amp;#34;

[[processors.starlark]]
 source=&amp;#39;&amp;#39;&amp;#39;
lookup = {
{% for device in Mitigation.devices %}
 &amp;#34;{{ device.ip }}&amp;#34;: &amp;#34;{{ device.name }}&amp;#34;,
{% endfor %}}
def apply(metric):
 if metric.tags[&amp;#39;device_ip&amp;#39;] and metric.tags[&amp;#39;device_ip&amp;#39;] in lookup:
 metric.tags[&amp;#39;device_name&amp;#39;] = lookup[metric.tags[&amp;#39;device_ip&amp;#39;]]
 return metric
&amp;#39;&amp;#39;&amp;#39;

[[outputs.file]]
 files = [&amp;#34;stdout&amp;#34;]
 data_format = &amp;#34;influx&amp;#34;
 influx_sort_fields = false
 tagexclude = [&amp;#34;path&amp;#34;]

[[outputs.http]]
 url = &amp;#34;{{ lookup(&amp;#39;env&amp;#39;, &amp;#39;KENTIK_API_ENDPOINT&amp;#39;)}}&amp;#34;
 data_format = &amp;#34;influx&amp;#34;
 influx_sort_fields = false
 tagexclude = [&amp;#34;path&amp;#34;]

 [outputs.http.headers]
 Content-Type = &amp;#34;application/influx&amp;#34;
 X-CH-Auth-Email = &amp;#34;${KENTIK_API_EMAIL}&amp;#34;
 X-CH-Auth-API-Token = &amp;#34;${KENTIK_API_TOKEN}&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;eda/telegraf/telegraf.conf.j2&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;And the respective config file produced to be picked up by docker:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[agent]
 omit_hostname = true
 debug = true
 quiet = false

[global_tags]
 platform_id = &amp;#34;257&amp;#34;

[[inputs.gnmi]]

 addresses = [&amp;#34;10.12.255.1:57344&amp;#34;,&amp;#34;10.13.255.1:57344&amp;#34;]
 username = &amp;#34;${GRPC_USERNAME}&amp;#34;
 password = &amp;#34;${GRPC_PASSWORD}&amp;#34;
 redial = &amp;#34;10s&amp;#34;
 encoding = &amp;#34;proto&amp;#34;
 tls_enable = true
 insecure_skip_verify = true

[[inputs.gnmi.subscription]]
 name = &amp;#34;/devices/xrv9000/flowspec&amp;#34;
 origin = &amp;#34;Cisco-IOS-XR-flowspec-oper&amp;#34;
 path = &amp;#34;/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/&amp;#34;
 subscription_mode = &amp;#34;sample&amp;#34;
 sample_interval = &amp;#34;30s&amp;#34;

[[processors.rename]]
 [[processors.rename.replace]]
 tag = &amp;#34;source&amp;#34;
 dest = &amp;#34;device_ip&amp;#34;

[[processors.override]]
 [processors.override.tagpass]
 vrf_name = [&amp;#34;&amp;#34;]
 [processors.override.tags]
 vrf_name = &amp;#34;default&amp;#34;

[[processors.starlark]]
 source=&amp;#39;&amp;#39;&amp;#39;
lookup = {
 &amp;#34;10.12.255.1&amp;#34;: &amp;#34;ath-pop1-xrv1&amp;#34;,
 &amp;#34;10.13.255.1&amp;#34;: &amp;#34;ath-pop1-xrv2&amp;#34;,
}
def apply(metric):
 if metric.tags[&amp;#39;device_ip&amp;#39;] and metric.tags[&amp;#39;device_ip&amp;#39;] in lookup:
 metric.tags[&amp;#39;device_name&amp;#39;] = lookup[metric.tags[&amp;#39;device_ip&amp;#39;]]
 return metric
&amp;#39;&amp;#39;&amp;#39;

[[outputs.file]]
 files = [&amp;#34;stdout&amp;#34;]
 data_format = &amp;#34;influx&amp;#34;
 influx_sort_fields = false
 tagexclude = [&amp;#34;path&amp;#34;]

[[outputs.http]]
 url = &amp;#34;https://grpc.api.kentik.eu/kmetrics/v202207/metrics/api/v2/write?bucket=&amp;amp;org=&amp;amp;precision=ns&amp;#34;
 data_format = &amp;#34;influx&amp;#34;
 influx_sort_fields = false
 tagexclude = [&amp;#34;path&amp;#34;]

 [outputs.http.headers]
 Content-Type = &amp;#34;application/influx&amp;#34;
 X-CH-Auth-Email = &amp;#34;${KENTIK_API_EMAIL}&amp;#34;
 X-CH-Auth-API-Token = &amp;#34;${KENTIK_API_TOKEN}&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;eda/telegraf/telegraf.conf&lt;/b&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="moment-of-truth"&gt;&lt;span&gt;Moment of Truth&lt;/span&gt;
 &lt;a href="#moment-of-truth" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;After starting some manual mitigations, telegraf will ship the gnmi metrics to the Portal and those will be available under the &lt;code&gt;/devices/xrv9000/flowspec&lt;/code&gt; custom schema path based on our configuration in the &lt;a href="#telegraf-configuration"&gt;&lt;code&gt;telegraf.conf&lt;/code&gt;&lt;/a&gt;file.&lt;/p&gt;
&lt;p&gt;Here is how it looks like in the Metrics Explorer
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/modern-nms/mot.png" title="/posts/modern-nms/mot.png" data-thumbnail="/posts/modern-nms/mot.png" data-sub-html="&lt;h2&gt;Flowspec metrics in the Portal&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/modern-nms/mot.png' alt="/posts/modern-nms/mot.png" height="920" width="2541"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Flowspec metrics in the Portal&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Here are some console outputs from EDA running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;** 2024-05-26 16:00:04.559137 [debug] ******************************************
Ignoring mitigation event
********************************************************************************

** 2024-05-26 16:00:18.406938 [debug] ******************************************
New manual/manualMitigating event received
ID: 10108
Platform: XR-FlowSpec
Method: Discard ICMP echo-request
IP: 10.10.10.11/32
********************************************************************************

PLAY [::HANDLE MITIGATION EVENT::] *********************************************

TASK [START::IS TELEGRAF RUNNING] **********************************************
ok: [localhost]

TASK [START::GENERATE TELEGRAF CONFIG] *****************************************
ok: [localhost]

TASK [START::BRING UP CONTAINER] ***********************************************
changed: [localhost]

TASK [STOP::GET ACTIVE ALERTS FROM KENTIK] *************************************
skipping: [localhost]

TASK [STOP::CHECK KENTIK FOR ACTIVE MITIGATIONS] *******************************
skipping: [localhost]

TASK [STOP::REMOVE TELEGRAF CONTAINER] *****************************************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost : ok=3 changed=1 unreachable=0 failed=0 skipped=3 rescued=0 ignored=0&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;New mitigation&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;** 2024-05-26 16:10:20.682550 [debug] ******************************************
New manual/archived event received
ID: 10111
Platform: XR-FlowSpec
Method: Rate Limit 20k TCP SSH
IP: 10.10.10.15/32
********************************************************************************

PLAY [::HANDLE MITIGATION EVENT::] *********************************************

TASK [START::IS TELEGRAF RUNNING] **********************************************
skipping: [localhost]

TASK [START::GENERATE TELEGRAF CONFIG] *****************************************
skipping: [localhost]

TASK [START::BRING UP CONTAINER] ***********************************************
skipping: [localhost]

TASK [STOP::GET ACTIVE ALERTS FROM KENTIK] *************************************
ok: [localhost]

TASK [STOP::CHECK KENTIK FOR ACTIVE MITIGATIONS] *******************************
ok: [localhost] =&amp;gt; {
 &amp;#34;msg&amp;#34;: [
 &amp;#34;Current Active Mitigations on Platform ID#257: 3&amp;#34;
 ]
}

TASK [STOP::REMOVE TELEGRAF CONTAINER] *****************************************
skipping: [localhost]

PLAY RECAP *********************************************************************
localhost : ok=2 changed=0 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Stop mitigation while others are running&lt;/b&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;Outro&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Well I hope this post was interesting enough and can be used as a reference while exploring the use cases covered:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to leverage Kentik EDA to receive Portal notifications and execute ansible playbooks&lt;/li&gt;
&lt;li&gt;How to use telegraf to send custom ST metrics to Kentik NMS&lt;/li&gt;
&lt;li&gt;Generating telegraf configuration dynamically&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="right"&gt;&lt;br&gt;&lt;br&gt;&lt;i&gt;...till next time...have fun!!! &lt;/i&gt; &lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="influences-and-reference"&gt;&lt;span&gt;Influences and Reference&lt;/span&gt;
 &lt;a href="#influences-and-reference" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.kentik.com/blog/driving-network-automation-innovation-kentik-and-red-hat-launch-integration/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Driving Network Automation Innovation: Kentik and Red Hat Launch Integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ansible.com/blog/getting-started-with-event-driven-ansible/" target="_blank" rel="external nofollow noopener noreferrer"&gt;EDA Quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kentik.com/blog/using-telegraf-to-feed-api-json-data-into-kentik-nms/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Using Telegraf to Feed API JSON Data into Kentik NMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/kentik/ansible_eda" target="_blank" rel="external nofollow noopener noreferrer"&gt;Kentik&amp;rsquo;s ansible_eda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/becos76/kentik-eda" target="_blank" rel="external nofollow noopener noreferrer"&gt;Repo for this post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;</description></item><item><title>K~ustom Metrics in Kentik NMS</title><link>https://net4fungr.github.io/posts/kustom-metrics/</link><pubDate>Sat, 04 May 2024 00:00:00 +0000</pubDate><guid>https://net4fungr.github.io/posts/kustom-metrics/</guid><category domain="https://net4fungr.github.io/categories/network-monitoring/">Network Monitoring</category><description>&lt;hr&gt;
&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;Intro&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Since the launch of Kentik NMS, it it is possible to ingest and display custom metrics in the Portal. In this post we will be going over a walkthrough of how we can enable Kentik&amp;rsquo;s Universal Agent to poll custom SNMP and Streaming Telemetry metrics from devices and report them back to the Portal. The use case is about having visibility into BGP Flowspec counters to see what our mitigations are reporting on the devices.&lt;/p&gt;
&lt;p&gt;We are going to address this through SNMP as well as ST for both Junos and IOS-XR devices. For Junos, the flowspec rules are translated into firewall filters which have counters and policers depending on the action. We have two possible ways to extract those, either via SNMP or via streaming telemetry and we are going to use both. For IOS-XR, on the other-hand, there are no SNMP flowspec related OIDs, but there is a dedicated flowspec YANG model we can use to extract the counters via streaming telemetry.&lt;/p&gt;
&lt;p&gt;The various tools and device versions used throughout the use case are listed below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kentik kagent docker container&lt;/li&gt;
&lt;li&gt;snmpwalk and snmptable&lt;/li&gt;
&lt;li&gt;gnmic&lt;/li&gt;
&lt;li&gt;Junos vMX on 21.3R1.9&lt;/li&gt;
&lt;li&gt;Cisco IOS-XRv 9000 on 7.9.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You may find all relevant files in my &lt;a href="https://github.com/becos76/kentik-custom-metrics" target="_blank" rel="external nofollow noopener noreferrer"&gt;repo&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="kentik-universal-agent-kagent"&gt;&lt;span&gt;Kentik Universal Agent (kagent)&lt;/span&gt;
 &lt;a href="#kentik-universal-agent-kagent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;In order to use the custom metrics feature on the kagent we need some local configuration to be picked up by the agent on startup so it can be processed. In summary, we need three configuration files to exist localy in a specific directory structure that we can call the &lt;em&gt;override&lt;/em&gt; directory.&lt;/p&gt;
&lt;p&gt;Below is the structure along with a brief explanation on the purpose of each one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/opt/kentik/components/ranger/local/
└── config
 ├── profiles # Holds the configuration yaml files for &amp;#39;binding&amp;#39; the sources to specific &amp;#39;device&amp;#39; types
 ├── reports # Holds the configuration yaml files for &amp;#39;how&amp;#39; we want to report what is collected from the sources in the portal
 └── sources # Holds the configuration yaml files for &amp;#39;what&amp;#39; we want to poll from the device&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So once kagent starts it looks for the &lt;code&gt;local&lt;/code&gt; folder and it processes those files in the structure. For example, if we want to poll an SNMP OID for a device, we would need to create a configuration file under the &lt;code&gt;sources&lt;/code&gt; directory specifying which OID to poll and how often. Then we need to &lt;em&gt;bind&lt;/em&gt; this source to only get polled if say the device is of a specific sysObjectID, and we do that in the &lt;code&gt;profiles&lt;/code&gt; directory. Lastly, in the &lt;code&gt;reports&lt;/code&gt; directory we define the path to present the data in the portal, how the data is represented and polled from the MIB, i.e. metrics or dimensions, and how often to update the values in the database. Additionally, in the &lt;code&gt;reports&lt;/code&gt; directory we can use &lt;code&gt;starlark&lt;/code&gt; scripts to add additional logic to our reporting capabilities.&lt;/p&gt;
&lt;h3 class="heading-element" id="kagent-container"&gt;&lt;span&gt;Kagent container&lt;/span&gt;
 &lt;a href="#kagent-container" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;We are going to be running our kagent instance as a container through compose. Here is how our directory structure looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/opt/dev/kentik/
├── docker-compose.yml # How to bring up the container
├── kagent-data # Local dir mount so kagent data persists -&amp;gt; /opt/kentik in the container
└── override-data # Local overrides directory with custom definitions -&amp;gt; /opt/kentik/components/ranger/local in the container
 └── config
 ├── profiles
 ├── reports
 └── sources&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here is the docker compose file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
services:
 kagent:
 hostname: kagent03
 image: kentik/kagent:latest
 restart: unless-stopped
 pull_policy: always
 cap_add:
 - NET_RAW
 environment:
 - K_COMPANY_ID=&amp;lt;REDACTED&amp;gt;
 - K_API_ROOT=grpc.api.kentik.eu:443
 #- K_LOG_LEVEL=debug
 volumes:
 - /opt/dev/kentik/kagent-data:/opt/kentik
 - /opt/dev/kentik/override-data:/opt/kentik/components/ranger/local/
 &lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="junos-firewall-filters"&gt;&lt;span&gt;Junos Firewall Filters&lt;/span&gt;
 &lt;a href="#junos-firewall-filters" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;In Junos the flowspec rules create relevant ad-hoc firewall filters and policers that are applied to the linecards and can be examined via the show firewall detail command. Here is what we get with nothing configured:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;netops@ATH-POP1-VMX1&amp;gt; show configuration firewall

netops@ATH-POP1-VMX1&amp;gt; show firewall detail

Filter: __default_bpdu_filter__&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here is what we get if we configure a filter to count SSH packets destined to the management IP of the device and two manual mitigations from the portal, one to block traffic and one to rate limit:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;netops@ATH-POP1-VMX1&amp;gt; show firewall detail

Filter: __default_bpdu_filter__

Filter: TEST-FIREWALL
Counters:
Name Bytes Packets
SSH-PACKETS 74932 1153

Filter: __flowspec_default_inet__
Counters:
Name Bytes Packets
10.11.10.10,*,icmp-type=8 41496 30
10.11.10.10,*,proto=6,dstport=5201 172233 184
Policers:
Name Bytes Packets
40K_10.11.10.10,*,proto=6,dstport=5201 402000 268&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So any flowpsec rule received is reported under the &lt;code&gt;__flowspec_default_inet__&lt;/code&gt; filter. The one that blocks ICMP traffic is a counter and the one that limits IPERF is both a counter and a policer.&lt;/p&gt;
&lt;h3 class="heading-element" id="snmp"&gt;&lt;span&gt;SNMP&lt;/span&gt;
 &lt;a href="#snmp" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;It seems that Juniper has a dedicated MIB for reporting those firewall metrics, the &lt;em&gt;JUNOS-FIREWALL-MIB&lt;/em&gt; and after downloading all juniper MIBs in my &lt;code&gt;~/.snmp/mibs&lt;/code&gt; directory and grepping for Firewall I got this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jnxFirewallsTable OBJECT-TYPE
 SYNTAX SEQUENCE OF JnxFirewallsEntry
 MAX-ACCESS not-accessible
 STATUS deprecated
 DESCRIPTION
 &amp;#34;A list of firewalls entries.
 NOTE: This table is deprecated and exists for backward
 compatibility. The user is encouraged to use
 jnxFirewallCounterTable. This table does not handle:
 1) counter and filter names greater than 24 characters
 2) counters with same names but different types (the first
 duplicate is returned only)&amp;#34;


 ::= { jnxFirewalls 1 }&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So the interesting OID to be polled is the &lt;code&gt;jnxFirewallCounterTable&lt;/code&gt; at &lt;strong&gt;1.3.6.1.4.1.2636.3.5.2&lt;/strong&gt;. Let’s use snmptable to see what we get:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ snmptable -v2c -c kentik -m all 10.11.255.1 jnxFirewallCounterTable
SNMP table: JUNIPER-FIREWALL-MIB::jnxFirewallCounterTable

 jnxFWCounterPacketCount jnxFWCounterByteCount jnxFWCounterDisplayFilterName jnxFWCounterDisplayName jnxFWCounterDisplayType
 1118 72508 TEST-FIREWALL SSH-PACKETS counter
 0 0 __default_arp_policer__ __default_arp_policer__ policer
 30 41496 __flowspec_default_inet__ 10.11.10.10,*,icmp-type=8 counter
 184 172233 __flowspec_default_inet__ 10.11.10.10,*,proto=6,dstport=5201 counter
 268 402000 __flowspec_default_inet__ 40K_10.11.10.10,*,proto=6,dstport=5201 policer&lt;/code&gt;&lt;/pre&gt;&lt;h4 class="heading-element" id="local-configuration"&gt;&lt;span&gt;Local Configuration&lt;/span&gt;
 &lt;a href="#local-configuration" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;From this point onward we can define our custom metrics in the relevant &lt;em&gt;overrides&lt;/em&gt; sub-directories&lt;/p&gt;
&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Sources file&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We are going to poll the table every 1 minute.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
version: 1
metadata:
 name: junos-fw-snmp
  kind: sources
sources:
  junos-fw-snmp: !snmp
    table: 1.3.6.1.4.1.2636.3.5.2
    interval: 60s&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Profiles file&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We will bind the source to the vMX sysObjectId&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
version: 1
metadata:
 name: junos-fw-snmp
 kind: profile
profile:
 match:
 sysobjectid:
 - 1.3.6.1.4.1.2636.1.1.1.2.108
 reports:
 - junos-fw-snmp
 include:
 - device_name_ip
 sources:
 - junos-fw-snmp&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Reports file&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We are going to report those under the &lt;code&gt;/junos/firewall/snmp&lt;/code&gt; schema path in the Portal and we define the mapping on the table fields identifying the metrics:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
version: 1
metadata:
 name: junos-fw-snmp
 kind: reports
reports:
 /junos/firewall/snmp:
 combine:
 table0: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 index: $index0
 fields:
 packets: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 value: 1.3.6.1.4.1.2636.3.5.2.1.4
 metric: true
 bytes: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 value: 1.3.6.1.4.1.2636.3.5.2.1.5
 metric: true
 filter_name: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 value: 1.3.6.1.4.1.2636.3.5.2.1.6
 metric: false
 counter_name: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 value: 1.3.6.1.4.1.2636.3.5.2.1.7
 metric: false
 counter_type: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 value: 1.3.6.1.4.1.2636.3.5.2.1.8
 metric: false
 tweak: !enum
 1: other
 2: counter
 3: policer
 interval: 60s&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is how our &lt;em&gt;overrides&lt;/em&gt; directory structure looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;override-data/
└── config
 ├── profiles
 │   ├── junos-fw-snmp.yml
 ├── reports
 │   ├── junos-fw-snmp.yml
 └── sources
 └── junos-fw-snmp.yml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I&amp;rsquo;ve used the same file name for these but it could be anything. Resources are referenced via the metadata name key and not by the filename.&lt;/p&gt;
&lt;h4 class="heading-element" id="kagent-bring-up"&gt;&lt;span&gt;Kagent Bring Up&lt;/span&gt;
 &lt;a href="#kagent-bring-up" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Next step is to bring up the container and see what we get, but it seems there is an error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;#34;level&amp;#34;:&amp;#34;error&amp;#34;,&amp;#34;error&amp;#34;:&amp;#34;OID 1.3.6.1.4.1.2636.3.5.2 in table source jnxFirewallCounterTable 
 loaded from config/sources/snmp/juniper.yml also appears in table source junos-fw-snmp 
 loaded from sources/junos-fw-snmp.yml&amp;#34;,&amp;#34;time&amp;#34;:&amp;#34;2024-05-03T16:51:41Z&amp;#34;,&amp;#34;message&amp;#34;:&amp;#34;invalid config&amp;#34;}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This means that kagent is already configured to poll this OID from the file mentioned.
&lt;div class="details admonition note open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Kagent Default Config&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;Kagent is pulling its &lt;em&gt;default configuration&lt;/em&gt; each time is brought up and this is in the &lt;code&gt;/opt/kentik/components/ranger/current/LATEST.zip&lt;/code&gt; file&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
So after unziping the file and looking into the file mentioned we see that the definition is there and the table is polled every five minutes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat config/sources/snmp/juniper.yml | grep FirewallCounter -A3
 jnxFirewallCounterTable: !snmp
 table: 1.3.6.1.4.1.2636.3.5.2
 interval: 5m&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, since we can have reports and profiles referring to existing sources in the &lt;code&gt;LATEST.zip&lt;/code&gt; file we are going to remove the sources definition file and remove the reference in the profiles. Furthermore, we are going to adjust the interval in the profile definition since there is no reason to report more frequently than we gather the data at this point.&lt;/p&gt;
&lt;p&gt;Upon restarting kagent, the &lt;em&gt;overrides&lt;/em&gt; directory is picked up with no errors:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;#34;level&amp;#34;:&amp;#34;info&amp;#34;,&amp;#34;path&amp;#34;:&amp;#34;../local/config&amp;#34;,&amp;#34;time&amp;#34;:&amp;#34;2024-05-03T17:12:58Z&amp;#34;,
 &amp;#34;message&amp;#34;:&amp;#34;optional/override config directory exists, using&amp;#34;}&lt;/code&gt;&lt;/pre&gt;&lt;h4 class="heading-element" id="kentik-portal"&gt;&lt;span&gt;Kentik Portal&lt;/span&gt;
 &lt;a href="#kentik-portal" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;In the portal, the metrics are available under the configured path:&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_001.png" title="/posts/kustom-metrics/img_001.png" data-thumbnail="/posts/kustom-metrics/img_001.png" data-sub-html="&lt;h2&gt;SCHEMA path&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_001.png' alt="/posts/kustom-metrics/img_001.png" height="1098" width="400"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;SCHEMA path&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;p&gt;The table is populating:
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_002.png" title="/posts/kustom-metrics/img_002.png" data-thumbnail="/posts/kustom-metrics/img_002.png" data-sub-html="&lt;h2&gt;Junos Metrics Table&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_002.png' alt="/posts/kustom-metrics/img_002.png" height="311" width="2000"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Junos Metrics Table&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;After a while the chart started graphing as well
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_003.png" title="/posts/kustom-metrics/img_003.png" data-thumbnail="/posts/kustom-metrics/img_003.png" data-sub-html="&lt;h2&gt;Junos Metrics Chart&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_003.png' alt="/posts/kustom-metrics/img_003.png" height="711" width="2000"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Junos Metrics Chart&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;h3 class="heading-element" id="grpc"&gt;&lt;span&gt;GRPC&lt;/span&gt;
 &lt;a href="#grpc" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Let’s try now to get the same via streaming telemetry and GRPC. According to &lt;a href="https://www.juniper.net/documentation/us/en/software/junos/interfaces-telemetry/topics/concept/junos-telemetry-interface-grpc-sensors.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;this&lt;/a&gt; we can get those metrics under the &lt;code&gt;/junos/system/linecard/firewall&lt;/code&gt; path.&lt;/p&gt;
&lt;p&gt;Using gnmic (I could only get data via subscriptions and not get rpc calls):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gnmic -a 10.11.255.1:32767 -u &amp;lt;username&amp;gt;-p &amp;lt;password&amp;gt; --skip-verify sub --mode once --path /junos/system/linecard/firewall
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371632000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.632&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_bpdu_filter__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 2596
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371632000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.632&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=TEST-FIREWALL]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 4004
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 1162
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 75400
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371632000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.632&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_arp_policer__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714403887
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 1652
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/out-of-spec-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-packets&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/out-of-spec-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-bytes&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/offered-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/offered-packets&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/offered-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/offered-bytes&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/transmitted-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/transmitted-packets&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/transmitted-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/transmitted-bytes&amp;#34;: 0
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371632000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.632&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__flowspec_default_inet__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714753321
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 7172
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 1315
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 1876476
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 3311
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 4738920
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-packets&amp;#34;: 6891
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-bytes&amp;#34;: 10336500
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/offered-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/offered-packets&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/offered-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/offered-bytes&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/transmitted-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/transmitted-packets&amp;#34;: 0
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/transmitted-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/transmitted-bytes&amp;#34;: 0
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371633000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.633&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_bpdu_filter__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 2596
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371633000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.633&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=TEST-FIREWALL]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 4004
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 1162
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 75400
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371633000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.633&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_arp_policer__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714403887
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 1652
 }
 }
 ]
}
{
 &amp;#34;source&amp;#34;: &amp;#34;10.11.255.1:32767&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714758367&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714758371633000000,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-03T20:46:11.633&amp;#43;03:00&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__flowspec_default_inet__]/state&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714753321
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;memory-usage/allocated&amp;#34;: 7172
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 1315
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 1876476
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/packets&amp;#34;: 3311
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;counter/bytes&amp;#34;: 4738920
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-packets&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-packets&amp;#34;: 6891
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-bytes&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;policer/out-of-spec-bytes&amp;#34;: 10336500
 }
 }
 ]
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s briefly look at the paths returned to better understand what we are getting via this subscription:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gnmic -a 10.11.255.1:32767 -u &amp;lt;username&amp;gt; -p &amp;lt;password&amp;gt; --skip-verify sub --mode once --path /junos/system/linecard/firewall | grep -e prefix -e Path
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_bpdu_filter__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=TEST-FIREWALL]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/bytes&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_arp_policer__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/out-of-spec-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/out-of-spec-bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/offered-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/offered-bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/transmitted-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=__default_arp_policer__]/transmitted-bytes&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__flowspec_default_inet__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/offered-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/offered-bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/transmitted-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/transmitted-bytes&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_bpdu_filter__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=TEST-FIREWALL]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=SSH-PACKETS]/bytes&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__default_arp_policer__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;junos/firewall[name=__flowspec_default_inet__]/state&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;timestamp&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;memory-usage[name=HEAP]/allocated&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,icmp-type=8]/bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;counter[name=10.11.10.10,*,proto=6,dstport=5201]/bytes&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-packets&amp;#34;,
 &amp;#34;Path&amp;#34;: &amp;#34;policer[name=40K_10.11.10.10,*,proto=6,dstport=5201]/out-of-spec-bytes&amp;#34;,&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It looks like we are getting the allocated memory per filter and the relevant metrics according to if the filter is a counter or policer. Let&amp;rsquo;s create the relevant local overrides files. In the reports file we need extra processing on the data returned from the subscription before it is stored in the database and this is done via the use of starlark scripts.&lt;/p&gt;
&lt;h4 class="heading-element" id="local-configuration-take-1"&gt;&lt;span&gt;Local Configuration (take 1)&lt;/span&gt;
 &lt;a href="#local-configuration-take-1" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Sources file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: junos-fw-grpc
 kind: sources
sources:
 junos-fw-grpc: !gnmi
 path: /junos/system/linecard/firewall/
 mode: SAMPLE
 extra:
 sample_interval: 30s&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Profiles file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: junos-fw-grpc
 kind: profile
profile:
 match:
 sysobjectid:
 - 1.3.6.1.4.1.2636.1.1.1.2.108
 features:
 - gnmi
 reports:
 - junos-fw-grpc
 include:
 - device_name_ip
 sources:
 - junos-fw-grpc&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Reports file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: junos-fw-grpc
 kind: reports
reports:
 /junos/firewall/grpc:
 script: !external
 type: starlark
 file: junos-fw-grpc.star
 interval: 30s&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The starlark script acts as a pre-processor to the data before forming it to influx line protocol and ingesting it in the database. So we have options to manipulate the data according to the use case.&lt;/p&gt;
&lt;p&gt;From the rpc we see that all information is returned under the &lt;code&gt;/junos/firewall/&lt;/code&gt; path so lets see what we get from this. We are going to use the log method to output the dictionary we receive from gnmi in the container logs using a basic starlark script:&lt;/p&gt;
&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Basic Starlark Script&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;load(&amp;#34;ranger&amp;#34;, &amp;#34;source&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;metric&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;device&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;log&amp;#34;)

def execute(report):
    log(&amp;#34;###### STARTING STRALARK #######&amp;#34;)
    data = source.select(&amp;#34;junos/firewall&amp;#34;)
    log(data)
    log(&amp;#34;###### STRALARK FINISHED #######&amp;#34;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is how our overrides directory look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;override-data/
└── config
 ├── profiles
 │   ├── junos-fw-grpc.yml
 │   └── junos-fw-snmp.yml
 ├── reports
 │   ├── junos-fw-grpc.star
 │   ├── junos-fw-grpc.yml
 │   └── junos-fw-snmp.yml
 └── sources
 └── junos-fw-grpc.yml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here is what is returned from starlark when we dump it as a dictionary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
 {
 &amp;#34;state&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658,
 &amp;#34;memory-usage&amp;#34;: [
 {
 &amp;#34;allocated&amp;#34;: 2596,
 &amp;#34;name&amp;#34;: &amp;#34;HEAP&amp;#34;
 }
 ]
 },
 &amp;#34;name&amp;#34;: &amp;#34;__default_bpdu_filter__&amp;#34;
 },
 {
 &amp;#34;state&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714746658,
 &amp;#34;memory-usage&amp;#34;: [
 {
 &amp;#34;allocated&amp;#34;: 4004,
 &amp;#34;name&amp;#34;: &amp;#34;HEAP&amp;#34;
 }
 ],
 &amp;#34;counter&amp;#34;: [
 {
 &amp;#34;packets&amp;#34;: 1341,
 &amp;#34;bytes&amp;#34;: 88064,
 &amp;#34;name&amp;#34;: &amp;#34;SSH-PACKETS&amp;#34;
 }
 ]
 },
 &amp;#34;name&amp;#34;: &amp;#34;TEST-FIREWALL&amp;#34;
 },
 {
 &amp;#34;state&amp;#34;: {
 &amp;#34;policer&amp;#34;: [
 {
 &amp;#34;out-of-spec-packets&amp;#34;: 0,
 &amp;#34;out-of-spec-bytes&amp;#34;: 0,
 &amp;#34;offered-packets&amp;#34;: 0,
 &amp;#34;offered-bytes&amp;#34;: 0,
 &amp;#34;transmitted-packets&amp;#34;: 0,
 &amp;#34;transmitted-bytes&amp;#34;: 0,
 &amp;#34;name&amp;#34;: &amp;#34;__default_arp_policer__&amp;#34;
 }
 ],
 &amp;#34;timestamp&amp;#34;: 1714403887,
 &amp;#34;memory-usage&amp;#34;: [
 {
 &amp;#34;allocated&amp;#34;: 1652,
 &amp;#34;name&amp;#34;: &amp;#34;HEAP&amp;#34;
 }
 ]
 },
 &amp;#34;name&amp;#34;: &amp;#34;__default_arp_policer__&amp;#34;
 },
 {
 &amp;#34;state&amp;#34;: {
 &amp;#34;timestamp&amp;#34;: 1714753321,
 &amp;#34;memory-usage&amp;#34;: [
 {
 &amp;#34;allocated&amp;#34;: 7172,
 &amp;#34;name&amp;#34;: &amp;#34;HEAP&amp;#34;
 }
 ],
 &amp;#34;counter&amp;#34;: [
 {
 &amp;#34;packets&amp;#34;: 36574,
 &amp;#34;bytes&amp;#34;: 52226328,
 &amp;#34;name&amp;#34;: &amp;#34;10.11.10.10,*,icmp-type=8&amp;#34;
 },
 {
 &amp;#34;packets&amp;#34;: 6336,
 &amp;#34;bytes&amp;#34;: 9216704,
 &amp;#34;name&amp;#34;: &amp;#34;10.11.10.10,*,proto=6,dstport=5201&amp;#34;
 }
 ],
 &amp;#34;policer&amp;#34;: [
 {
 &amp;#34;out-of-spec-packets&amp;#34;: 13378,
 &amp;#34;out-of-spec-bytes&amp;#34;: 20067000,
 &amp;#34;offered-packets&amp;#34;: 0,
 &amp;#34;offered-bytes&amp;#34;: 0,
 &amp;#34;transmitted-packets&amp;#34;: 0,
 &amp;#34;transmitted-bytes&amp;#34;: 0,
 &amp;#34;name&amp;#34;: &amp;#34;40K_10.11.10.10,*,proto=6,dstport=5201&amp;#34;
 }
 ]
 },
 &amp;#34;name&amp;#34;: &amp;#34;__flowspec_default_inet__&amp;#34;
 }
]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we got a list of dictionaries. One dictionary per firewall filter containing the allocated memory and the counter or policer names and metrics. Now since the counter metrics are different from the policer one&amp;rsquo;s, it seems wise to report them in different paths on the portal schema. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/junos/firewall/filter/memory/&lt;/code&gt; → will hold the allocated memory for each filter&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/junos/firewall/filter/counters/&lt;/code&gt; → will hold the counter metrics&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/junos/firewall/filter/policers/&lt;/code&gt; → will hold the policer metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 class="heading-element" id="local-configuration-take-2"&gt;&lt;span&gt;Local Configuration (take 2)&lt;/span&gt;
 &lt;a href="#local-configuration-take-2" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Reports - different paths&lt;/b&gt;&lt;/p&gt;
In order to achieve this we are going to adjust our reports file to specify those three different configs, paths and scripts.
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: junos-fw-grpc
 kind: reports
reports:
 /junos/firewall/filter/memory:
 script: !external
 type: starlark
 file: junos-fw-grpc-memory.star
 interval: 30s
 /junos/firewall/filter/counters:
 script: !external
 type: starlark
 file: junos-fw-grpc-counters.star
 interval: 30s
 /junos/firewall/filter/policers:
 script: !external
 type: starlark
 file: junos-fw-grpc-policers.star
 interval: 30s&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Starlark - Memory&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;load(&amp;#34;ranger&amp;#34;, &amp;#34;source&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;metric&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;device&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;log&amp;#34;)

def execute(report):
 log(&amp;#34;###### STLRK - MEMORY START #######&amp;#34;)
 data = source.select(&amp;#34;junos/firewall&amp;#34;)

 if data:
 # iterate over non empty dicts in the list
 for name, memory in [
 (_.get(&amp;#39;name&amp;#39;),
 _[&amp;#39;state&amp;#39;][&amp;#39;memory-usage&amp;#39;][0][&amp;#39;allocated&amp;#39;]
 ) for _ in data if _]:
 record = report.append()
 record.append(&amp;#34;filter_name&amp;#34;, name)
 record.append(&amp;#34;allocated_memory&amp;#34;, memory, metric=True)
 record.append(&amp;#34;device_name&amp;#34;, device().config.name)
 record.append(&amp;#34;device_ip&amp;#34;, device().config.host)
 log(&amp;#34;###### STLRK - MEMORY END #######&amp;#34;)
 else:
 log(&amp;#34;###### STLRK - MEMORY *** EMPTY **** #######&amp;#34;)&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Starlark - Counters&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;load(&amp;#34;ranger&amp;#34;, &amp;#34;source&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;metric&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;device&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;log&amp;#34;)

def execute(report):
 log(&amp;#34;###### STLRK - COUNTERS START #######&amp;#34;)
 data = source.select(&amp;#34;junos/firewall&amp;#34;)

 if data:
 # iterate over non empty dicts that have counter key
 for fname, state in [
 (_.get(&amp;#39;name&amp;#39;),
 _.get(&amp;#39;state&amp;#39;)
 ) for _ in data if _ and _[&amp;#39;state&amp;#39;].get(&amp;#39;counter&amp;#39;)] :

 for cname, packets, bytes in [
 (_.get(&amp;#39;name&amp;#39;) ,
 _.get(&amp;#39;packets&amp;#39;),
 _.get(&amp;#39;bytes&amp;#39;)) for _ in state[&amp;#39;counter&amp;#39;] ]:

 record = report.append()
 record.append(&amp;#34;filter_name&amp;#34;, fname)
 record.append(&amp;#34;counter_name&amp;#34;, cname)
 record.append(&amp;#34;packets&amp;#34;, packets, metric=True)
 record.append(&amp;#34;bytes&amp;#34;, bytes, metric=True)
 record.append(&amp;#34;device_name&amp;#34;, device().config.name)
 record.append(&amp;#34;device_ip&amp;#34;, device().config.host)

 log(&amp;#34;###### STLRK - COUNTERS END #######&amp;#34;)
 else:
 log(&amp;#34;###### STLRK - COUNTERS *** EMPTY **** #######&amp;#34;)&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Starlark - Policers&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;load(&amp;#34;ranger&amp;#34;, &amp;#34;source&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;metric&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;device&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;log&amp;#34;)

metrics = [
 &amp;#39;offered-bytes&amp;#39;,
 &amp;#39;offered-packets&amp;#39;,
 &amp;#39;out-of-spec-bytes&amp;#39;,
 &amp;#39;out-of-spec-packets&amp;#39;,
 &amp;#39;transmitted-bytes&amp;#39;,
 &amp;#39;transmitted-packets&amp;#39;
]

def execute(report):
 log(&amp;#34;###### STLRK - POLICER START #######&amp;#34;)
 data = source.select(&amp;#34;junos/firewall&amp;#34;)

 if data:
 # iterate over non empty dicts that have policer key
 for fname, state in [
 (_.get(&amp;#39;name&amp;#39;),
 _.get(&amp;#39;state&amp;#39;)
 ) for _ in data if _ and _[&amp;#39;state&amp;#39;].get(&amp;#39;policer&amp;#39;)]:

 for policer in state[&amp;#39;policer&amp;#39;]:
 record = report.append()
 record.append(&amp;#34;filter_name&amp;#34;, fname)
 record.append(&amp;#34;policer_name&amp;#34;, policer.pop(&amp;#39;name&amp;#39;))
 # Get metrics defined statically above
 for key in metrics:
 record.append(key, policer.get(key) , metric=True)
 record.append(&amp;#34;device_name&amp;#34;, device().config.name)
 record.append(&amp;#34;device_ip&amp;#34;, device().config.host)

 log(&amp;#34;###### STLRK - POLICER END #######&amp;#34;)
 else:
 log(&amp;#34;###### STLRK - POLICER *** EMPTY **** #######&amp;#34;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And this is our &lt;em&gt;overrides&lt;/em&gt; structure now:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;override-data/
└── config
 ├── profiles
 │   ├── junos-fw-grpc.yml
 │   └── junos-fw-snmp.yml
 ├── reports
 │   ├── junos-fw-grpc-counters.star
 │   ├── junos-fw-grpc-memory.star
 │   ├── junos-fw-grpc-policers.star
 │   ├── junos-fw-grpc.yml
 │   └── junos-fw-snmp.yml
 └── sources
 └── junos-fw-grpc.yml&lt;/code&gt;&lt;/pre&gt;&lt;h4 class="heading-element" id="kentik-portal-1"&gt;&lt;span&gt;Kentik Portal&lt;/span&gt;
 &lt;a href="#kentik-portal-1" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;After restarting kagent, we look at the Portal for the results in the three different paths.&lt;/p&gt;
&lt;p&gt;Here are the &lt;strong&gt;Memory&lt;/strong&gt; metrics for our fitlers:
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_004.png" title="/posts/kustom-metrics/img_004.png" data-thumbnail="/posts/kustom-metrics/img_004.png" data-sub-html="&lt;h2&gt;GRPC Memory metrics&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_004.png' alt="/posts/kustom-metrics/img_004.png" height="653" width="2000"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;GRPC Memory metrics&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Counter&lt;/strong&gt; metrics:
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_005.png" title="/posts/kustom-metrics/img_005.png" data-thumbnail="/posts/kustom-metrics/img_005.png" data-sub-html="&lt;h2&gt;GRPC Counter metrics&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_005.png' alt="/posts/kustom-metrics/img_005.png" height="610" width="2000"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;GRPC Counter metrics&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;And the &lt;strong&gt;Policer&lt;/strong&gt; one&amp;rsquo;s:
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_006.png" title="/posts/kustom-metrics/img_006.png" data-thumbnail="/posts/kustom-metrics/img_006.png" data-sub-html="&lt;h2&gt;GRPC Policer metrics&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_006.png' alt="/posts/kustom-metrics/img_006.png" height="555" width="2000"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;GRPC Policer metrics&lt;/figcaption&gt;
 &lt;/figure&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="ios-xr-flowspec"&gt;&lt;span&gt;IOS-XR Flowspec&lt;/span&gt;
 &lt;a href="#ios-xr-flowspec" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s do the same now for the XRs. Since there is no SNMP for flowspec but there is a dedicated yang model for it let’s see what gnmic has to say:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;get -e json_ietf --path Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow/
[
 {
 &amp;#34;source&amp;#34;: &amp;#34;10.12.255.1&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714928869517180944,
 &amp;#34;time&amp;#34;: &amp;#34;2024-05-05T20:07:49.517180944&amp;#43;03:00&amp;#34;,
 &amp;#34;updates&amp;#34;: [
 {
 &amp;#34;Path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf[vrf-name=default]/afs/af[af-name=IPv4]/flows/flow[flow-notation=Dest:10.11.10.10/32,Proto:=6,DPort:=5201]&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;flow-spec/vrfs/vrf/afs/af/flows/flow&amp;#34;: {
 &amp;#34;active-flow-client&amp;#34;: {
 &amp;#34;action&amp;#34;: [
 {
 &amp;#34;dscp&amp;#34;: 0,
 &amp;#34;ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;rate&amp;#34;: &amp;#34;40000&amp;#34;
 }
 ]
 },
 &amp;#34;flow-notation&amp;#34;: &amp;#34;Dest:10.11.10.10/32,Proto:=6,DPort:=5201&amp;#34;,
 &amp;#34;flow-statistics&amp;#34;: {
 &amp;#34;classified&amp;#34;: {
 &amp;#34;bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;packets&amp;#34;: &amp;#34;0&amp;#34;
 },
 &amp;#34;dropped&amp;#34;: {
 &amp;#34;bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;packets&amp;#34;: &amp;#34;0&amp;#34;
 }
 },
 &amp;#34;matches&amp;#34;: {
 &amp;#34;destination-port&amp;#34;: {
 &amp;#34;uint16_rng_array&amp;#34;: [
 {
 &amp;#34;max&amp;#34;: 5201,
 &amp;#34;min&amp;#34;: 5201
 }
 ]
 },
 &amp;#34;destination-prefix-ipv4&amp;#34;: {
 &amp;#34;mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;10.11.10.10&amp;#34;
 },
 &amp;#34;destination-prefix-ipv6&amp;#34;: {
 &amp;#34;mask&amp;#34;: 0,
 &amp;#34;prefix&amp;#34;: &amp;#34;::&amp;#34;
 },
 &amp;#34;icmp&amp;#34;: {
 &amp;#34;code&amp;#34;: 0,
 &amp;#34;type&amp;#34;: 0
 },
 &amp;#34;ip-protocol&amp;#34;: {
 &amp;#34;uint16_rng_array&amp;#34;: [
 {
 &amp;#34;max&amp;#34;: 6,
 &amp;#34;min&amp;#34;: 6
 }
 ]
 },
 &amp;#34;source-prefix-ipv4&amp;#34;: {
 &amp;#34;mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;
 },
 &amp;#34;source-prefix-ipv6&amp;#34;: {
 &amp;#34;mask&amp;#34;: 0,
 &amp;#34;prefix&amp;#34;: &amp;#34;::&amp;#34;
 },
 &amp;#34;tcp-flag&amp;#34;: {
 &amp;#34;match-any&amp;#34;: false,
 &amp;#34;value&amp;#34;: 0
 }
 }
 }
 }
 },
 {
 &amp;#34;Path&amp;#34;: &amp;#34;Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf[vrf-name=default]/afs/af[af-name=IPv4]/flows/flow[flow-notation=Dest:10.11.10.10/32,ICMPType:=8]&amp;#34;,
 &amp;#34;values&amp;#34;: {
 &amp;#34;flow-spec/vrfs/vrf/afs/af/flows/flow&amp;#34;: {
 &amp;#34;active-flow-client&amp;#34;: {
 &amp;#34;action&amp;#34;: [
 {
 &amp;#34;dscp&amp;#34;: 0,
 &amp;#34;ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;rate&amp;#34;: &amp;#34;0&amp;#34;
 }
 ]
 },
 &amp;#34;flow-notation&amp;#34;: &amp;#34;Dest:10.11.10.10/32,ICMPType:=8&amp;#34;,
 &amp;#34;flow-statistics&amp;#34;: {
 &amp;#34;classified&amp;#34;: {
 &amp;#34;bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;packets&amp;#34;: &amp;#34;0&amp;#34;
 },
 &amp;#34;dropped&amp;#34;: {
 &amp;#34;bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;packets&amp;#34;: &amp;#34;0&amp;#34;
 }
 },
 &amp;#34;matches&amp;#34;: {
 &amp;#34;destination-prefix-ipv4&amp;#34;: {
 &amp;#34;mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;10.11.10.10&amp;#34;
 },
 &amp;#34;destination-prefix-ipv6&amp;#34;: {
 &amp;#34;mask&amp;#34;: 0,
 &amp;#34;prefix&amp;#34;: &amp;#34;::&amp;#34;
 },
 &amp;#34;icmp&amp;#34;: {
 &amp;#34;code&amp;#34;: 255,
 &amp;#34;type&amp;#34;: 8
 },
 &amp;#34;source-prefix-ipv4&amp;#34;: {
 &amp;#34;mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;
 },
 &amp;#34;source-prefix-ipv6&amp;#34;: {
 &amp;#34;mask&amp;#34;: 0,
 &amp;#34;prefix&amp;#34;: &amp;#34;::&amp;#34;
 },
 &amp;#34;tcp-flag&amp;#34;: {
 &amp;#34;match-any&amp;#34;: false,
 &amp;#34;value&amp;#34;: 0
 }
 }
 }
 }
 }
 ]
 }
]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And the equivalent list of paths:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sub --mode once -e json_ietf --path Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow/ --format event
[
 {
 &amp;#34;name&amp;#34;: &amp;#34;default-1714934425&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714934426719000000,
 &amp;#34;tags&amp;#34;: {
 &amp;#34;af_af-name&amp;#34;: &amp;#34;IPv4&amp;#34;,
 &amp;#34;flow_flow-notation&amp;#34;: &amp;#34;Dest:10.11.10.10/32,Proto:=6,DPort:=5201&amp;#34;,
 &amp;#34;source&amp;#34;: &amp;#34;10.12.255.1:57344&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714934425&amp;#34;,
 &amp;#34;vrf_vrf-name&amp;#34;: &amp;#34;&amp;#34;
 },
 &amp;#34;values&amp;#34;: {
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/dscp&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/rate&amp;#34;: &amp;#34;40000&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-port.0/max&amp;#34;: 5201,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-port.0/min&amp;#34;: 5201,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/prefix&amp;#34;: &amp;#34;10.11.10.10&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/code&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/type&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/ip-protocol.0/max&amp;#34;: 6,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/ip-protocol.0/min&amp;#34;: 6,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/match-any&amp;#34;: false,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/value&amp;#34;: 0
 }
 }
]
[
 {
 &amp;#34;name&amp;#34;: &amp;#34;default-1714934425&amp;#34;,
 &amp;#34;timestamp&amp;#34;: 1714934426719000000,
 &amp;#34;tags&amp;#34;: {
 &amp;#34;af_af-name&amp;#34;: &amp;#34;IPv4&amp;#34;,
 &amp;#34;flow_flow-notation&amp;#34;: &amp;#34;Dest:10.11.10.10/32,ICMPType:=8&amp;#34;,
 &amp;#34;source&amp;#34;: &amp;#34;10.12.255.1:57344&amp;#34;,
 &amp;#34;subscription-name&amp;#34;: &amp;#34;default-1714934425&amp;#34;,
 &amp;#34;vrf_vrf-name&amp;#34;: &amp;#34;&amp;#34;
 },
 &amp;#34;values&amp;#34;: {
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/dscp&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv4-nh&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/ipv6-nh&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/action.0/rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/classified/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/bytes&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/dropped/packets&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/mask&amp;#34;: &amp;#34;255.255.255.255&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv4/prefix&amp;#34;: &amp;#34;10.11.10.10&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/destination-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/code&amp;#34;: 255,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/icmp/type&amp;#34;: 8,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/mask&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv4/prefix&amp;#34;: &amp;#34;0.0.0.0&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/mask&amp;#34;: 0,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/source-prefix-ipv6/prefix&amp;#34;: &amp;#34;::&amp;#34;,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/match-any&amp;#34;: false,
 &amp;#34;Cisco-IOS-XR-flowspec-oper:/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/tcp-flag/value&amp;#34;: 0
 }
 }
]
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So we get the &lt;strong&gt;actions&lt;/strong&gt; of the rule, the &lt;strong&gt;statistics&lt;/strong&gt;, as well as the &lt;strong&gt;match configuration&lt;/strong&gt; under the respective paths:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/flow-spec/vrfs/vrf/afs/af/flows/flow/active-flow-client/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/flow-spec/vrfs/vrf/afs/af/flows/flow/flow-statistics/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/flow-spec/vrfs/vrf/afs/af/flows/flow/matches/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 class="heading-element" id="local-configuration-1"&gt;&lt;span&gt;Local Configuration&lt;/span&gt;
 &lt;a href="#local-configuration-1" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;The &lt;em&gt;interesting&lt;/em&gt; metrics are under &lt;code&gt;/flow-statistics&lt;/code&gt; and we get the tags for the &lt;code&gt;vrf&lt;/code&gt; and the &lt;code&gt;address-family&lt;/code&gt;. Let&amp;rsquo;s configure &lt;em&gt;our&lt;/em&gt; local files.&lt;/p&gt;
&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Sources file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: xrv-fspec-grpc
 kind: sources
sources:
 xrv-fspec-grpc: !gnmi
 path: Cisco-IOS-XR-flowspec-oper:flow-spec/vrfs/vrf/afs/af/flows/flow/
 mode: SAMPLE
 extra:
 sample_interval: 30s&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Profiles file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: xrv-fspec-grpc
 kind: profile
profile:
 match:
 sysobjectid:
 - 1.3.6.1.4.1.9.1.2264
 features:
 - gnmi
 reports:
 - xrv-fspec-grpc
 include:
 - device_name_ip
 sources:
 - xrv-fspec-grpc&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;Reports file&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: 1
metadata:
 name: xrv-fspec-grpc
 kind: reports
reports:
 /xrv/flowspec/statistics:
 script: !external
 type: starlark
 file: xrv-fspec-grpc.star
 interval: 30s&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:skyblue;text-align:center"&gt;&lt;b&gt;XR Starlark Script&lt;/b&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;load(&amp;#34;ranger&amp;#34;, &amp;#34;source&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;metric&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;device&amp;#34;)
load(&amp;#34;ranger&amp;#34;, &amp;#34;log&amp;#34;)

def execute(report):
 data = source.select(&amp;#34;flow-spec/vrfs/vrf&amp;#34;)

 for vrf_name, af_name, flow, statistics in [(
 i.get(&amp;#39;vrf-name&amp;#39;),
 y.get(&amp;#39;af-name&amp;#39;),
 z.get(&amp;#39;flow-notation&amp;#39;),
 z.get(&amp;#34;flow-statistics&amp;#34;)
 ) for i in data for y in i[&amp;#39;afs&amp;#39;][&amp;#39;af&amp;#39;] for z in y[&amp;#39;flows&amp;#39;][&amp;#39;flow&amp;#39;] ]:
 if vrf_name == &amp;#34;&amp;#34;:
 vrf_name = &amp;#34;default&amp;#34;
 record = report.append()
 record.append(&amp;#34;vrf_name&amp;#34;, vrf_name)
 record.append(&amp;#34;af_name&amp;#34;, af_name)
 record.append(&amp;#34;flow_rule&amp;#34;, flow)
 record.append(
 &amp;#34;classified_bytes&amp;#34;, statistics[&amp;#39;classified&amp;#39;].get(&amp;#39;bytes&amp;#39;),
 metric=True)
 record.append(
 &amp;#34;classified_packets&amp;#34;, statistics[&amp;#39;classified&amp;#39;].get(&amp;#39;packets&amp;#39;),
 metric=True)
 record.append(
 &amp;#34;dropped_bytes&amp;#34;, statistics[&amp;#39;dropped&amp;#39;].get(&amp;#39;bytes&amp;#39;), metric=True)
 record.append(
 &amp;#34;dropped_packets&amp;#34;, statistics[&amp;#39;dropped&amp;#39;].get(&amp;#39;packets&amp;#39;), metric=True)

 record.append(&amp;#34;device_name&amp;#34;, device().config.name)
 record.append(&amp;#34;device_ip&amp;#34;, device().config.host)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here is our directory structure now with the new files added for XR:
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;override-data/
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;└── config
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ├── profiles
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-grpc.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-snmp.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line hl"&gt;&lt;span class="cl"&gt; │   └── xrv-fspec-grpc.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ├── reports
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-grpc-counters.star
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-grpc-memory.star
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-grpc-policers.star
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-grpc.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; │   ├── junos-fw-snmp.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line hl"&gt;&lt;span class="cl"&gt; │   ├── xrv-fspec-grpc.star
&lt;/span&gt;&lt;/span&gt;&lt;span class="line hl"&gt;&lt;span class="cl"&gt; │   └── xrv-fspec-grpc.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; └── sources
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ├── junos-fw-grpc.yml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line hl"&gt;&lt;span class="cl"&gt; └── xrv-fspec-grpc.yml&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;h4 class="heading-element" id="kentik-portal-2"&gt;&lt;span&gt;Kentik Portal&lt;/span&gt;
 &lt;a href="#kentik-portal-2" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h4&gt;&lt;p&gt;Restarting kagent to pick up the new configuration and here is what we get in the Portal under &lt;code&gt;/xrv/flowspec/statistics&lt;/code&gt;, the configured path in our Reports file:&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kustom-metrics/img_007.png" title="/posts/kustom-metrics/img_007.png" data-thumbnail="/posts/kustom-metrics/img_007.png" data-sub-html="&lt;h2&gt;XR Flowspec metrics&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kustom-metrics/img_007.png' alt="/posts/kustom-metrics/img_007.png" height="701" width="2544"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;XR Flowspec metrics&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;div class="details admonition note open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;No XRv counters&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;Unfortunately, XRv does not report those due to limitations of its virtual dataplane &amp;#x1f622;, but you get the picture&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;Outro&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Well we covered enough ground to demonstrate what is possible currently with Kentik NMS when it comes to custom metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to enable Kentik Universal Agent to poll for specific metrics from devices&lt;/li&gt;
&lt;li&gt;Polling and reporting on a custom SNMP Table&lt;/li&gt;
&lt;li&gt;Polling and reporting on a custom ST path via GRPC&lt;/li&gt;
&lt;li&gt;Associating custom metrics to specific device types&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="right"&gt;&lt;br&gt;&lt;br&gt;&lt;i&gt;...till next time...have fun!!! &lt;/i&gt; &lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="influences-and-reference"&gt;&lt;span&gt;Influences and Reference&lt;/span&gt;
 &lt;a href="#influences-and-reference" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.kentik.com/blog/how-to-configure-kentik-nms-to-collect-custom-snmp-metrics/" target="_blank" rel="external nofollow noopener noreferrer"&gt;How to Configure Kentik NMS to Collect Custom SNMP Metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kentik.com/blog/adding-multiple-custom-metrics-to-kentik-nms/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Adding Multiple Custom Metrics to Kentik NMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kentik.com/blog/adjusting-data-before-sending-it-to-kentik-nms/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Adjusting Data Before Sending It to Kentik NMS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/becos76/kentik-custom-metrics" target="_blank" rel="external nofollow noopener noreferrer"&gt;Repo for this post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>IOS-XR :: Get Your XPATHs, Get Your XPATHs Honey</title><link>https://net4fungr.github.io/posts/xr-get-xpath/</link><pubDate>Mon, 11 Jul 2022 00:00:00 +0300</pubDate><guid>https://net4fungr.github.io/posts/xr-get-xpath/</guid><category domain="https://net4fungr.github.io/categories/telemetry/">Telemetry</category><description>&lt;p&gt;One of the mostly raised questions when you start leveraging MDT is which YANG model and xpath to use to configure the subscription on the device. Up to now, there was little to none help from the box itself, and a lot of searching and experimentation on the models was needed. Apparently this has changed now, and there are two sets of commands that will help in your quest.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s jump on &lt;a href="https://devnetsandbox.cisco.com/RM/Diagram/Index/e83cfd31-ade3-4e15-91d6-3118b867a0dd?diagramType=Topology" target="_blank" rel="external nofollow noopener noreferrer"&gt;DevNet&amp;rsquo;s always-on XRv9000&lt;/a&gt; sandbox and issue some commands.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh admin@sandbox-iosxr-1.cisco.com

Password:


RP/0/RP0/CPU0:ansible-iosxr#
RP/0/RP0/CPU0:ansible-iosxr#show version
Sun Jul 10 22:02:49.475 UTC
Cisco IOS XR Software, Version 7.3.2
Copyright (c) 2013-2021 by Cisco Systems, Inc.

Build Information:
 Built By : ingunawa
 Built On : Wed Oct 13 20:00:36 PDT 2021
 Built Host : iox-ucs-017
 Workspace : /auto/srcarchive17/prod/7.3.2/xrv9k/ws
 Version : 7.3.2
 Location : /opt/cisco/XR/packages/
 Label : 7.3.2-0

cisco IOS-XRv 9000 () processor
System uptime is 2 weeks 5 days 10 hours 35 minutes&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s say we want to find out which model and xpath will give us the sensors for &lt;code&gt;show interfaces&lt;/code&gt;. There was the &lt;em&gt;old&lt;/em&gt; command &lt;code&gt;schema-describe&lt;/code&gt;, but now there is a new kid in town called &lt;code&gt;show telemetry internal&lt;/code&gt; that does the trick.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ansible-iosxr#schema-describe &amp;#34;show interfaces&amp;#34;
Sun Jul 10 22:09:54.304 UTC
Action: get
Path: RootOper.Interfaces.Interface

RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal xpath &amp;#34;show interfaces&amp;#34;
Sun Jul 10 22:11:04.759 UTC
Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So now, we&amp;rsquo;ve got the model and xpath, let&amp;rsquo;s see what will be streamed for just the Bundle interfaces&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal json Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface[interface-name=&amp;#39;Bundle-*&amp;#39;]
Sun Jul 10 22:24:38.169 UTC
{
 &amp;#34;encoding_path&amp;#34;: &amp;#34;Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface&amp;#34;,
 &amp;#34;subscription_id_str&amp;#34;: &amp;#34;app_TEST_200000001&amp;#34;,
 &amp;#34;collection_start_time&amp;#34;: &amp;#34;1657491878258&amp;#34;,
 &amp;#34;msg_timestamp&amp;#34;: &amp;#34;1657491878577&amp;#34;,
 &amp;#34;collection_end_time&amp;#34;: &amp;#34;1657491878577&amp;#34;,
 &amp;#34;node_id_str&amp;#34;: &amp;#34;ansible-iosxr&amp;#34;,
 &amp;#34;data_json&amp;#34;: [
 {
 &amp;#34;keys&amp;#34;: [
 {
 &amp;#34;interface-name&amp;#34;: &amp;#34;Bundle-Ether10&amp;#34;
 }
 ],
 &amp;#34;timestamp&amp;#34;: &amp;#34;1657491878321&amp;#34;,
 &amp;#34;content&amp;#34;: {
 &amp;#34;bandwidth64-bit&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;data-rates&amp;#34;: {
 &amp;#34;peak-output-data-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;input-load&amp;#34;: 0,
 &amp;#34;input-packet-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;output-data-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;peak-input-packet-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;bandwidth&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;load-interval&amp;#34;: 9,
 &amp;#34;output-packet-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;input-data-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;peak-output-packet-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;reliability&amp;#34;: 255,
 &amp;#34;peak-input-data-rate&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;output-load&amp;#34;: 0
 },
 &amp;#34;interface-type&amp;#34;: &amp;#34;IFT_ETHERBUNDLE&amp;#34;,
 &amp;#34;bandwidth&amp;#34;: 0,
 &amp;#34;fast-shutdown&amp;#34;: false,
 &amp;#34;is-intf-logical&amp;#34;: true,
 &amp;#34;speed&amp;#34;: 0,
 &amp;#34;interface-type-information&amp;#34;: {
 &amp;#34;bundle-information&amp;#34;: {},
 &amp;#34;interface-type-info&amp;#34;: &amp;#34;bundle&amp;#34;
 },
 &amp;#34;loopback-configuration&amp;#34;: &amp;#34;no-loopback&amp;#34;,
 &amp;#34;state-transition-count&amp;#34;: 0,
 &amp;#34;last-state-transition-time&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;interface-handle&amp;#34;: &amp;#34;Bundle-Ether10&amp;#34;,
 &amp;#34;is-dampening-enabled&amp;#34;: false,
 &amp;#34;state&amp;#34;: &amp;#34;im-state-down&amp;#34;,
 &amp;#34;mac-address&amp;#34;: {
 &amp;#34;address&amp;#34;: &amp;#34;00:08:20:78:ff:1d&amp;#34;
 },
 &amp;#34;hardware-type-string&amp;#34;: &amp;#34;Aggregated Ethernet interface(s)&amp;#34;,
 &amp;#34;is-l2-looped&amp;#34;: false,
 &amp;#34;line-state&amp;#34;: &amp;#34;im-state-down&amp;#34;,
 &amp;#34;encapsulation&amp;#34;: &amp;#34;ether&amp;#34;,
 &amp;#34;encapsulation-type-string&amp;#34;: &amp;#34;ARPA&amp;#34;,
 &amp;#34;is-l2-transport-enabled&amp;#34;: true,
 &amp;#34;duplexity&amp;#34;: &amp;#34;im-attr-duplex-full&amp;#34;,
 &amp;#34;mtu&amp;#34;: 1514,
 &amp;#34;max-bandwidth64-bit&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;if-index&amp;#34;: 28,
 &amp;#34;max-bandwidth&amp;#34;: 0
 }
 }
 ],
 &amp;#34;collection_id&amp;#34;: &amp;#34;54&amp;#34;
},&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or, by using the old method:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ansible-iosxr#run mdt_exec -s Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface[interface-name=&amp;#39;Bundle-*&amp;#39;]
Sun Jul 10 22:26:48.133 UTC
Enter any key to exit...
 Sub_id 200000001, flag 0, len 0
 Sub_id 200000001, flag 4, len 1440
--------
{&amp;#34;node_id_str&amp;#34;:&amp;#34;ansible-iosxr&amp;#34;,&amp;#34;subscription_id_str&amp;#34;:&amp;#34;app_TEST_200000001&amp;#34;,
&amp;#34;encoding_path&amp;#34;:&amp;#34;Cisco-IOS-XR-pfi-im-cmd-oper:interfaces/interface-xr/interface&amp;#34;,
&amp;#34;collection_id&amp;#34;:&amp;#34;55&amp;#34;,&amp;#34;collection_start_time&amp;#34;:&amp;#34;1657492008249&amp;#34;,&amp;#34;msg_timestamp&amp;#34;:&amp;#34;1657492008548&amp;#34;,
&amp;#34;data_json&amp;#34;:[{&amp;#34;timestamp&amp;#34;:&amp;#34;1657492008306&amp;#34;,&amp;#34;keys&amp;#34;:[{&amp;#34;interface-name&amp;#34;:&amp;#34;Bundle-Ether10&amp;#34;}],
&amp;#34;content&amp;#34;:{&amp;#34;interface-handle&amp;#34;:&amp;#34;Bundle-Ether10&amp;#34;,&amp;#34;interface-type&amp;#34;:&amp;#34;IFT_ETHERBUNDLE&amp;#34;,
&amp;#34;hardware-type-string&amp;#34;:&amp;#34;Aggregated Ethernet interface(s)&amp;#34;,&amp;#34;state&amp;#34;:&amp;#34;im-state-down&amp;#34;,
&amp;#34;line-state&amp;#34;:&amp;#34;im-state-down&amp;#34;,&amp;#34;encapsulation&amp;#34;:&amp;#34;ether&amp;#34;,&amp;#34;encapsulation-type-string&amp;#34;:&amp;#34;ARPA&amp;#34;,
&amp;#34;mtu&amp;#34;:1514,&amp;#34;is-l2-transport-enabled&amp;#34;:true,&amp;#34;state-transition-count&amp;#34;:0,
&amp;#34;last-state-transition-time&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;is-dampening-enabled&amp;#34;:false,&amp;#34;speed&amp;#34;:0,
&amp;#34;duplexity&amp;#34;:&amp;#34;im-attr-duplex-full&amp;#34;,&amp;#34;mac-address&amp;#34;:{&amp;#34;address&amp;#34;:&amp;#34;00:08:20:78:ff:1d&amp;#34;},&amp;#34;bandwidth&amp;#34;:0,
&amp;#34;max-bandwidth&amp;#34;:0,&amp;#34;is-l2-looped&amp;#34;:false,&amp;#34;loopback-configuration&amp;#34;:&amp;#34;no-loopback&amp;#34;,
&amp;#34;fast-shutdown&amp;#34;:false,&amp;#34;interface-type-information&amp;#34;:{&amp;#34;interface-type-info&amp;#34;:&amp;#34;bundle&amp;#34;,
&amp;#34;bundle-information&amp;#34;:{}},&amp;#34;data-rates&amp;#34;:{&amp;#34;input-data-rate&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;input-packet-rate&amp;#34;:&amp;#34;0&amp;#34;,
&amp;#34;output-data-rate&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;output-packet-rate&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;peak-input-data-rate&amp;#34;:&amp;#34;0&amp;#34;,
&amp;#34;peak-input-packet-rate&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;peak-output-data-rate&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;peak-output-packet-rate&amp;#34;:&amp;#34;0&amp;#34;,
&amp;#34;bandwidth&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;load-interval&amp;#34;:9,&amp;#34;output-load&amp;#34;:0,&amp;#34;input-load&amp;#34;:0,&amp;#34;reliability&amp;#34;:255},
&amp;#34;if-index&amp;#34;:28,&amp;#34;is-intf-logical&amp;#34;:true,&amp;#34;bandwidth64-bit&amp;#34;:&amp;#34;0&amp;#34;,&amp;#34;max-bandwidth64-bit&amp;#34;:&amp;#34;0&amp;#34;}}],
&amp;#34;collection_end_time&amp;#34;:&amp;#34;1657492008549&amp;#34;}
--------
 Sub_id 200000001, flag 8, len 0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let&amp;rsquo;s try to &lt;em&gt;start&lt;/em&gt; from an openconfig model.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal xpath openconfig-interfaces
Sun Jul 10 22:39:52.953 UTC
openconfig-interfaces:interfaces/interface/state/counters
openconfig-interfaces:interfaces/interface
openconfig-interfaces:interfaces/interface/subinterfaces/subinterface/state/counters
openconfig-interfaces:interfaces/interface/state
openconfig-interfaces:interfaces/interface/hold-time
openconfig-interfaces:interfaces/interface/subinterfaces/subinterface

# Or old school

RP/0/RP0/CPU0:ansible-iosxr#run mdt_get_gather_paths openconfig-interfaces
Sun Jul 10 22:41:36.554 UTC
openconfig-interfaces:interfaces/interface/state/counters
openconfig-interfaces:interfaces/interface
openconfig-interfaces:interfaces/interface/subinterfaces/subinterface/state/counters
openconfig-interfaces:interfaces/interface/state
openconfig-interfaces:interfaces/interface/hold-time
openconfig-interfaces:interfaces/interface/subinterfaces/subinterface

RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal json openconfig-interfaces:interfaces/interface[name=&amp;#39;Bundle-*&amp;#39;]/state/counters
Sun Jul 10 22:43:59.255 UTC
{
 &amp;#34;encoding_path&amp;#34;: &amp;#34;openconfig-interfaces:interfaces/interface/state&amp;#34;,
 &amp;#34;subscription_id_str&amp;#34;: &amp;#34;app_TEST_200000001&amp;#34;,
 &amp;#34;collection_start_time&amp;#34;: &amp;#34;1657493039807&amp;#34;,
 &amp;#34;msg_timestamp&amp;#34;: &amp;#34;1657493039813&amp;#34;,
 &amp;#34;collection_end_time&amp;#34;: &amp;#34;1657493039813&amp;#34;,
 &amp;#34;node_id_str&amp;#34;: &amp;#34;ansible-iosxr&amp;#34;,
 &amp;#34;data_json&amp;#34;: [
 {
 &amp;#34;keys&amp;#34;: [
 {
 &amp;#34;name&amp;#34;: &amp;#34;Bundle-Ether10&amp;#34;
 }
 ],
 &amp;#34;timestamp&amp;#34;: &amp;#34;1657493039812&amp;#34;,
 &amp;#34;content&amp;#34;: {
 &amp;#34;name&amp;#34;: &amp;#34;Bundle-Ether10&amp;#34;,
 &amp;#34;type&amp;#34;: &amp;#34;iana-if-type:ieee8023adLag&amp;#34;,
 &amp;#34;oper-status&amp;#34;: &amp;#34;DOWN&amp;#34;,
 &amp;#34;enabled&amp;#34;: true,
 &amp;#34;admin-status&amp;#34;: &amp;#34;UP&amp;#34;,
 &amp;#34;logical&amp;#34;: true,
 &amp;#34;mtu&amp;#34;: 1514,
 &amp;#34;ifindex&amp;#34;: 28,
 &amp;#34;last-change&amp;#34;: &amp;#34;0&amp;#34;,
 &amp;#34;loopback-mode&amp;#34;: false,
 &amp;#34;counters&amp;#34;: {
 &amp;#34;carrier-transitions&amp;#34;: &amp;#34;0&amp;#34;
 }
 }
 }
 ],
 &amp;#34;collection_id&amp;#34;: &amp;#34;70&amp;#34;
},&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That is all! Keep a note on the old commands that exists:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;schema-describe&lt;/strong&gt; &lt;em&gt;&amp;ldquo;show command&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;run mdt_get_gather_paths&lt;/strong&gt; &lt;em&gt;&amp;lt;yang model&amp;gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;run mdt_exec&lt;/strong&gt; -s &lt;em&gt;&amp;lt;xpath&amp;gt;&lt;/em&gt; -c &lt;em&gt;&amp;lt;sample interval in msec&amp;gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the new one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RP/0/RP0/CPU0:ansible-iosxr#show telemetry internal ?
 json Display yang sensor paths data in json format
 xpath Display yang sensor paths&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Find out more on &lt;a href="https://xrdocs.io/" target="_blank" rel="external nofollow noopener noreferrer"&gt;xrdocs.io&lt;/a&gt;, in the &lt;a href="https://xrdocs.io/telemetry/tutorials/" target="_blank" rel="external nofollow noopener noreferrer"&gt;telemetry tutorials&lt;/a&gt;&lt;/p&gt;
&lt;p align="right"&gt;...till next time...&lt;em&gt;have fun!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>k8s Ansible</title><link>https://net4fungr.github.io/posts/k8s-ansible/</link><pubDate>Wed, 06 Jul 2022 15:36:24 +0300</pubDate><guid>https://net4fungr.github.io/posts/k8s-ansible/</guid><category domain="https://net4fungr.github.io/categories/ansible/">Ansible</category><description>&lt;img src="https://net4fungr.github.io/posts/k8s-ansible/featured-image.png" alt="featured image" referrerpolicy="no-referrer"&gt;&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;Intro&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;Throughout this post, I am documenting my ansible orientation and ramping-up process towards automating the provisioning of a k8s cluster on ubuntu linux. I believe it is not something too fancy or something that has not been visited over and over again in various other posts, but this is the scrub of my exposure with ansible automation. I tried to make it modular with several playbook imports and task includes executed from a &lt;em&gt;parent&lt;/em&gt; playbook file, rather than having a single long playbook. Ansible &lt;em&gt;roles&lt;/em&gt; are not leveraged &amp;#x1f601;. The &lt;em&gt;code&lt;/em&gt; for this project can be found &lt;a href="https://github.com/becos76/k8s_ansible/" target="_blank" rel="external nofollow noopener noreferrer"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="the-intent"&gt;&lt;span&gt;The Intent&lt;/span&gt;
 &lt;a href="#the-intent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;Let&amp;rsquo;s begin by setting the in-scope items for the project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 20.04 VMs based on cloud images provisioned with a known username/passwd and assigned DHCP IPv4 addresses. (Setting up the VMs &lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1"&gt;reference&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Kubernetes single node cluster version 1.22&lt;/li&gt;
&lt;li&gt;Docker CRI&lt;/li&gt;
&lt;li&gt;Flannel CNI&lt;/li&gt;
&lt;li&gt;Single playbook which calls subsequent playbooks and task lists at runtime&lt;/li&gt;
&lt;li&gt;Kubeadm for cluster setup&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="playbook-overview"&gt;&lt;span&gt;Playbook Overview&lt;/span&gt;
 &lt;a href="#playbook-overview" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;The following mindmap diagram represents the automation tasks flows. &lt;span style="color:red"&gt;Red &lt;/span&gt;lines represent imported playbook files. &lt;span style="color:green"&gt;Green &lt;/span&gt;lines are included task lists files, and &lt;span style="color:#7a28FF"&gt;blue &lt;/span&gt; lines are the actual tasks to be executed.&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/k8s-ansible/play_mmap.png" title="/posts/k8s-ansible/play_mmap.png" data-thumbnail="/posts/k8s-ansible/play_mmap.png" data-sub-html="&lt;h2&gt;k8s Ansible Playbook Flow&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/k8s-ansible/play_mmap.png' alt="/posts/k8s-ansible/play_mmap.png" height="1062" width="800"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;k8s Ansible Playbook Flow&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;p&gt;In short, we start from a single playbook file called &lt;em&gt;start.yml&lt;/em&gt; and we have broken down our flow in three phases. The &lt;em&gt;&lt;strong&gt;init&lt;/strong&gt;&lt;/em&gt; phase covers Steps 01 and 02, and refer to assigning static IPs to our dynamic VMs. Step 01 is about building the mapping from DHCP to Static IPs of our nodes and generating the relevant &lt;em&gt;netplan&lt;/em&gt; configuration files using a jinja2 template. Step 02 covers the application of these configuration files to the VMs.&lt;/p&gt;
&lt;p&gt;Next, is the &lt;em&gt;&lt;strong&gt;pre-deployment&lt;/strong&gt;&lt;/em&gt; phase, or Step 03, which is about preparing the VMs for k8s deployment, i.e. setting hostnames, establishing SSH key authentication with ansible, upgrading, etc.&lt;/p&gt;
&lt;p&gt;The final phase is the &lt;em&gt;&lt;strong&gt;deployment&lt;/strong&gt;&lt;/em&gt; one, where we call our tasks to deploy the k8s cluster upon the relevant control and worker nodes.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;&lt;strong&gt;check&lt;/strong&gt;&lt;/em&gt; phase, although not depicted in the flow, is a very important one during which we do our environment pre-checks in order for the playbook to be executed successfully, i.e. are all hosts declared properly in the ansible hosts file, are all variables declared as they should be,etc.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s expand on the directory structure in order to make things more explicit.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="directory-layout"&gt;&lt;span&gt;Directory Layout&lt;/span&gt;
 &lt;a href="#directory-layout" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Here is how the tree of our ansible playbook &lt;em&gt;home&lt;/em&gt; directory looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.
├── .secrets -------------------&amp;lt; Custom directory to hold sensitive data
│   ├── passwd.yml -------------&amp;lt; Encrypted secrets file
│   └── vault_passwd -----------&amp;lt; Ansible-vault clear text password
├── ansible.cfg ----------------&amp;lt; ansible configuration file
├── checks.yml -----------------&amp;lt; &amp;#34;Pre-checks&amp;#34; playbook - Step 00
├── configs --------------------&amp;lt; Directory to store generated static ip netplan files
├── deployment.yml -------------&amp;lt; &amp;#34;Deploy&amp;#34; phase playbook - Step 04
├── hosts ----------------------&amp;lt; ansible inventory file in ini format
├── init_play.yml --------------&amp;lt; &amp;#34;Init&amp;#34; phase playbook - Step 01
├── pre_deploy.yml -------------&amp;lt; &amp;#34;Pre-deploy&amp;#34; phase playbook - Step 03
├── start.yml ---------------&amp;gt;&amp;gt;&amp;gt;&amp;gt; &amp;#34;Master&amp;#34; playbook
├── tasks ----------------------&amp;lt; Folder to hold all task lists files arranged per phase
│   ├── deploy
│   │   ├── boot_control.yml
│   │   ├── cni.yml
│   │   ├── cri.yml
│   │   ├── packages_general.yml
│   │   ├── packages_kube.yml
│   │   ├── swap.yml
│   │   └── workers.yml
│   ├── init
│   │   └── apply_netplan.yml --&amp;lt; Step 02 playbook
│   └── pre
│   ├── cloud-init.yml
│   ├── hostname.yml
│   ├── hosts.yml
│   ├── reboot.yml
│   ├── sshkeys.yml
│   ├── sudo.yml
│   └── upgrade.yml
├── templates ------------------&amp;lt; Templates default folder
│   └── netplan.j2
└── vars -----------------------&amp;lt; Custom directory to host variables
 └── netplan.yml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Below is the ansible configuration file where we define which file contains the inventory. We instruct ansible not complain if the SSH target hosts are not known. For facts gathering, we only need the network facts and not the hardware ones. We define where is the encryption password for ansible-vault. The &lt;em&gt;callback_whitelist&lt;/em&gt; is very useful if we want to see timing statistics of our playbook execution.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[defaults]
inventory = hosts
host_key_checking = False
gather_subset=!hardware, network
vault_password_file=.secrets/vault_passwd
#callback_whitelist = timer, profile_tasks&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;ansible.cfg&lt;/b&gt;&lt;/p&gt;
&lt;h3 class="heading-element" id="ansible-key-files-overview"&gt;&lt;span&gt;Ansible key files overview&lt;/span&gt;
 &lt;a href="#ansible-key-files-overview" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;p&gt;Here is our inventory file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[all:vars]
ansible_ssh_common_args=&amp;#39;-o UserKnownHostsFile=/dev/null&amp;#39;
ansible_user=ubuntu
ansible_ssh_private_key_file=~/.ssh/id_ansible
k8s_version=1.22.10
k8s_pod_cidr=10.244.0.0/16

[control]
kates-control ansible_host=192.168.1.40

[workers]
kates-node-01 ansible_host=192.168.1.41
kates-node-02 ansible_host=192.168.1.42
kates-node-03 ansible_host=192.168.1.43

[dhcp_hosts]
192.168.1.203
192.168.1.206
192.168.1.208
192.168.1.209&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;hosts&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We split our targets into three groups and declare common variables in the &lt;em&gt;all&lt;/em&gt; section. The &lt;em&gt;ansible_ssh_common_args&lt;/em&gt; variable prevents ansible to complain about host key changes, since these VMs were re-provisioned a lot of times during testing the playbook and were getting the same DHCP addresses. We declare here the SSH user that is used for the initial connection to the &lt;em&gt;dynamic&lt;/em&gt; hosts till the point that these hosts are assigned static IPs and configured with an SSH public key in order for ansible to continue further with the tasks.&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;passwd.yml&lt;/em&gt; file contains the passwords that ansible will use for SSH and &lt;em&gt;sudo&lt;/em&gt; access on the targets. These are used initially and then &lt;em&gt;publickey&lt;/em&gt; and sudoless access is enabled.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ansible-vault view .secrets/passwd.yml
ansible_sudo_pass: &amp;#34;ubuntu123&amp;#34;
ansible_become_pass: &amp;#34;ubuntu123&amp;#34;
ansible_ssh_pass: &amp;#34;ubuntu123&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;.secrets/passwd.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s now check the variables file that will be loaded during play runtime.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
netplan:
 gateway4: 192.168.1.1
 subnet: 24
 dns:
 - 192.168.1.1
 - 8.8.8.8&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;vars/netplan.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;It is a dictionary containing all variables needed to populate the &lt;em&gt;jinja2&lt;/em&gt; template and produce the respective netplan configuration file that will enable assigning static ip to our hosts.&lt;/p&gt;
&lt;p&gt;Here is the &lt;em&gt;jinja2&lt;/em&gt; template file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;network:
 ethernets:
 {{ item.intf }}:
 dhcp4: false
 dhcp6: false
 addresses: [{{ item.newIP }}/{{ netplan.subnet }}]
 gateway4: {{ netplan.gateway4 }}
 nameservers:
 addresses: [{% for dns in netplan.dns %}{{dns}}{%- if not loop.last %}, {% endif %}{% endfor %}]
 version: 2&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;templates/netplan.j2&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;So, this template will iterate over a list of dictionaries that will be created in runtime containing a mapping of &lt;em&gt;dynamic&lt;/em&gt; IP to &lt;em&gt;static&lt;/em&gt; one along with the &lt;em&gt;netplan&lt;/em&gt; variables for each hosts. The outcome will be a netplan config file that will be placed and applied on the target host.
&lt;div class="details admonition note open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Note&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;For DNS entries, since we can have more than one, we append a &lt;em&gt;comma&lt;/em&gt; if it is not the last item in order to build the list.&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Last but not least, here is the &lt;em&gt;master&lt;/em&gt; playbook, or &lt;code&gt;playbook zero&lt;/code&gt; that I like to call it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env ansible-playbook
---
- name: ONE PLAY TO CONTROL ALL
 hosts: all
 gather_facts: no

- name: &amp;#34;&amp;lt;! ################# CHECK :: PRE-FLIGHT CHECKING ################### !&amp;gt;&amp;#34;
 import_playbook: checks.yml

- name: &amp;#34;&amp;lt;! ################# INIT :: PREPARE FOR STATIC IPs ################# !&amp;gt;&amp;#34;
 import_playbook: init_play.yml

- name: &amp;#34;&amp;lt;! ################# INIT :: CHANGE TO STATIC IPs ################### !&amp;gt;&amp;#34;
 import_playbook: tasks/init/apply_netplan.yml

- name: &amp;#34;&amp;lt;! ################# PRE :: PERFORM PRE-DEPLOYMENT TASKS ############ !&amp;gt;&amp;#34;
 import_playbook: pre_deploy.yml

- name: &amp;#34;&amp;lt;! ################# DEPLOY :: PERFORM DEPLOYMENT TASKS ############# !&amp;gt;&amp;#34;
 import_playbook: deployment.yml&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;start.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Pretty straight forward. It is just importing all other playbooks one by one &amp;#x1f604;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="ansible-modules-in-play"&gt;&lt;span&gt;Ansible modules in play&lt;/span&gt;
 &lt;a href="#ansible-modules-in-play" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;The following table lists all ansible modules used in this project in alphabetical order along with a short description on their use.&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;Short Name&lt;/th&gt;
 &lt;th&gt;FQCN&lt;/th&gt;
 &lt;th&gt;Description&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;apt&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.apt&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manages &lt;em&gt;apt&lt;/em&gt; packages in Debian/Ubuntu distros&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;apt_key&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_key_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.apt_key&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manages keys in &lt;em&gt;apt&lt;/em&gt; keyring&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;apt_repository&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_repository_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.apt_repository&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manages &lt;em&gt;apt&lt;/em&gt; repositories&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;assert&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/assert_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.assert&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Evaluates if given expressions are true&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;authorized_key&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/posix/authorized_key_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.posix.authorized_key&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manages SSH authorized keys of user accounts&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;blockinfile&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/blockinfile_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.blockinfile&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manages a block of multi-line text surrounded by customizable marker lines in files&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;command&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.command&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Executes commands on linux targets without invoking a shell&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;copy&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/copy_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.copy&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Copy files to remote linux locations&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;debug&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.debug&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Print statements during execution and can be useful for debugging variables or expressions without necessarily halting the playbook&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;file&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/file_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.file&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manage files, attributes of files, symlinks or directories in linux nodes&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;hostname&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/hostname_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.hostname&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Set the hostname in most linux distros&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;import_playbook&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/import_playbook_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.import_playbook&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Imports a playbook file in the current playbook for execution&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;include_tasks&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_tasks_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.include_tasks&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Dynamically includes a file with a list of tasks to be executed in the current playbook&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;include_vars&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_vars_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.include_vars&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Loads YAML/JSON variables dynamically from a file or directory, recursively, during task runtime&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;lineinfile&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/lineinfile_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.lineinfile&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manage lines in a text file&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;meta&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/meta_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.meta&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Execute ansible &lt;em&gt;actions&lt;/em&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;openssh_keypair&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/community/crypto/openssh_keypair_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;community.crypto.openssh_keypair&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;(Re)Generate OpenSSH private and public keys&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;reboot&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/reboot_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.reboot&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Reboot a machine, wait for it to go down, come back up, and respond to commands&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;replace&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/replace_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.replace&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Replace all instances of a particular string in a file using a back-referenced regular expression&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;set_fact&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/set_fact_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.set_fact&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Set host variable(s) and fact(s)&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;setup&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/setup_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.setup&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Gathers facts about remote hosts&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;shell&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.shell&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Execute shell commands on targets&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;stat&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/stat_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.stat&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Retrieve file or file system status&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;systemd&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.systemd&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manage systemd units&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;template&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.template&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Template a file out to a target host using &lt;em&gt;jinja2&lt;/em&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;user&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/user_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.user&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Manage user accounts and user attributes&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;wait_for&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://docs.ansible.com/ansible/latest/collections/ansible/builtin/wait_for_module.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;ansible.builtin.wait_for&lt;/a&gt;&lt;/td&gt;
 &lt;td&gt;Waits for a condition before continuing&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="phased-execution"&gt;&lt;span&gt;Phased Execution&lt;/span&gt;
 &lt;a href="#phased-execution" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;Let&amp;rsquo;s delve a bit deeper on the phases now. We will just analyse some key tasks to make the logic more explicit.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="the-check-phase"&gt;&lt;span&gt;The &lt;em&gt;check&lt;/em&gt; phase&lt;/span&gt;
 &lt;a href="#the-check-phase" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;As previously states, during this phase we are aiming to check if all variables, files, and configurations are how they are supposed to be, or better how are playbooks want them to be in order to execute correctly. The most popular modules used here are those of &lt;em&gt;debug&lt;/em&gt; and &lt;em&gt;assert&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see for example a simple check on the inventory groups:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: INVENTORY CHECK - SINGLE CONTROL NODE
 debug: 
 msg: &amp;#34;control group is not correctly populated for a single (1) control node&amp;#34;
 when: (not groups.control) or (groups.control|length &amp;gt; 1)
 failed_when: (not groups.control) or (groups.control|length &amp;gt; 1)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What we do here is making sure the group &lt;em&gt;control&lt;/em&gt; is defined and it contains only one target host definition, since we are deploying a single control node cluster. This task will be executed only &lt;code&gt;when&lt;/code&gt; the condition we are checking is &lt;em&gt;false&lt;/em&gt; and will be declared as failed using the &lt;code&gt;failed_when&lt;/code&gt; clause.&lt;/p&gt;
&lt;p&gt;Another simple example is using &lt;em&gt;assert&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: CHECK QUANTITIES
 assert:
 that: groups.dhcp_hosts|length == (groups.control&amp;#43;groups.workers)|length
 quiet: yes
 fail_msg: &amp;#34;Number of DHCP hosts cannot be different of number of K8s nodes&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here, we are checking that we have the same number of &lt;em&gt;dynamic&lt;/em&gt; hosts defined as the total number of k8s nodes, workers and control nodes together, since there will be a one-to-one mapping in the configuration and deployment.&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s see how we check the variables file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: CHECK FOR NETPLAN VARIABLES FILE
 stat:
 path: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;PWD&amp;#39;) }}/vars/netplan.yml&amp;#34;
 register: netplan_file

- debug: msg=&amp;#34;Netplan variables file is not found&amp;#34;
 when: not netplan_file.stat.exists
 failed_when: not netplan_file.stat.exists

- name: INCLUDING NETPLAN VARIABLES
 include_vars:
 dir: &amp;#34;{{ lookup(&amp;#39;ansible.builtin.env&amp;#39;, &amp;#39;PWD&amp;#39;) }}/vars&amp;#34;
 files_matching: netplan.yml

- name: CHECKING NETPLAN VARIABLES
 assert:
 that: 
 - netplan is defined and netplan
 - netplan.gateway4 is defined and netplan.gateway4
 - netplan.subnet is defined and netplan.subnet|int &amp;gt; 0 and netplan.subnet &amp;lt;= 31
 - netplan.dns is defined and netplan.dns
 quiet: yes
 fail_msg: &amp;#34;Make sure all netplan variables are defined correctly&amp;#34;
 success_msg: &amp;#34;Looks Good!&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, we use &lt;em&gt;stat&lt;/em&gt; and &lt;em&gt;debug&lt;/em&gt; to make sure that the file exists in the correct directory. Then we &lt;em&gt;load&lt;/em&gt; it in the play with &lt;em&gt;include_vars&lt;/em&gt; so we can have access to the variables, and finally we check the values with &lt;em&gt;assert&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Finally, using &lt;em&gt;wait_for&lt;/em&gt; we check if there is connectivity to the target hosts and act accordingly. We need the &lt;em&gt;dynamic_hosts&lt;/em&gt; to be alive and the k8s node&amp;rsquo;s IPs to be unreachable.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: CHECK SSH CONNECTIVITY TO DHCP HOSTS
 wait_for:
 port: 22
 host: &amp;#34;{{item}}&amp;#34;
 search_regex: OpenSSH
 delay: 0
 timeout: 2
 loop: &amp;#34;{{groups.dhcp_hosts}}&amp;#34;

- name: CHECK SSH CONNECTIVITY TO K8S NODES
 wait_for:
 port: 22
 host: &amp;#34;{{hostvars[item].ansible_host}}&amp;#34;
 search_regex: OpenSSH
 delay: 0
 timeout: 2
 msg: Should not be alive
 state: stopped
 loop: &amp;#34;{{groups.control&amp;#43;groups.workers}}&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="the-init-phase-steps-01-and-02"&gt;&lt;span&gt;The &lt;em&gt;init&lt;/em&gt; phase (Steps 01 and 02)&lt;/span&gt;
 &lt;a href="#the-init-phase-steps-01-and-02" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;This phase calls two playbook files. As Step 01, we build the &lt;em&gt;dynamic&lt;/em&gt; host mapping to &lt;em&gt;static&lt;/em&gt; k8s node and we create the netplan config files for the hosts locally, thus this playbook is run against localhost. As Step 02, we upload the netplan files and apply the new configuration on the targets.&lt;/p&gt;
&lt;p&gt;Here is the playbook for the first step:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env ansible-playbook
---
- name: &amp;#34;&amp;lt;! ################# INIT :: PREPARE FOR STATIC IPs ################# !&amp;gt;&amp;#34;
 hosts: localhost
 gather_facts: yes
 vars_files:
 - .secrets/passwd.yml
 - vars/netplan.yml
 
 
 tasks:
 - name: GET FACTS OF DHCP NODES
 setup:
 delegate_to: &amp;#34;{{ item }}&amp;#34;
 delegate_facts: true
 loop: &amp;#34;{{groups.dhcp_hosts}}&amp;#34;
 
 - name: PREPARE STATIC MAPPINGS
 set_fact: dhcp_map=&amp;#34;{{ dhcp_map|default([]) &amp;#43; 
 [{
 &amp;#39;oldIP&amp;#39;:hostvars[item.0].ansible_default_ipv4.address,
 &amp;#39;intf&amp;#39;:hostvars[item.0].ansible_default_ipv4.interface,
 &amp;#39;newIP&amp;#39;:hostvars[item.1].ansible_host
 }]
 }}&amp;#34;
 loop: &amp;#34;{{groups.dhcp_hosts|zip(groups.control&amp;#43;groups.workers)|list}}&amp;#34; 
 
 - name: GENERATE NETPLAN CONFIGS
 template:
 src: netplan.j2
 dest: configs/netplan.{{item.oldIP}}
 loop: &amp;#34;{{dhcp_map}}&amp;#34;
 &lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;init_play.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We use the &lt;em&gt;setup&lt;/em&gt; module to connect to &lt;em&gt;dhcp_hosts&lt;/em&gt; and gather their facts. We are interested in their IPv4 assigned address and the network interface name. We then use &lt;em&gt;set_fact&lt;/em&gt; to build our list of dictionaries in order to use it for &lt;em&gt;jinja2&lt;/em&gt; template config creation.&lt;/p&gt;
&lt;p&gt;A sample of the list of dictionaries looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[
 {&amp;#34;oldIP&amp;#34;:&amp;#34;192.168.1.203&amp;#34;,&amp;#34;intf&amp;#34;:&amp;#34;ens3&amp;#34;,&amp;#34;newIP&amp;#34;:&amp;#34;192.168.1.40&amp;#34;},
 {&amp;#34;oldIP&amp;#34;:&amp;#34;192.168.1.204&amp;#34;,&amp;#34;intf&amp;#34;:&amp;#34;ens3&amp;#34;,&amp;#34;newIP&amp;#34;:&amp;#34;192.168.1.41&amp;#34;},
 {&amp;#34;oldIP&amp;#34;:&amp;#34;192.168.1.205&amp;#34;,&amp;#34;intf&amp;#34;:&amp;#34;ens3&amp;#34;,&amp;#34;newIP&amp;#34;:&amp;#34;192.168.1.42&amp;#34;},
 {&amp;#34;oldIP&amp;#34;:&amp;#34;192.168.1.206&amp;#34;,&amp;#34;intf&amp;#34;:&amp;#34;ens3&amp;#34;,&amp;#34;newIP&amp;#34;:&amp;#34;192.168.1.43&amp;#34;}
]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the list is populated, we use the &lt;em&gt;template&lt;/em&gt; module to get the configuration files and output them in the &lt;em&gt;configs&lt;/em&gt; directory appending the &amp;ldquo;OldIP&amp;rdquo; to the filename.&lt;/p&gt;
&lt;p&gt;As a second step, we apply the configs to our target hosts by getting the netplan filename and replacing it with the respective netplan config file generated in the previous step. We make the change and wait for connectivity to the static IPs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env ansible-playbook
---
- name: &amp;#34;&amp;lt;! ################# INIT :: CHANGE TO STATIC IPs ################### !&amp;gt;&amp;#34;
 hosts: dhcp_hosts
 gather_facts: yes
 vars_files:
 - &amp;#34;{{inventory_dir}}/.secrets/passwd.yml&amp;#34;

 tasks:
 - name: GET NETPLAN FILENAME
 shell: ls /etc/netplan
 register: netplan_file
 
 - name: UPLOAD NETPLAN CONFIGS
 copy:
 content: &amp;#34;{{lookup(&amp;#39;file&amp;#39;, &amp;#39;{{inventory_dir}}/configs/netplan.{{ansible_host}}&amp;#39;)}}\n&amp;#34;
 dest: &amp;#34;/etc/netplan/{{netplan_file.stdout}}&amp;#34;
 become: yes

 - name: APPLY NETPLAN SETTINGS
 command: netplan apply
 become: yes
 async: 10
 poll: 0
 
 - name: CHECK CONNECTIVITY TO STATIC IPs
 wait_for:
 port: 22
 host: &amp;#34;{{hostvars[item].ansible_host}}&amp;#34;
 search_regex: OpenSSH
 delay: 20
 timeout: 120
 loop: &amp;#34;{{groups.control&amp;#43;groups.workers}}&amp;#34;
 connection: local
 run_once: yes&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;tasks/init/apply_netplan.yml&lt;/b&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="the-pre-deploy-phase-step-03"&gt;&lt;span&gt;The &lt;em&gt;pre-deploy&lt;/em&gt; phase (Step 03)&lt;/span&gt;
 &lt;a href="#the-pre-deploy-phase-step-03" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Now that we have established that our targets will use their final static IPs, we are going to perform some tasks to prepare them for k8s deployment.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env ansible-playbook
---
- name: &amp;#34;&amp;lt;! ################# PRE :: PERFORM PRE-DEPLOYMENT TASKS ################### !&amp;gt;&amp;#34;
 hosts: all:!dhcp_hosts
 gather_facts: yes
 #any_errors_fatal: no
 vars_files:
 - .secrets/passwd.yml

 tasks:
 - name: &amp;#34;&amp;lt;======================== SSH KEYS ========================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/sshkeys.yml
 
 - name: &amp;#34;&amp;lt;======================== SUDO ============================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/sudo.yml
 
 - name: &amp;#34;&amp;lt;======================== CLOUD-INIT ======================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/cloud-init.yml
 
 - name: &amp;#34;&amp;lt;======================== HOSTNAMES =======================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/hostname.yml
 
 - name: &amp;#34;&amp;lt;======================== HOSTS FILES =====================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/hosts.yml
 
 - name: &amp;#34;&amp;lt;======================== UPDATE/UPGRADE ==================&amp;gt;&amp;#34;
 include_tasks: tasks/pre/upgrade.yml
 
 - name: &amp;#34;&amp;lt;======================== REBOOT ========================-&amp;gt;&amp;#34;
 include_tasks: tasks/pre/reboot.yml 

 - debug: msg=&amp;#34;\u2705 NODE READY FOR DEPLOYMENT&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;pre_deploy.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We first generate an SSH key on localhost and distribute it to all the nodes in order for ansible to access them without using the user password. Then we enable passwordless sudo access for the ansible user. We disable cloud-init if the service is there. Set the correct hostname and configure all k8s nodes in the hosts files, and, finally perform pings between hosts to verify that name resolution and connectivity is successful.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="the-deploy-phase-step-04"&gt;&lt;span&gt;The &lt;em&gt;deploy&lt;/em&gt; phase (Step 04)&lt;/span&gt;
 &lt;a href="#the-deploy-phase-step-04" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;The last phase is to deploy the k8s cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env ansible-playbook
---
- name: K8S DEPLOYMENT
 hosts: all:!dhcp_hosts
 gather_facts: yes
 vars_files:
 - .secrets/passwd.yml

 tasks:
 - name: &amp;#34;&amp;lt;======================== PRE-REQUISITES ===================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/packages_general.yml
 args:
 apply:
 become: yes
 
 - name: &amp;#34;&amp;lt;======================== TURN OFF SWAP ====================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/swap.yml
 
 - name: &amp;#34;&amp;lt;======================== DOCKER CRI =======================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/cri.yml
 args:
 apply:
 become: yes
 
 - name: &amp;#34;&amp;lt;======================== KUBE PACKAGES ====================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/packages_kube.yml
 args:
 apply:
 become: yes

 - name: &amp;#34;&amp;lt;======================= PREPARE THE CONTROL NODE ==========&amp;gt;&amp;#34;
 block:
 - name: &amp;#34;&amp;lt;======================== INIT CONTROL NODE ==========&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/boot_control.yml
 
 - name: &amp;#34;&amp;lt;======================== DEPLOY CNI =================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/cni.yml
 when: inventory_hostname in groups.control
 
 - name: &amp;#34;&amp;lt;===================== ADD WORKER NODES ====================&amp;gt;&amp;#34;
 include_tasks: tasks/deploy/workers.yml
 &lt;/code&gt;&lt;/pre&gt;&lt;p style="background-color:deepskyblue;text-align:center"&gt;&lt;b&gt;deployment.yml&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We start off by installing the prerequisite packages, apt keys and repositories. We then turn off swap if any, in order for &lt;em&gt;kubelet&lt;/em&gt; service to run without issues. Then, we proceed installing docker CRI, changing cgroup to &lt;em&gt;systemd&lt;/em&gt; and assigning the user to docker group. We download &lt;em&gt;kubeadm&lt;/em&gt;, &lt;em&gt;kubectl&lt;/em&gt;, and &lt;em&gt;kubelet&lt;/em&gt; packages. Next, we initialise the control node and install the network CNI plugin. Finally, we join the worker nodes to the cluster.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="optimisations"&gt;&lt;span&gt;Optimisations&lt;/span&gt;
 &lt;a href="#optimisations" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;If we&amp;rsquo;ve reached this stage, it means that everything is working fine, we are happy, so the code is good and we do not need any optimisations or fine tuning &amp;#x1f604;. Well, there is always room for improvement and fine tuning, the only enemy is time.&lt;/p&gt;
&lt;p&gt;I am sure that a more experienced eye could spot many ways to improve the playbook and suggest better ways to do things or use tasks, but here are my observations after finishing the playbook:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Improving Speed&lt;/strong&gt;: During the &lt;em&gt;check&lt;/em&gt; phase, where we check for reachability, I initially used to ping the hosts and act on the result. This was adding a nearly 45 second delay in execution, so I tested with &lt;em&gt;wait_for&lt;/em&gt; towards SSH connectivity and this improved script time tremendously. After all, SSH connectivity is somewhat better than ping reachability, since it is one step further &amp;#x1f604;. What I am suggesting here is to take in mind the end goal of what you are after and figure out a way to do it more meaningful and perhaps faster. For example, if you have a task to create a file in a directory, should you first check if the directory exists? Well, it depends on the use case, but in general the task to create the file will fail if the directory does not exist in the first place and you would be able catch this.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task Consolidation&lt;/strong&gt;: Although this playbook does the job, I think it is just automating a list of steps to achieve the result like one could perform manually on a system. Let&amp;rsquo;s take for example the &lt;em&gt;apt&lt;/em&gt; module that installs packages. The module is called several times to install packages according to the phase of the playbook, but what about if we just used a single &lt;em&gt;apt&lt;/em&gt; task to install all our needed packages from all phases. It would be like having a &lt;em&gt;package installation&lt;/em&gt; phase. Unless for some reason we need discrete stages and actions, I think that looking at the playbook as a holistic entity most probably will reveal tasks that can be consolidated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task Reduction&lt;/strong&gt;: Well, here, the main focus is about the question should I use several tasks to do something or it can be done with a single task or less. As an example, we need to check for the existence of a file. We use the &lt;em&gt;stat&lt;/em&gt; module and register a variable. We then use the &lt;em&gt;debug&lt;/em&gt; module to check the output for success or not. For sure, it will depend on the use case, but another way of treating this could be by just the &lt;em&gt;debug&lt;/em&gt; module and using a file lookup conditional clause for this task.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Best Practices&lt;/strong&gt;: Here, I will not expand more on using ansible roles, or group_vars folder, or avoiding the declarations of variables in the inventory file &amp;#x1f604;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align="right"&gt;...till next time...&lt;em&gt;have fun!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Proxy or not...here I come...</title><link>https://net4fungr.github.io/posts/proxy-or-not/</link><pubDate>Tue, 14 Jun 2022 00:00:00 +0000</pubDate><guid>https://net4fungr.github.io/posts/proxy-or-not/</guid><category domain="https://net4fungr.github.io/categories/linux/">Linux</category><description>&lt;p&gt;There has been a need sometimes that you are on a system that is not permanently set to use a proxy server for internet access and you just want to give one or two curl or wget commands to fetch some files, or vice versa &amp;#x1f604;. In order to avoid exporting the appropriate environment variables in the correct place, you can use the following two methods to enable or disable ad-hoc usage of the proxy server in linux bash.&lt;/p&gt;
&lt;h2 class="heading-element" id="method-one---as-an-executable-preceding-your-actual-command"&gt;&lt;span&gt;Method One - as an executable preceding your actual command&lt;/span&gt;
 &lt;a href="#method-one---as-an-executable-preceding-your-actual-command" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;Just put the following commands in a bash script, make it executable and put it in your path somewhere on the system.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;becos@fossa:~$ cat proxy
#!/bin/bash -eu

###########
## Adjust to your environment
##
HTTP_PROXY=&amp;#34;http://10.10.10.10:8080&amp;#34;
HTTPS_PROXY=&amp;#34;http://10.10.10.10:8080&amp;#34;
NO_PROXY=&amp;#34;localhost,127.0.0.1,$(hostname -i),.domain.com&amp;#34;
###########
http_proxy=&amp;#34;$HTTP_PROXY&amp;#34;
https_proxy=&amp;#34;$HTTPS_PROXY&amp;#34;
no_proxy=&amp;#34;$NO_PROXY&amp;#34;

export HTTP_PROXY HTTPS_PROXY NO_PROXY http_proxy https_proxy no_proxy
exec &amp;#34;$@&amp;#34;

becos@fossa:~$ chmod &amp;#43;x proxy &amp;amp;&amp;amp; sudo mv !$ /usr/local/bin/
chmod &amp;#43;x proxy &amp;amp;&amp;amp; sudo mv proxy /usr/local/bin/&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now you can precede the &lt;strong&gt;proxy&lt;/strong&gt; command just before calling your command that needs the proxy environment variables.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;becos@fossa:~$ proxy curl -sv http://www.google.com &amp;gt; /dev/null
* Uses proxy env variable no_proxy == &amp;#39;localhost,127.0.0.1,192.168.1.5,.domain.com&amp;#39;
* Uses proxy env variable http_proxy == &amp;#39;http://10.10.10.10:8080&amp;#39;
* Trying 10.10.10.10:8080...
* TCP_NODELAY set
^C
becos@fossa:~$&lt;/code&gt;&lt;/pre&gt;&lt;h2 class="heading-element" id="method-two---as-functions-to-the-user-profile"&gt;&lt;span&gt;Method Two - as functions to the user profile&lt;/span&gt;
 &lt;a href="#method-two---as-functions-to-the-user-profile" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;p&gt;You can add these two functions in say your &lt;em&gt;.profile&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function proxyoff
{
 unset http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY
}
function proxyon
{
 http_proxy=&amp;#34;http://10.10.10.10:8080&amp;#34;
 HTTP_PROXY=&amp;#34;$http_proxy&amp;#34;
 https_proxy=&amp;#34;http://10.10.10.10:8080&amp;#34;
 HTTPS_PROXY=&amp;#34;$http_proxy&amp;#34;
 no_proxy=&amp;#34;localhost,127.0.0.1,$(hostname -i),.domain.com&amp;#34;
 NO_PROXY=&amp;#34;$no_proxy&amp;#34;
 export http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, after a new shell, you can use the on and off functions according to your intent.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;becos@fossa:~$ env | grep -i proxy

becos@fossa:~$ proxyon

becos@fossa:~$ env | grep -i proxy
no_proxy=localhost,127.0.0.1,192.168.1.5,.domain.com
https_proxy=http://10.10.10.10:8080
NO_PROXY=localhost,127.0.0.1,192.168.1.5,.domain.com
HTTPS_PROXY=http://10.10.10.10:8080
HTTP_PROXY=http://10.10.10.10:8080
http_proxy=http://10.10.10.10:8080

becos@fossa:~$ proxyoff

becos@fossa:~$ env | grep -i proxy&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&amp;rsquo;s it, I hope it finds a use case.&lt;/p&gt;
&lt;p align="right"&gt;...till next time...&lt;em&gt;have fun!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Kube my router up! - Last Part</title><link>https://net4fungr.github.io/posts/kube-my-router-pt3/</link><pubDate>Mon, 06 Jun 2022 00:00:00 +0300</pubDate><guid>https://net4fungr.github.io/posts/kube-my-router-pt3/</guid><category domain="https://net4fungr.github.io/categories/art-of-labbing/">Art of Labbing</category><description>&lt;img src="https://net4fungr.github.io/posts/kube-my-router-pt3/featured-image-preview.jpg" alt="featured image" referrerpolicy="no-referrer"&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1/#intro"&gt;Intro&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="part-one---setting-up-the-k8s-vms-in-eve-ng"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1/"&gt;Part One - Setting up the k8s VMs in EVE-NG&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#part-one---setting-up-the-k8s-vms-in-eve-ng" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="part-two---deploying-the-k8s-cluster-with-kubeadm"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt2/"&gt;Part Two - Deploying the k8s cluster with kubeadm&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#part-two---deploying-the-k8s-cluster-with-kubeadm" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="last-part---installing-and-testing-kne"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/"&gt;Last Part - Installing and testing KNE&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#last-part---installing-and-testing-kne" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="the-intent"&gt;&lt;span&gt;The Intent&lt;/span&gt;
 &lt;a href="#the-intent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Install Google&amp;rsquo;s KNE on the k8s control node&lt;/li&gt;
&lt;li&gt;Use KNE to create sample topologies&lt;/li&gt;
&lt;li&gt;Test with Nokia srlinux&lt;/li&gt;
&lt;li&gt;Test with Arista cEOS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The time has come to install Google&amp;rsquo;s KNE!!!. We are going to use the k8s control node for KNEs &amp;ldquo;control&amp;rdquo; server, so everything will be installed on it.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="prepare-for-kne-installation"&gt;&lt;span&gt;Prepare for KNE installation&lt;/span&gt;
 &lt;a href="#prepare-for-kne-installation" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;We need &lt;strong&gt;go&lt;/strong&gt; so we are going to install it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Download go
ubuntu@kates-control:~$ wget -q https://go.dev/dl/go1.18.2.linux-amd64.tar.gz

# Install it under our HOME directory
ubuntu@kates-control:~$ tar -xvzf go1.18.2.linux-amd64.tar.gz

# Put it in your PATH
ubuntu@kates-control:~$ export PATH=$PATH:~/go/bin

ubuntu@kates-control:~$ echo !! &amp;gt;&amp;gt; ~/.profile
echo export PATH=$PATH:~/go/bin &amp;gt;&amp;gt; ~/.profile

# Check if it&amp;#39;s working
ubuntu@kates-control:~$ go version
go version go1.18.2 linux/amd64&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="deploy-kne"&gt;&lt;span&gt;Deploy KNE&lt;/span&gt;
 &lt;a href="#deploy-kne" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;div class="details admonition note open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Use of kind&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;KNE requires &lt;strong&gt;kind&lt;/strong&gt; if you are going to use it in a single node. KNE can also deploy a single node k8s using kind and have it run inside a container. Then all the labs will be deployed into this containerised k8s node.&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;OK! We are now ready to install KNE. There are two ways, either install it via go&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ go install github.com/google/kne/kne_cli@latest&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or, clone the repo from github and build it locally, which is what I did.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ git clone https://github.com/google/kne.git
Cloning into &amp;#39;kne&amp;#39;...
remote: Enumerating objects: 2146, done.
remote: Counting objects: 100% (154/154), done.
remote: Compressing objects: 100% (89/89), done.
remote: Total 2146 (delta 66), reused 145 (delta 62), pack-reused 1992
Receiving objects: 100% (2146/2146), 41.28 MiB | 200.00 KiB/s, done.
Resolving deltas: 100% (1052/1052), done.
ubuntu@kates-control:~$

ubuntu@kates-control:~$ cd kne/kne_cli/
ubuntu@kates-control:~/kne/kne_cli$ GOPATH=~/go go install

ubuntu@kates-control:~/kne/kne_cli$ cd
ubuntu@kates-control:~$ kne_cli
Kubernetes Network Emulation CLI. Works with meshnet to create
layer 2 topology used by containers to layout networks in a k8s
environment.

Usage:
 kne_cli [command]

Available Commands:
 completion Generate the autocompletion script for the specified shell
 create Create Topology
 delete Delete Topology
 deploy Deploy cluster.
 help Help about any command
 show Show Topology
 topology Topology commands.

Flags:
 -h, --help help for kne_cli
 --kubecfg string kubeconfig file (default &amp;#34;/home/ubuntu/.kube/config&amp;#34;)
 -v, --verbosity string log level (default &amp;#34;info&amp;#34;)

Use &amp;#34;kne_cli [command] --help&amp;#34; for more information about a command.
ubuntu@kates-control:~$&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="prepare-k8s-cluster-for-kne"&gt;&lt;span&gt;Prepare k8s cluster for KNE&lt;/span&gt;
 &lt;a href="#prepare-k8s-cluster-for-kne" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;We need to install meshnet CNI.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Install meshnet from local manifests
ubuntu@kates-control:~$ kubectl apply -k kne/manifests/meshnet/base/
namespace/meshnet created
customresourcedefinition.apiextensions.k8s.io/topologies.networkop.co.uk created
serviceaccount/meshnet created
clusterrole.rbac.authorization.k8s.io/meshnet-clusterrole created
clusterrolebinding.rbac.authorization.k8s.io/meshnet-clusterrolebinding created
daemonset.apps/meshnet created

# Check for any issues
ubuntu@kates-control:~$ kubectl get events -n meshnet
LAST SEEN TYPE REASON OBJECT MESSAGE
15m Normal Scheduled pod/meshnet-72zz4 Successfully assigned meshnet/meshnet-72zz4 to kates-node-02
15m Normal Pulling pod/meshnet-72zz4 Pulling image &amp;#34;hfam/meshnet:latest&amp;#34;
15m Normal Pulled pod/meshnet-72zz4 Successfully pulled image &amp;#34;hfam/meshnet:latest&amp;#34; in 9.581184132s
15m Normal Created pod/meshnet-72zz4 Created container meshnet
15m Normal Started pod/meshnet-72zz4 Started container meshnet
15m Normal Scheduled pod/meshnet-9vqr2 Successfully assigned meshnet/meshnet-9vqr2 to kates-node-01
15m Normal Pulling pod/meshnet-9vqr2 Pulling image &amp;#34;hfam/meshnet:latest&amp;#34;
15m Normal Pulled pod/meshnet-9vqr2 Successfully pulled image &amp;#34;hfam/meshnet:latest&amp;#34; in 9.716760651s
15m Normal Created pod/meshnet-9vqr2 Created container meshnet
15m Normal Started pod/meshnet-9vqr2 Started container meshnet
15m Normal Scheduled pod/meshnet-fkv2s Successfully assigned meshnet/meshnet-fkv2s to kates-control
15m Normal Pulling pod/meshnet-fkv2s Pulling image &amp;#34;hfam/meshnet:latest&amp;#34;
15m Normal Pulled pod/meshnet-fkv2s Successfully pulled image &amp;#34;hfam/meshnet:latest&amp;#34; in 10.072682996s
15m Normal Created pod/meshnet-fkv2s Created container meshnet
15m Normal Started pod/meshnet-fkv2s Started container meshnet
15m Normal SuccessfulCreate daemonset/meshnet Created pod: meshnet-fkv2s
15m Normal SuccessfulCreate daemonset/meshnet Created pod: meshnet-72zz4
15m Normal SuccessfulCreate daemonset/meshnet Created pod: meshnet-9vqr2


# Check the new namespace
ubuntu@kates-control:~$ kubectl get all -n meshnet
NAME READY STATUS RESTARTS AGE
pod/meshnet-72zz4 1/1 Running 0 15m
pod/meshnet-9vqr2 1/1 Running 0 15m
pod/meshnet-fkv2s 1/1 Running 0 15m

NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
daemonset.apps/meshnet 3 3 3 3 3 kubernetes.io/arch=amd64 15m

# Check the cni
ubuntu@kates-control:~$ sudo cat /etc/cni/net.d/00-meshnet.conflist
{
 &amp;#34;cniVersion&amp;#34;: &amp;#34;0.3.1&amp;#34;,
 &amp;#34;name&amp;#34;: &amp;#34;cbr0&amp;#34;,
 &amp;#34;plugins&amp;#34;: [
 {
 &amp;#34;delegate&amp;#34;: {
 &amp;#34;hairpinMode&amp;#34;: true,
 &amp;#34;isDefaultGateway&amp;#34;: true
 },
 &amp;#34;type&amp;#34;: &amp;#34;flannel&amp;#34;
 },
 {
 &amp;#34;capabilities&amp;#34;: {
 &amp;#34;portMappings&amp;#34;: true
 },
 &amp;#34;type&amp;#34;: &amp;#34;portmap&amp;#34;
 },
 {
 &amp;#34;name&amp;#34;: &amp;#34;meshnet&amp;#34;,
 &amp;#34;type&amp;#34;: &amp;#34;meshnet&amp;#34;,
 &amp;#34;ipam&amp;#34;: {},
 &amp;#34;dns&amp;#34;: {}
 }
 ]
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we need to install metallb in order to access our nodes from outside k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Install from local manifests
ubuntu@kates-control:~$ kubectl apply -f kne/manifests/metallb/namespace.yaml
namespace/metallb-system created

ubuntu@kates-control:~$ kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=&amp;#34;$(openssl rand -base64 128)&amp;#34;
secret/memberlist created

ubuntu@kates-control:~$ kubectl apply -f kne/manifests/metallb/metallb.yaml
Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21&amp;#43;, unavailable in v1.25&amp;#43;
podsecuritypolicy.policy/controller created
podsecuritypolicy.policy/speaker created
serviceaccount/controller created
serviceaccount/speaker created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
role.rbac.authorization.k8s.io/config-watcher created
role.rbac.authorization.k8s.io/pod-lister created
role.rbac.authorization.k8s.io/controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/config-watcher created
rolebinding.rbac.authorization.k8s.io/pod-lister created
rolebinding.rbac.authorization.k8s.io/controller created
daemonset.apps/speaker created
deployment.apps/controller created

ubuntu@kates-control:~$ kubectl get events -n metallb-system
LAST SEEN TYPE REASON OBJECT MESSAGE
70s Normal Scheduled pod/controller-868bf4c94d-dtnmn Successfully assigned metallb-system/controller-868bf4c94d-dtnmn to kates-node-02
70s Normal Pulling pod/controller-868bf4c94d-dtnmn Pulling image &amp;#34;quay.io/metallb/controller:v0.12.1&amp;#34;
52s Normal Pulled pod/controller-868bf4c94d-dtnmn Successfully pulled image &amp;#34;quay.io/metallb/controller:v0.12.1&amp;#34; in 17.316467325s
52s Normal Created pod/controller-868bf4c94d-dtnmn Created container controller
52s Normal Started pod/controller-868bf4c94d-dtnmn Started container controller
70s Normal SuccessfulCreate replicaset/controller-868bf4c94d Created pod: controller-868bf4c94d-dtnmn
70s Normal ScalingReplicaSet deployment/controller Scaled up replica set controller-868bf4c94d to 1
70s Normal Scheduled pod/speaker-hb6ms Successfully assigned metallb-system/speaker-hb6ms to kates-node-02
70s Normal Pulling pod/speaker-hb6ms Pulling image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34;
60s Normal Pulled pod/speaker-hb6ms Successfully pulled image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34; in 9.820655993s
60s Normal Created pod/speaker-hb6ms Created container speaker
60s Normal Started pod/speaker-hb6ms Started container speaker
70s Normal Scheduled pod/speaker-j5gpn Successfully assigned metallb-system/speaker-j5gpn to kates-node-01
70s Normal Pulling pod/speaker-j5gpn Pulling image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34;
59s Normal Pulled pod/speaker-j5gpn Successfully pulled image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34; in 10.835647902s
59s Normal Created pod/speaker-j5gpn Created container speaker
59s Normal Started pod/speaker-j5gpn Started container speaker
70s Normal Scheduled pod/speaker-z9qqw Successfully assigned metallb-system/speaker-z9qqw to kates-control
70s Normal Pulling pod/speaker-z9qqw Pulling image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34;
59s Normal Pulled pod/speaker-z9qqw Successfully pulled image &amp;#34;quay.io/metallb/speaker:v0.12.1&amp;#34; in 11.068649905s
59s Normal Created pod/speaker-z9qqw Created container speaker
59s Normal Started pod/speaker-z9qqw Started container speaker
70s Normal SuccessfulCreate daemonset/speaker Created pod: speaker-z9qqw
70s Normal SuccessfulCreate daemonset/speaker Created pod: speaker-j5gpn
70s Normal SuccessfulCreate daemonset/speaker Created pod: speaker-hb6ms


ubuntu@kates-control:~$ kubectl get all -n metallb-system
NAME READY STATUS RESTARTS AGE
pod/controller-868bf4c94d-qllcz 1/1 Running 0 39s
pod/speaker-2dpxw 1/1 Running 0 39s
pod/speaker-5qgm9 1/1 Running 0 39s

NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
daemonset.apps/speaker 2 2 2 2 2 kubernetes.io/os=linux 39s

NAME READY UP-TO-DATE AVAILABLE AGE
deployment.apps/controller 1/1 1 1 39s

NAME DESIRED CURRENT READY AGE
replicaset.apps/controller-868bf4c94d 1 1 1 39s&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Finally we need a configmap with an ip range to assign addresses from out local network.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ cat &amp;gt; ./metallb-configmap.yaml &amp;lt;&amp;lt; EOF
&amp;gt; apiVersion: v1
&amp;gt; kind: ConfigMap
&amp;gt; metadata:
&amp;gt; namespace: metallb-system
&amp;gt; name: config
&amp;gt; data:
&amp;gt; config: |
&amp;gt; address-pools:
&amp;gt; - name: default
&amp;gt; protocol: layer2
&amp;gt; addresses:
&amp;gt; - 192.168.1.50 - 192.168.1.99
&amp;gt;
&amp;gt; EOF

ubuntu@kates-control:~$ kubectl apply -f metallb-configmap.yaml
configmap/config created

ubuntu@kates-control:~$ kubectl get cm -n metallb-system
NAME DATA AGE
config 1 13s
kube-root-ca.crt 1 4m16s&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="use-kne-to-create-a-basic-topology"&gt;&lt;span&gt;Use KNE to create a basic topology&lt;/span&gt;
 &lt;a href="#use-kne-to-create-a-basic-topology" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Okay now! Let pick a simple sample lab with two linux nodes and spin it up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kne_cli create kne/examples/2node-host.pb.txt
INFO[0000] /home/ubuntu/kne/examples
INFO[0000] Creating manager for: 2node-host
INFO[0000] Trying in-cluster configuration
INFO[0000] Falling back to kubeconfig: &amp;#34;/home/ubuntu/.kube/config&amp;#34;
INFO[0000] Topology:
name: &amp;#34;2node-host&amp;#34;
nodes: &amp;lt;
 name: &amp;#34;vm-1&amp;#34;
 type: HOST
 config: &amp;lt;
 image: &amp;#34;hfam/ubuntu:latest&amp;#34;
 &amp;gt;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;vm-2&amp;#34;
 type: HOST
&amp;gt;
links: &amp;lt;
 a_node: &amp;#34;vm-1&amp;#34;
 a_int: &amp;#34;eth1&amp;#34;
 z_node: &amp;#34;vm-2&amp;#34;
 z_int: &amp;#34;eth1&amp;#34;
&amp;gt;

INFO[0000] Adding Link: vm-1:eth1 vm-2:eth1
INFO[0000] Adding Node: vm-1:UNKNOWN:HOST
INFO[0000] Adding Node: vm-2:UNKNOWN:HOST
INFO[0000] Creating namespace for topology: &amp;#34;2node-host&amp;#34;
INFO[0000] Server Namespace: &amp;amp;Namespace{ObjectMeta:{2node-host 13677a1e-f4fc-42cc-bee8-4484107facb6 139020 0 2022-06-01 13:29:27 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[kubernetes.io/metadata.name:2node-host] map[] [] [] [{kne_cli Update v1 2022-06-01 13:29:27 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:kubernetes.io/metadata.name&amp;#34;:{}}}} }]},Spec:NamespaceSpec{Finalizers:[kubernetes],},Status:NamespaceStatus{Phase:Active,Conditions:[]NamespaceCondition{},},}
INFO[0000] Getting topology specs for namespace 2node-host
INFO[0000] Getting topology specs for node vm-1
INFO[0000] Getting topology specs for node vm-2
INFO[0000] Creating topology for meshnet node vm-2
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:vm-2 GenerateName: Namespace:2node-host SelfLink: UID:b6de0742-35e3-478b-8c40-e7b6f59dc8bf ResourceVersion:139023 Generation:1 CreationTimestamp:2022-06-01 13:29:27 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ZZZ_DeprecatedClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-01 13:29:27 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}} Subresource:}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ZZZ_DeprecatedClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:eth1 LocalIP: PeerIntf:eth1 PeerIP: PeerPod:vm-1 UID:0}]}}
INFO[0000] Creating topology for meshnet node vm-1
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:vm-1 GenerateName: Namespace:2node-host SelfLink: UID:140df03a-15a1-44fe-a57f-47d464f8b9fc ResourceVersion:139024 Generation:1 CreationTimestamp:2022-06-01 13:29:27 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ZZZ_DeprecatedClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-01 13:29:27 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}} Subresource:}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ZZZ_DeprecatedClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:eth1 LocalIP: PeerIntf:eth1 PeerIP: PeerPod:vm-2 UID:0}]}}
INFO[0000] Creating Node Pods
INFO[0000] Creating Pod:
 name:&amp;#34;vm-1&amp;#34; type:HOST config:{command:&amp;#34;/bin/sh&amp;#34; command:&amp;#34;-c&amp;#34; command:&amp;#34;sleep 2000000000000&amp;#34; image:&amp;#34;hfam/ubuntu:latest&amp;#34; entry_command:&amp;#34;kubectl exec -it vm-1 -- sh&amp;#34; config_path:&amp;#34;/etc&amp;#34; config_file:&amp;#34;config&amp;#34;} interfaces:{key:&amp;#34;eth1&amp;#34; value:{int_name:&amp;#34;eth1&amp;#34; peer_name:&amp;#34;vm-2&amp;#34; peer_int_name:&amp;#34;eth1&amp;#34;}}
INFO[0000] no services found
INFO[0000] Node &amp;#34;vm-1&amp;#34; resource created
INFO[0000] Creating Pod:
 name:&amp;#34;vm-2&amp;#34; type:HOST config:{command:&amp;#34;/bin/sh&amp;#34; command:&amp;#34;-c&amp;#34; command:&amp;#34;sleep 2000000000000&amp;#34; image:&amp;#34;alpine:latest&amp;#34; entry_command:&amp;#34;kubectl exec -it vm-2 -- sh&amp;#34; config_path:&amp;#34;/etc&amp;#34; config_file:&amp;#34;config&amp;#34;} interfaces:{key:&amp;#34;eth1&amp;#34; value:{int_name:&amp;#34;eth1&amp;#34; peer_name:&amp;#34;vm-1&amp;#34; peer_int_name:&amp;#34;eth1&amp;#34;}}
INFO[0000] no services found
INFO[0000] Node &amp;#34;vm-2&amp;#34; resource created
INFO[0003] Node &amp;#34;vm-1&amp;#34;: Status RUNNING
INFO[0003] Node &amp;#34;vm-2&amp;#34;: Status RUNNING
INFO[0003] Topology &amp;#34;2node-host&amp;#34; created
Error: failed to check resource kne/examples/2node-host.pb.txt: could not get services for node vm-1: services &amp;#34;service-vm-1&amp;#34; not found
ubuntu@kates-control:~$&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s look in k8s&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl get all -n 2node-host -owide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
pod/vm-1 1/1 Running 0 55s 10.244.115.196 kates-node-01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/vm-2 1/1 Running 0 55s 10.244.209.195 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;

# Attach to the 1st device
ubuntu@kates-control:~$ kubectl exec -n 2node-host -it pod/vm-1 -- bash
Defaulted container &amp;#34;vm-1&amp;#34; out of: vm-1, init-vm-1 (init)
root@vm-1:/#

root@vm-1:/# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
3: eth0@if26: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default
 link/ether d6:75:2e:b9:44:e1 brd ff:ff:ff:ff:ff:ff link-netnsid 0
27: eth1@if27: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/ether 5e:02:2b:e4:66:b2 brd ff:ff:ff:ff:ff:ff link-netnsid 0
root@vm-1

# Configure an IP address on the adapter connected to the 2nd device
root@vm-1:/# ip add add 10.1.1.1/30 dev eth1
root@vm-1:/# exit
exit

# Attach to the 2nd device, do the same and verify that the ping is successful
ubuntu@kates-control:~$ kubectl exec -n 2node-host -it pod/vm-2 -- sh
Defaulted container &amp;#34;vm-2&amp;#34; out of: vm-2, init-vm-2 (init)
/ #
/ # ip link
/ # ip add add 10.1.1.2/30 dev eth1
/ # ping 10.1.1.1
PING 10.1.1.1 (10.1.1.1): 56 data bytes
64 bytes from 10.1.1.1: seq=0 ttl=64 time=3.370 ms
64 bytes from 10.1.1.1: seq=1 ttl=64 time=1.082 ms
64 bytes from 10.1.1.1: seq=2 ttl=64 time=0.844 ms
64 bytes from 10.1.1.1: seq=3 ttl=64 time=1.001 ms
^C
--- 10.1.1.1 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.844/1.574/3.370 ms

# We are learning the MAC of the peer device
/ # ip nei
10.1.1.1 dev eth1 lladdr 5e:02:2b:e4:66:b2 ref 1 used 0/0/0 probes 4 REACHABLE&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Seems working, right? &amp;#x1f604;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="test-nokia-srlinux"&gt;&lt;span&gt;Test Nokia srlinux&lt;/span&gt;
 &lt;a href="#test-nokia-srlinux" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;In order to use the srlinux container we need to have the srlinux controller installed in k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl apply -k https://github.com/srl-labs/srl-controller/config/default
namespace/srlinux-controller created
customresourcedefinition.apiextensions.k8s.io/srlinuxes.kne.srlinux.dev created
serviceaccount/srlinux-controller-controller-manager created
role.rbac.authorization.k8s.io/srlinux-controller-leader-election-role created
clusterrole.rbac.authorization.k8s.io/srlinux-controller-manager-role created
clusterrole.rbac.authorization.k8s.io/srlinux-controller-metrics-reader created
clusterrole.rbac.authorization.k8s.io/srlinux-controller-proxy-role created
rolebinding.rbac.authorization.k8s.io/srlinux-controller-leader-election-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/srlinux-controller-manager-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/srlinux-controller-proxy-rolebinding created
configmap/srlinux-controller-manager-config created
service/srlinux-controller-controller-manager-metrics-service created
deployment.apps/srlinux-controller-controller-manager created

ubuntu@kates-control:~$ kubectl get all -n srlinux-controller

NAME READY STATUS RESTARTS AGE
pod/srlinux-controller-controller-manager-69f6579c6f-skg2j 2/2 Running 0 40s

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/srlinux-controller-controller-manager-metrics-service ClusterIP 10.100.185.117 &amp;lt;none&amp;gt; 8443/TCP 40s

NAME READY UP-TO-DATE AVAILABLE AGE
deployment.apps/srlinux-controller-controller-manager 1/1 1 1 40s

NAME DESIRED CURRENT READY AGE
replicaset.apps/srlinux-controller-controller-manager-69f6579c6f 1 1 1 40s


ubuntu@kates-control:~$ kubectl get events -n srlinux-controller
LAST SEEN TYPE REASON OBJECT MESSAGE
49s Normal LeaderElection configmap/8bce046c.srlinux.dev srlinux-controller-controller-manager-69f6579c6f-skg2j_9e9d41e6-e29c-4abd-849f-39fd019eca72 became leader
49s Normal LeaderElection lease/8bce046c.srlinux.dev srlinux-controller-controller-manager-69f6579c6f-skg2j_9e9d41e6-e29c-4abd-849f-39fd019eca72 became leader
62s Normal Scheduled pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Successfully assigned srlinux-controller/srlinux-controller-controller-manager-69f6579c6f-skg2j to kates-node-02
61s Normal Pulling pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Pulling image &amp;#34;gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0&amp;#34;
57s Normal Pulled pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Successfully pulled image &amp;#34;gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0&amp;#34; in 4.485800395s
57s Normal Created pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Created container kube-rbac-proxy
57s Normal Started pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Started container kube-rbac-proxy
57s Normal Pulling pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Pulling image &amp;#34;ghcr.io/srl-labs/srl-controller:0.3.1&amp;#34;
53s Normal Pulled pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Successfully pulled image &amp;#34;ghcr.io/srl-labs/srl-controller:0.3.1&amp;#34; in 4.313788546s
52s Normal Created pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Created container manager
52s Normal Started pod/srlinux-controller-controller-manager-69f6579c6f-skg2j Started container manager
62s Normal SuccessfulCreate replicaset/srlinux-controller-controller-manager-69f6579c6f Created pod: srlinux-controller-controller-manager-69f6579c6f-skg2j
62s Normal ScalingReplicaSet deployment/srlinux-controller-controller-manager Scaled up replica set srlinux-controller-controller-manager-69f6579c6f to 1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Deploy a sample topology using KNEs sample topologies files.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ cat kne/examples/srlinux/2node-srl-with-cert.pbtxt
name: &amp;#34;2srl-certs&amp;#34;
nodes: {
 name: &amp;#34;r1&amp;#34;
 type: NOKIA_SRL
 config: {
 cert: {
 self_signed: {
 cert_name: &amp;#34;kne-profile&amp;#34;,
 key_name: &amp;#34;N/A&amp;#34;,
 key_size: 4096,
 }
 }
 }
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 services:{
 key: 57400
 value: {
 name: &amp;#34;gnmi&amp;#34;
 inside: 57400
 }
 }
}
nodes: {
 name: &amp;#34;r2&amp;#34;
 type: NOKIA_SRL
 config: {
 cert: {
 self_signed: {
 cert_name: &amp;#34;kne-profile&amp;#34;,
 key_name: &amp;#34;N/A&amp;#34;,
 key_size: 4096,
 }
 }
 }
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
}

links: {
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;e1-1&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;e1-1&amp;#34;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create the topology with 2 SR linux devices.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kne_cli create kne/examples/srlinux/2node-srl-with-cert.pbtxt
INFO[0000] /home/ubuntu/kne/examples/srlinux
INFO[0000] Creating manager for: 2srl-certs
INFO[0000] Trying in-cluster configuration
INFO[0000] Falling back to kubeconfig: &amp;#34;/home/ubuntu/.kube/config&amp;#34;
INFO[0000] Topology:
name: &amp;#34;2srl-certs&amp;#34;
nodes: &amp;lt;
 name: &amp;#34;r1&amp;#34;
 type: NOKIA_SRL
 config: &amp;lt;
 cert: &amp;lt;
 self_signed: &amp;lt;
 cert_name: &amp;#34;kne-profile&amp;#34;
 key_name: &amp;#34;N/A&amp;#34;
 key_size: 4096
 &amp;gt;
 &amp;gt;
 &amp;gt;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 services: &amp;lt;
 key: 57400
 value: &amp;lt;
 name: &amp;#34;gnmi&amp;#34;
 inside: 57400
 &amp;gt;
 &amp;gt;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r2&amp;#34;
 type: NOKIA_SRL
 config: &amp;lt;
 cert: &amp;lt;
 self_signed: &amp;lt;
 cert_name: &amp;#34;kne-profile&amp;#34;
 key_name: &amp;#34;N/A&amp;#34;
 key_size: 4096
 &amp;gt;
 &amp;gt;
 &amp;gt;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
&amp;gt;
links: &amp;lt;
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;e1-1&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;e1-1&amp;#34;
&amp;gt;

INFO[0000] Adding Link: r1:e1-1 r2:e1-1
INFO[0000] Adding Node: r1:UNKNOWN:NOKIA_SRL
INFO[0000] Adding Node: r2:UNKNOWN:NOKIA_SRL
INFO[0000] Creating namespace for topology: &amp;#34;2srl-certs&amp;#34;
INFO[0000] Server Namespace: &amp;amp;Namespace{ObjectMeta:{2srl-certs 3dbfff65-53fe-430a-b4a5-1d8f364b598c 9092 0 2022-06-03 21:30:30 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[kubernetes.io/metadata.name:2srl-certs] map[] [] [] [{kne_cli Update v1 2022-06-03 21:30:30 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:kubernetes.io/metadata.name&amp;#34;:{}}}}}]},Spec:NamespaceSpec{Finalizers:[kubernetes],},Status:NamespaceStatus{Phase:Active,Conditions:[]NamespaceCondition{},},}
INFO[0000] Getting topology specs for namespace 2srl-certs
INFO[0000] Getting topology specs for node r1
INFO[0000] Getting topology specs for node r2
INFO[0000] Creating topology for meshnet node r2
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r2 GenerateName: Namespace:2srl-certs SelfLink: UID:45c4a20d-a803-491d-8a78-9a75603e3f1a ResourceVersion:9095 Generation:1 CreationTimestamp:2022-06-03 21:30:30 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-03 21:30:30 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:e1-1 LocalIP: PeerIntf:e1-1 PeerIP: PeerPod:r1 UID:0}]}}
INFO[0000] Creating topology for meshnet node r1
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r1 GenerateName: Namespace:2srl-certs SelfLink: UID:bda477bd-f318-4a3d-ba2a-a7688c60716b ResourceVersion:9096 Generation:1 CreationTimestamp:2022-06-03 21:30:30 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-03 21:30:30 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:e1-1 LocalIP: PeerIntf:e1-1 PeerIP: PeerPod:r2 UID:0}]}}
INFO[0000] Creating Node Pods
INFO[0000] Creating Srlinux node resource r1
INFO[0000] Created SR Linux node r1 configmap
INFO[0000] Created Srlinux resource: r1
INFO[0000] Created Service:
&amp;amp;Service{ObjectMeta:{service-r1 2srl-certs 776a3f25-05bd-483e-9947-2800efa8e796 9111 0 2022-06-03 21:30:31 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r1] map[] [] [] [{kne_cli Update v1 2022-06-03 21:30:31 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}},&amp;#34;k:{\&amp;#34;port\&amp;#34;:57400,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30742,AppProtocol:nil,},ServicePort{Name:gnmi,Protocol:TCP,Port:57400,TargetPort:{0 57400 },NodePort:30637,AppProtocol:nil,},},Selector:map[string]string{app: r1,},ClusterIP:10.103.94.50,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.103.94.50],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0000] Node &amp;#34;r1&amp;#34; resource created
INFO[0000] Creating Srlinux node resource r2
INFO[0000] Created SR Linux node r2 configmap
INFO[0001] Created Srlinux resource: r2
INFO[0001] Created Service:
&amp;amp;Service{ObjectMeta:{service-r2 2srl-certs 09c1e6e0-0c19-4497-b133-d2b2fa22d20d 9126 0 2022-06-03 21:30:31 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r2] map[] [] [] [{kne_cli Update v1 2022-06-03 21:30:31 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:32417,AppProtocol:nil,},},Selector:map[string]string{app: r2,},ClusterIP:10.111.173.232,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.111.173.232],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}

INFO[0001] Node &amp;#34;r2&amp;#34; resource created
INFO[0001] r1 - generating self signed certs
INFO[0001] r1 - waiting for pod to be running
INFO[0003] r1 - pod running.
INFO[0018] r1 - finshed cert generation
INFO[0018] r2 - generating self signed certs
INFO[0018] r2 - waiting for pod to be running
INFO[0018] r2 - pod running.
INFO[0021] r2 - finshed cert generation
INFO[0022] Node &amp;#34;r1&amp;#34;: Status RUNNING
INFO[0022] Node &amp;#34;r2&amp;#34;: Status RUNNING
INFO[0022] Topology &amp;#34;2srl-certs&amp;#34; created
INFO[0022] Pods:
INFO[0022] r1
INFO[0022] r2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, it may take some time for the last command to complete since it is fetching the images as well. Let&amp;rsquo;s check on k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl get all -n 2srl-certs
NAME READY STATUS RESTARTS AGE
pod/r1 1/1 Running 0 23m
pod/r2 1/1 Running 0 23m

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/service-r1 LoadBalancer 10.103.94.50 192.168.1.50 22:30742/TCP,57400:30637/TCP 23m
service/service-r2 LoadBalancer 10.111.173.232 192.168.1.51 22:32417/TCP 23m

ubuntu@kates-control:~$ kubectl get events -n 2srl-certs
LAST SEEN TYPE REASON OBJECT MESSAGE
23m Normal Scheduled pod/r1 Successfully assigned 2srl-certs/r1 to kates-node-02
23m Normal Pulled pod/r1 Container image &amp;#34;networkop/init-wait:latest&amp;#34; already present on machine
23m Normal Created pod/r1 Created container init-r1
23m Normal Started pod/r1 Started container init-r1
23m Normal Pulled pod/r1 Container image &amp;#34;ghcr.io/nokia/srlinux:latest&amp;#34; already present on machine
23m Normal Created pod/r1 Created container r1
23m Normal Started pod/r1 Started container r1
23m Normal Scheduled pod/r2 Successfully assigned 2srl-certs/r2 to kates-node-01
23m Normal Pulled pod/r2 Container image &amp;#34;networkop/init-wait:latest&amp;#34; already present on machine
23m Normal Created pod/r2 Created container init-r2
23m Normal Started pod/r2 Started container init-r2
23m Normal Pulled pod/r2 Container image &amp;#34;ghcr.io/nokia/srlinux:latest&amp;#34; already present on machine
23m Normal Created pod/r2 Created container r2
23m Normal Started pod/r2 Started container r2
23m Normal IPAllocated service/service-r1 Assigned IP [&amp;#34;192.168.1.50&amp;#34;]
23m Normal nodeAssigned service/service-r1 announcing from node &amp;#34;kates-node-01&amp;#34;
23m Normal IPAllocated service/service-r2 Assigned IP [&amp;#34;192.168.1.51&amp;#34;]
23m Normal nodeAssigned service/service-r2 announcing from node &amp;#34;kates-node-02&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It looks good. From another terminal you can access the devices via SSH to the service IP assigned (admin:admin are the credentials).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ ssh admin@192.168.1.50
The authenticity of host &amp;#39;192.168.1.50 (192.168.1.50)&amp;#39; can&amp;#39;t be established.
ECDSA key fingerprint is SHA256:cJwi5r4UVEVYEX9IAqrThzCrIQUYRRk3y5i5Lnw5hPE.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added &amp;#39;192.168.1.50&amp;#39; (ECDSA) to the list of known hosts.
admin@192.168.1.50&amp;#39;s password:
Using configuration file(s): [&amp;#39;/etc/opt/srlinux/srlinux.rc&amp;#39;]
Welcome to the srlinux CLI.
Type &amp;#39;help&amp;#39; (and press &amp;lt;ENTER&amp;gt;) if you need any help using this.
--{ running }--[ ]--
A:r1#
A:r1# show interface brief
&amp;#43;---------------------&amp;#43;---------------&amp;#43;---------------&amp;#43;---------------&amp;#43;---------------&amp;#43;
| Port | Admin State | Oper State | Speed | Type |
&amp;#43;=====================&amp;#43;===============&amp;#43;===============&amp;#43;===============&amp;#43;===============&amp;#43;
| mgmt0 | enable | down | | |
&amp;#43;---------------------&amp;#43;---------------&amp;#43;---------------&amp;#43;---------------&amp;#43;---------------&amp;#43;
--{ running }--[ ]--
A:r1#&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Hmmm, something is wrong here. We were supposed to get a bunch of interfaces, instead we got only mgmt0 and it is down.
Let&amp;rsquo;s attach to the device shell and check the interfaces with some pings&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs exec -it r1 -- bash
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
[root@r1 /]#
[root@r1 /]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
3: mgmt0@if6: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default
 link/ether 82:98:bc:94:f1:94 brd ff:ff:ff:ff:ff:ff link-netnsid 0
4: gway-2800@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether be:75:15:da:44:66 brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
7: e1-1@if7: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/ether f6:96:83:ff:1f:db brd ff:ff:ff:ff:ff:ff link-netnsid 0

[root@r1 /]# ip add
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
 inet 127.0.0.1/8 scope host lo
 valid_lft forever preferred_lft forever
 inet6 ::1/128 scope host
 valid_lft forever preferred_lft forever
3: mgmt0@if6: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP group default
 link/ether 82:98:bc:94:f1:94 brd ff:ff:ff:ff:ff:ff link-netnsid 0
 inet 10.244.2.53/24 brd 10.244.2.255 scope global eth0
 valid_lft forever preferred_lft forever
 inet6 fe80::8098:bcff:fe94:f194/64 scope link
 valid_lft forever preferred_lft forever
4: gway-2800@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
 link/ether be:75:15:da:44:66 brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
 inet6 fe80::bc75:15ff:feda:4466/64 scope link
 valid_lft forever preferred_lft forever
7: e1-1@if7: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN group default qlen 1000
 link/ether f6:96:83:ff:1f:db brd ff:ff:ff:ff:ff:ff link-netnsid 0
 inet6 fe80::f496:83ff:feff:1fdb/64 scope link
 valid_lft forever preferred_lft forever

[root@r1 /]# ip add add 10.1.1.1/30 dev e1-1
[root@r1 /]# exit
exit

ubuntu@kates-control:~$ kubectl -n 2srl-certs exec -it r2 -- bash
Defaulted container &amp;#34;r2&amp;#34; out of: r2, init-r2 (init)
[root@r2 /]#
[root@r2 /]#
[root@r2 /]# ip add add 10.1.1.2/30 dev e1-1
[root@r2 /]# ping 10.1.1.1
PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=1.99 ms
64 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.804 ms
64 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=0.678 ms
64 bytes from 10.1.1.1: icmp_seq=4 ttl=64 time=0.959 ms
^C
--- 10.1.1.1 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3052ms
rtt min/avg/max/mdev = 0.678/1.108/1.992/0.520 ms&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Seems PODs are communicating fine, and I guess the issues is with the router itself, or should I say the container &amp;#x1f604;. Let&amp;rsquo;s check some logs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs describe pod/r1
&amp;lt; ...omitted...&amp;gt;
Events:
 Type Reason Age From Message
 ---- ------ ---- ---- -------
 Normal Scheduled 36m default-scheduler Successfully assigned 2srl-certs/r1 to kates-node-02
 Normal Pulled 36m kubelet Container image &amp;#34;networkop/init-wait:latest&amp;#34; already present on machine
 Normal Created 36m kubelet Created container init-r1
 Normal Started 36m kubelet Started container init-r1
 Normal Pulled 36m kubelet Container image &amp;#34;ghcr.io/nokia/srlinux:latest&amp;#34; already present on machine
 Normal Created 36m kubelet Created container r1
 Normal Started 36m kubelet Started container r1

# Check to see the boot up logs
ubuntu@kates-control:~$ kubectl -n 2srl-certs logs r1
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
Fri Jun 3 21:30:33 UTC 2022: entrypoint.sh called
Fri Jun 3 21:30:33 UTC 2022: renaming docker interface eth0 to mgmt0
Fri Jun 3 21:30:33 UTC 2022: turning off checksum offloading on mgmt0
Actual changes:
rx-checksumming: off
tx-checksumming: off
 tx-checksum-ip-generic: off
 tx-checksum-sctp: off
tcp-segmentation-offload: off
 tx-tcp-segmentation: off [requested on]
 tx-tcp-ecn-segmentation: off [requested on]
 tx-tcp-mangleid-segmentation: off [requested on]
 tx-tcp6-segmentation: off [requested on]
Fri Jun 3 21:30:33 UTC 2022: starting sshd
ssh-keygen: generating new host keys: RSA DSA ECDSA ED25519
Fri Jun 3 21:30:33 UTC 2022: Calling boot_run script
cat: /sys/class/dmi/id/board_name: No such file or directory
cat: /sys/class/dmi/id/board_name: No such file or directory
/opt/srlinux/bin/bootscript/05_sr_createuser.sh: line 270: !srl_is_running_on_nokia_rootfs: command not found
/opt/srlinux/bin/bootscript/05_sr_createuser.sh: line 282: python: command not found
chmod: cannot access &amp;#39;/dev/console&amp;#39;: No such file or directory
chmod: missing operand after &amp;#39;0664&amp;#39;
Try &amp;#39;chmod --help&amp;#39; for more information.
/usr/bin/find: &amp;#39;/var/log/srlinux/file&amp;#39;: No such file or directory
logmgr_set_env.sh: plain_bootup_start
Fri Jun 3 21:30:35 UTC 2022 logmgr_set_env.sh: restart of rsyslogd
which: no python in (/opt/srlinux/bin:/opt/srlinux/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin)
readlink: missing operand
Try &amp;#39;readlink --help&amp;#39; for more information.
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: Option -m: Invalid argument near character 5
setfacl: Option -m: Invalid argument near character 3
setfacl: Option -m: Invalid argument near character 5
setfacl: Option -m: Invalid argument near character 3
System has not been booted with systemd as init system (PID 1). Can&amp;#39;t operate.
Failed to connect to bus: Host is down
Failed to open connection to &amp;#34;system&amp;#34; message bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory
System has not been booted with systemd as init system (PID 1). Can&amp;#39;t operate.
Failed to connect to bus: Host is down
findfs: unable to resolve &amp;#39;LABEL=EFI-System&amp;#39;
No disk with label EFI-System is found
Failed to set capabilities on file `/usr/sbin/tcpdump&amp;#39; (No such file or directory)
usage: setcap [-q] [-v] [-n &amp;lt;rootid&amp;gt;] (-r|-|&amp;lt;caps&amp;gt;) &amp;lt;filename&amp;gt; [ ... (-r|-|&amp;lt;capsN&amp;gt;) &amp;lt;filenameN&amp;gt; ]

 Note &amp;lt;filename&amp;gt; must be a regular (non-symlink) file.
Fri Jun 3 21:30:37 UTC 2022: entrypoint.sh done, executing sudo bash -c touch /.dockerenv &amp;amp;&amp;amp; /opt/srlinux/bin/sr_linux
No/Invalid license found!
Not starting in a named namespace, giving it the name &amp;#34;srbase&amp;#34;
Unix domain socket directory is /opt/srlinux/var/run/
Log directory is /var/log/srlinux/stdout
 Started supportd: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_supportd --server-mode&amp;#34; &amp;gt;/var/log/srlinux/stdout/supportd.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application supportd is running: PID 1525
 Started dev_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_device_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/dev_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application dev_mgr is running: PID 1548
 Started idb_server: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_idb_server&amp;#34; &amp;gt;/var/log/srlinux/stdout/idb_server.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application idb_server is running: PID 1568
 Started aaa_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_aaa_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/aaa_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started acl_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_acl_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/acl_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started arp_nd_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_arp_nd_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/arp_nd_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started chassis_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_chassis_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/chassis_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started dhcp_client_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_dhcp_client_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/dhcp_client_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started evpn_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_evpn_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/evpn_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started fhs_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_fhs_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/fhs_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started fib_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_fib_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/fib_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started l2_mac_learn_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_l2_mac_learn_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/l2_mac_learn_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started l2_mac_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_l2_mac_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/l2_mac_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started lag_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_lag_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/lag_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started linux_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_linux_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/linux_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started log_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_log_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/log_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started mcid_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_mcid_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/mcid_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started mgmt_server: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_mgmt_server&amp;#34; &amp;gt;/var/log/srlinux/stdout/mgmt_server.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started net_inst_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_net_inst_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/net_inst_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started sdk_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_sdk_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/sdk_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started sflow_sample_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_sflow_sample_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/sflow_sample_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Started xdp_lc_1: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;exec -a sr_xdp_lc_1 ./sr_xdp_lc --slot_num 1&amp;#34; &amp;gt;/var/log/srlinux/stdout/xdp_lc_1.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application aaa_mgr is running: PID 1582
 Application acl_mgr is running: PID 1593
 Application arp_nd_mgr is running: PID 1604
 Application chassis_mgr is running: PID 1615
 Application dhcp_client_mgr is running: PID 1627
 Application evpn_mgr is running: PID 1638
 Application fhs_mgr is running: PID 1649
 Application fib_mgr is running: PID 1662
 Application l2_mac_learn_mgr is running: PID 1673
 Application l2_mac_mgr is running: PID 1687
 Application lag_mgr is running: PID 1706
 Application linux_mgr is running: PID 1717
 Application log_mgr is running: PID 1728
 Application mcid_mgr is running: PID 1741
 Application mgmt_server is running: PID 1755
 Application net_inst_mgr is running: PID 1766
 Application sdk_mgr is running: PID 1777
 Application sflow_sample_mgr is running: PID 1787
 Application xdp_lc_1 is running: PID 1797
 Started xdp_lc_1: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;exec -a sr_xdp_lc_1 ./sr_xdp_lc --slot_num 1&amp;#34; &amp;gt;/var/log/srlinux/stdout/xdp_lc_1.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application xdp_lc_1 is running: PID 2551
[/dev/console unavailable]: 22-06-03 21:30:55.343 sr_app_mgr: Would reboot with reason &amp;#39;AppMgr: xdp_lc_1 has failed&amp;#39; but no-reboot is set&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Well it took me some time to figure out that the last line was the indication that &amp;ldquo;xdp_lc_1&amp;rdquo; represents the process for the line card, i.e. all interfaces were missing.
Let&amp;rsquo;s go into the device shell to check the mentioned log.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@r1 /]# cat /var/log/srlinux/stdout/xdp_lc_1.20220603_213042.log
ERROR: This system does not support &amp;#34;SSSE3&amp;#34;.
Please check that RTE_MACHINE is set correctly.
EAL: FATAL: unsupported cpu type.
EAL: unsupported cpu type.
22-06-03 21:30:42.524202 1797 C common dpdk.cc:925 SRL_ASSERT_MSG Termination handler
========= SRL_ASSERT_MSG in program: sr_xdp_lc_1 =========
=== At: /builds/sr/srlinux/srlutil/dpdk/dpdk.cc:925
=== Condition failed: ((diag &amp;gt; 0))
=== Cannot init DPDK EAL


 0x7a1bad, sr_xdp_lc_1 : srlinux::dpdk::Dpdk::InitEal()&amp;#43;0x159d
 0x7a1cb1, sr_xdp_lc_1 : srlinux::dpdk::Dpdk::Init()&amp;#43;0x11
 0x57c766, sr_xdp_lc_1 : main()&amp;#43;0x236
 0x7fc972aadca3, /lib64/libc.so.6 : __libc_start_main()&amp;#43;0xf3
 0x59268e, sr_xdp_lc_1 : _start()&amp;#43;0x2e
==============================
=== Program: sr_xdp_lc_1
/builds/sr/srlinux/srlutil/dpdk/dpdk.cc:925 | condition failed ((diag &amp;gt; 0)) | Cannot init DPDK EAL&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After some googling around, It seems that SSSE3 is not there in the CPU.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ lscpu
Architecture: x86_64
CPU op-mode(s): 32-bit, 64-bit
Byte Order: Little Endian
Address sizes: 40 bits physical, 48 bits virtual
CPU(s): 8
On-line CPU(s) list: 0-7
Thread(s) per core: 1
Core(s) per socket: 1
Socket(s): 8
NUMA node(s): 1
Vendor ID: GenuineIntel
CPU family: 6
Model: 6
Model name: QEMU Virtual CPU version 2.5&amp;#43;
Stepping: 3
CPU MHz: 2496.000
BogoMIPS: 4992.00
Hypervisor vendor: KVM
Virtualization type: full
L1d cache: 256 KiB
L1i cache: 256 KiB
L2 cache: 32 MiB
L3 cache: 128 MiB
NUMA node0 CPU(s): 0-7
Vulnerability Itlb multihit: KVM: Vulnerable
Vulnerability L1tf: Mitigation; PTE Inversion
Vulnerability Mds: Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown
Vulnerability Meltdown: Mitigation; PTI
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1: Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2: Mitigation; Retpolines, STIBP disabled, RSB filling
Vulnerability Srbds: Not affected
Vulnerability Tsx async abort: Not affected
Flags: fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 syscall nx lm rep_good nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s check on EVE-NGs CPU because I don&amp;rsquo;t think the processor is too old &amp;#x1f604;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01:~# lscpu | grep Flags
Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, it is there, but QEMU is not exposing it to the guest machines, which is an easy fix &amp;#x1f604; rather than deprecating the EVE-NGs. The fix is to append the parameters &lt;strong&gt;-cpu qemu64,+ssse3,+sse4.1,+sse4.2&lt;/strong&gt; to the qemu command line for booting the VMs, but only after shutting down all 3 nodes to apply the change, as depicted below.&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kube-my-router-pt3/ssse3.png" title="/posts/kube-my-router-pt3/ssse3.png" data-thumbnail="/posts/kube-my-router-pt3/ssse3.png" data-sub-html="&lt;h2&gt;Missing CPU instruction set for SR Linux&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kube-my-router-pt3/ssse3.png' alt="/posts/kube-my-router-pt3/ssse3.png" height="385" width="400"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Missing CPU instruction set for SR Linux&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;p&gt;Yet again if you want to make this the default for all linux VMs on your EVE-NG, you could append this to the template.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01:~# cat /opt/unetlab/html/templates/intel/linux.yml | grep -v &amp;#34;#&amp;#34;
---
type: qemu
description: Linux
name: Linux
cpulimit: 1
icon: Server.png
cpu: 2
ram: 4096
ethernet: 1
console: vnc
shutdown: 1
qemu_arch: x86_64
qemu_version: 2.12.0
qemu_nic: virtio-net-pci
qemu_options: -machine type=pc,accel=kvm -vga virtio -usbdevice tablet -boot order=cd -cpu qemu64,&amp;#43;ssse3,&amp;#43;sse4.1,&amp;#43;sse4.2
...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After applying the &amp;ldquo;patch&amp;rdquo; and bringing up all nodes, everything should look better.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs get all
NAME READY STATUS RESTARTS AGE
pod/r1 1/1 Running 1 63m
pod/r2 1/1 Running 1 63m

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
service/service-r1 LoadBalancer 10.103.94.50 192.168.1.50 22:30742/TCP,57400:30637/TCP 63m
service/service-r2 LoadBalancer 10.111.173.232 192.168.1.51 22:32417/TCP 63m

ubuntu@kates-control:~$ ssh admin@192.168.1.50
admin@192.168.1.50&amp;#39;s password:
Using configuration file(s): [&amp;#39;/etc/opt/srlinux/srlinux.rc&amp;#39;]
Welcome to the srlinux CLI.
Type &amp;#39;help&amp;#39; (and press &amp;lt;ENTER&amp;gt;) if you need any help using this.
--{ [FACTORY] running }--[ ]--
A:r1# show interface brief
&amp;#43;---------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;
| Port | Admin State | Oper State | Speed | Type |
&amp;#43;=====================&amp;#43;=======================&amp;#43;=======================&amp;#43;=======================&amp;#43;=======================&amp;#43;
| ethernet-1/1 | disable | down | 25G | |
| ethernet-1/2 | disable | down | 25G | |
| ethernet-1/3 | disable | down | 25G | |
| ethernet-1/4 | disable | down | 25G | |
| ethernet-1/5 | disable | down | 25G | |
| ethernet-1/6 | disable | down | 25G | |
| ethernet-1/7 | disable | down | 25G | |

&amp;lt; ...omitted... &amp;gt;

| ethernet-1/53 | disable | down | 100G | |
| ethernet-1/54 | disable | down | 100G | |
| ethernet-1/55 | disable | down | 100G | |
| ethernet-1/56 | disable | down | 100G | |
| mgmt0 | enable | up | 1G | |
&amp;#43;---------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;-----------------------&amp;#43;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can now proceed with the ping testing, this time from within the box &amp;#x1f604;. Let&amp;rsquo;s apply some configs on the interfaces.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A:r1# diff flat
insert / interface ethernet-1/1
insert / interface ethernet-1/1 admin-state enable
insert / interface ethernet-1/1 subinterface 0
insert / interface ethernet-1/1 subinterface 0 ipv4
insert / interface ethernet-1/1 subinterface 0 ipv4 address 10.1.1.1/30
insert / network-instance main
insert / network-instance main interface ethernet-1/1.0
A:r1# commit now
All changes have been committed. Leaving candidate mode.
--{ [FACTORY] &amp;#43; running }--[ ]--
A:r1# show interface ethernet-1/1
==========================================================================================================================
ethernet-1/1 is down, reason lower-layer-down
 ethernet-1/1.0 is down, reason port-down
 Network-instance: main
 Encapsulation : null
 Type : routed
 IPv4 addr : 10.1.1.1/30 (static, None)
--------------------------------------------------------------------------------------------------------------------------
==========================================================================================================================
--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--
A:r1#&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I guess we still have a &lt;em&gt;lower layer&lt;/em&gt; problem. Let&amp;rsquo;s get a shell into the box and check the logs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs exec -it r1 -- bash
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
[root@r1 /]# tail /var/log/messages
Jun 8 12:50:02 r1 sr_net_inst_mgr: netinst|1704|1704|00013|N: The interface mgmt0.0 in network-instance mgmt is now up
Jun 8 12:51:19 r1 sr_aaa_mgr: aaa|1528|1650|00000|N: Opened session for user admin from host 10.244.0.0
Jun 8 12:51:19 r1 sr_aaa_mgr: aaa|1528|1650|00001|N: User admin successfully authenticated from host 10.244.0.0
Jun 8 12:55:44 r1 sr_mgmt_server: mgmt|1693|1693|00020|I: All changes have been committed successfully by user admin session 1.
Jun 8 12:55:44 r1 sr_xdp_lc_1: debug|1739|1814|00001|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 32684 (0x7fac)): Operation not supported (95)
Jun 8 12:55:44 r1 sr_xdp_lc_1: debug|1739|1814|00003|E: common netdevice.c:182 NetDeviceSetMTU ioctl(SIOCSIFMTU, &amp;#34;e1-1&amp;#34;, 9232): Invalid argument (22)
Jun 8 12:55:44 r1 sr_xdp_lc_1: debug|1739|1814|00004|E: simif sim_physif.cc:764 UpdateAdminState error setting mtu for interface &amp;#34;ethernet-1/1&amp;#34; mtu: 9232
Jun 8 12:55:44 r1 sr_xdp_lc_1: debug|1739|1814|00005|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 26571 (0x67cb)): Operation not supported (95)
Jun 8 12:55:44 r1 sr_net_inst_mgr: netinst|1704|1704|00014|N: Network Instance main is now up
Jun 8 12:55:45 r1 sr_net_inst_mgr: netinst|1704|1704|00015|W: The interface ethernet-1/1.0 in network-instance main is now down for reason: the subinterface is operationally down

[root@r1 ~]# tail /var/log/srlinux/debug/errors.log
2022-06-08T12:55:44.990045&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00001|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 32684 (0x7fac)): Operation not supported (95)
2022-06-08T12:55:44.990171&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00003|E: common netdevice.c:182 NetDeviceSetMTU ioctl(SIOCSIFMTU, &amp;#34;e1-1&amp;#34;, 9232): Invalid argument (22)
2022-06-08T12:55:44.990193&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00004|E: simif sim_physif.cc:764 UpdateAdminState error setting mtu for interface &amp;#34;ethernet-1/1&amp;#34; mtu: 9232
2022-06-08T12:55:44.990805&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00005|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 26571 (0x67cb)): Operation not supported (95)

[root@r1 ~]# tail /var/log/srlinux/debug/sr_xdp_lc_1.log
2022-06-08T12:55:44.990045&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00001|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 32684 (0x7fac)): Operation not supported (95)
2022-06-08T12:55:44.990087&amp;#43;00:00 r1 local6|WARN sr_xdp_lc_1: debug|1739|1814|00002|W: simif sim_physif.cc:218 GetInterfaceSpeed Unable to get speed for interface: e1-1
2022-06-08T12:55:44.990171&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00003|E: common netdevice.c:182 NetDeviceSetMTU ioctl(SIOCSIFMTU, &amp;#34;e1-1&amp;#34;, 9232): Invalid argument (22)
2022-06-08T12:55:44.990193&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00004|E: simif sim_physif.cc:764 UpdateAdminState error setting mtu for interface &amp;#34;ethernet-1/1&amp;#34; mtu: 9232
2022-06-08T12:55:44.990805&amp;#43;00:00 r1 local6|ERR sr_xdp_lc_1: debug|1739|1814|00005|E: common netdevice.c:355 NetDeviceGetSpeed ioctl(SIOCETHTOOL, &amp;#34;e1-1&amp;#34;, 1 (0x1), 26571 (0x67cb)): Operation not supported (95)
2022-06-08T12:55:44.990828&amp;#43;00:00 r1 local6|WARN sr_xdp_lc_1: debug|1739|1814|00006|W: simif sim_physif.cc:218 GetInterfaceSpeed Unable to get speed for interface: e1-1
2022-06-08T12:55:45.006160&amp;#43;00:00 r1 local6|WARN sr_xdp_lc_1: debug|1739|2066|00009|W: cpmgr cp_mgr.cc:1595 CpMgrExtractFrameHandler interface 2147483647 not found for reason MLD
2022-06-08T12:55:45.018077&amp;#43;00:00 r1 local6|WARN sr_xdp_lc_1: debug|1739|2066|00010|W: cpmgr cp_mgr.cc:1595 CpMgrExtractFrameHandler interface 2147483647 not found for reason MLD
2022-06-08T12:55:45.658478&amp;#43;00:00 r1 local6|WARN sr_xdp_lc_1: debug|1739|2066|00011|W: cpmgr cp_mgr.cc:1595 CpMgrExtractFrameHandler interface 2147483647 not found for reason MLD&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It seems we have an MTU issue for the 25G interfaces that by default get 9232. Maybe if we specify a lower MTU and set speed to 1G&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--
A:r1# info flat interface ethernet-1/1
set / interface ethernet-1/1
set / interface ethernet-1/1 admin-state enable
set / interface ethernet-1/1 mtu 1500
set / interface ethernet-1/1 ethernet
set / interface ethernet-1/1 ethernet port-speed 1G
set / interface ethernet-1/1 subinterface 0
set / interface ethernet-1/1 subinterface 0 ipv4
set / interface ethernet-1/1 subinterface 0 ipv4 address 10.1.1.1/30
--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--

A:r1# show interface ethernet-1/1
==========================================================================
ethernet-1/1 is down, reason lower-layer-down
 ethernet-1/1.0 is down, reason ip-mtu-too-large
 Network-instance: main
 Encapsulation : null
 Type : routed
 IPv4 addr : 10.1.1.1/30 (static, None)
--------------------------------------------------------------------------
==========================================================================
--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--
A:r1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;OK, let&amp;rsquo;s check the MTU on the container then after deleting the configs in r1 to see the default situation&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@r1 ~]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
3: mgmt0@if7: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1514 qdisc noqueue state UP mode DEFAULT group default
 link/ether 86:28:21:01:2f:32 brd ff:ff:ff:ff:ff:ff link-netnsid 0
4: gway-2800@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether 26:e1:9b:7f:82:07 brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
5: mgmt0-0@if4: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether e2:33:67:b1:b0:8e brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
 alias mgmt0.0
6: monit_in@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9234 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether fa:13:fb:a3:7c:e6 brd ff:ff:ff:ff:ff:ff link-netns monit
8: e1-1@if8: &amp;lt;BROADCAST,MULTICAST&amp;gt; mtu 1450 qdisc noqueue state DOWN mode DEFAULT group default qlen 1000
 link/ether 02:ab:b7:ff:00:01 brd ff:ff:ff:ff:ff:ff link-netnsid 0&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, the interface is configured with an MTU of 1450, which I guess is inherited by our &lt;em&gt;host&lt;/em&gt; network adapter and also cannot be changed on the fly in the container. Let&amp;rsquo;s see what we kave in k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
 link/ether 00:50:02:00:01:00 brd ff:ff:ff:ff:ff:ff
3: flannel.1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default
 link/ether 5e:3c:ea:cf:bd:cd brd ff:ff:ff:ff:ff:ff
4: cni0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether 92:19:8e:ea:71:f5 brd ff:ff:ff:ff:ff:ff
5: vethf00a4528@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default
 link/ether 92:85:21:c2:60:82 brd ff:ff:ff:ff:ff:ff link-netns cni-461b355e-9191-3b43-3778-e328f19016ef
6: vethd6c19f4d@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default
 link/ether d6:77:32:3c:c2:91 brd ff:ff:ff:ff:ff:ff link-netns cni-c88dd2d1-485d-2cd4-5f2d-d5b5539370eb
ubuntu@kates-control:~$&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So flannel, since it is a VXLAN CNI inherits the MTU of ens3 &lt;em&gt;physical&lt;/em&gt; interface minus 50 overhead for the headers. I am thinking of an easy fix around this is to increase the MTU on the physical interface, i.e. EVE-NGs physical interface and k8s VMs one as well. Let&amp;rsquo;s shutdown all VMs first and make the change to the EVE hosts.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Configure jumbo MTU on both EVE-NG nodes
root@eve-01:~# ip link set mtu 9000 dev eth0
root@eve-01:~# ip link set mtu 9000 dev pnet0

root@eve-02:~# ip link set mtu 9000 dev eth0
root@eve-02:~# ip link set mtu 9000 dev pnet0

# If you want to make it permanent
root@eve-01:~# head -n20 /etc/network/interfaces
# This file describes the network interfaces available on your system
# and how to activate them. For more information, see interfaces(5).

# The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
iface eth0 inet manual
auto pnet0
iface pnet0 inet static
 address 192.168.1.21
 netmask 255.255.255.0
 gateway 192.168.1.1
 dns-domain lab.net
 dns-nameservers 192.168.1.1 8.8.8.8
 bridge_ports eth0
 bridge_stp off
 mtu 9000
 post-up ifconfig eth0 mtu 9000

# Verify that jumbo MTU is supported on your infra
root@eve-01:~# ping 192.168.1.22 -Mdo -s 5000
PING 192.168.1.22 (192.168.1.22) 5000(5028) bytes of data.
5008 bytes from 192.168.1.22: icmp_seq=1 ttl=64 time=0.434 ms
5008 bytes from 192.168.1.22: icmp_seq=2 ttl=64 time=0.415 ms
5008 bytes from 192.168.1.22: icmp_seq=3 ttl=64 time=0.423 ms
5008 bytes from 192.168.1.22: icmp_seq=4 ttl=64 time=0.397 ms
^C
--- 192.168.1.22 ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3083ms
rtt min/avg/max/mdev = 0.397/0.417/0.434/0.019 ms

root@eve-02:~# tracepath -n 192.168.1.21
 1?: [LOCALHOST] pmtu 9000
 1: 192.168.1.21 0.570ms reached
 1: 192.168.1.21 0.428ms reached
 Resume: pmtu 9000 hops 1 back 1&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Bring up the k8s VMs and set the MTU there too.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ cat /etc/netplan/50-cloud-init.yaml
# This file is generated from information provided by the datasource. Changes
# to it will not persist across an instance reboot. To disable cloud-init&amp;#39;s
# network configuration capabilities, write a file
# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:
# network: {config: disabled}
network:
 ethernets:
 ens3:
 mtu: 9000
 dhcp4: false
 dhcp6: false
 addresses: [192.168.1.30/24]
 gateway4: 192.168.1.1
 nameservers:
 addresses: [192.168.1.1, 8.8.8.8]
 version: 2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Reboot all 3 VMs and check the network&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9000 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
 link/ether 00:50:02:00:01:00 brd ff:ff:ff:ff:ff:ff
3: flannel.1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 8950 qdisc noqueue state UNKNOWN mode DEFAULT group default
 link/ether 2a:d3:ae:2c:3a:47 brd ff:ff:ff:ff:ff:ff
4: cni0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 8950 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether b2:26:5f:c2:46:4c brd ff:ff:ff:ff:ff:ff
5: veth48f89ceb@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 8950 qdisc noqueue master cni0 state UP mode DEFAULT group default
 link/ether 4a:f4:77:a3:32:db brd ff:ff:ff:ff:ff:ff link-netns cni-9818a9b4-e802-2a6c-fc91-c4e241c38383
6: vethafbac825@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 8950 qdisc noqueue master cni0 state UP mode DEFAULT group default
 link/ether c6:44:4c:53:b4:50 brd ff:ff:ff:ff:ff:ff link-netns cni-014e3a91-e088-0d4b-740b-1024368a45a4&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It looks so much better now &amp;#x1f604;. OK, back on r1 then, let&amp;rsquo;s see how it looks like on the networking side&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs exec -it r1 -- bash
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
[root@r1 /]# ip link
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
3: mgmt0@if10: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1514 qdisc noqueue state UP mode DEFAULT group default
 link/ether 2e:99:25:47:fe:3d brd ff:ff:ff:ff:ff:ff link-netnsid 0
4: gway-2800@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether 66:fa:8c:11:28:47 brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
5: mgmt0-0@if4: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether 0a:5d:84:d6:be:df brd ff:ff:ff:ff:ff:ff link-netns srbase-mgmt
 alias mgmt0.0
6: monit_in@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9234 qdisc noqueue state UP mode DEFAULT group default qlen 1000
 link/ether 76:35:de:b1:c1:a6 brd ff:ff:ff:ff:ff:ff link-netns monit
11: e1-1@if11: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 8950 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/ether be:d0:be:51:69:e3 brd ff:ff:ff:ff:ff:ff link-netnsid 0
[root@r1 /]#&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now lets configure the devices with the following commands&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# on R1
--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--
A:r1# info flat interface ethernet-1/1
set / interface ethernet-1/1
set / interface ethernet-1/1 mtu 1516
set / interface ethernet-1/1 ethernet
set / interface ethernet-1/1 ethernet port-speed 10G
set / interface ethernet-1/1 subinterface 0
set / interface ethernet-1/1 subinterface 0 ip-mtu 1500
set / interface ethernet-1/1 subinterface 0 ipv4
set / interface ethernet-1/1 subinterface 0 ipv4 address 10.1.1.1/30
--{ [FACTORY] &amp;#43; candidate shared default }--[ ]--
A:r1# info flat network-instance main
set / network-instance main
set / network-instance main interface ethernet-1/1.0

A:r1# show interface ethernet-1/1
==========================================================================
ethernet-1/1 is up, speed 10G, type None
 ethernet-1/1.0 is up
 Network-instance: main
 Encapsulation : null
 Type : routed
 IPv4 addr : 10.1.1.1/30 (static, preferred, primary)
--------------------------------------------------------------------------
==========================================================================

# on R2
A:r2# info flat interface ethernet-1/1
set / interface ethernet-1/1
set / interface ethernet-1/1 mtu 1516
set / interface ethernet-1/1 ethernet
set / interface ethernet-1/1 ethernet port-speed 10G
set / interface ethernet-1/1 subinterface 0
set / interface ethernet-1/1 subinterface 0 ip-mtu 1500
set / interface ethernet-1/1 subinterface 0 ipv4
set / interface ethernet-1/1 subinterface 0 ipv4 address 10.1.1.2/30
--{ running }--[ ]--
A:r2# info flat network-instance main
set / network-instance main
set / network-instance main interface ethernet-1/1.0

# Check that we get pings

A:r2# ping 10.1.1.1 network-instance main
Using network instance main
PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=58.8 ms
64 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=14.7 ms
64 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=9.13 ms
64 bytes from 10.1.1.1: icmp_seq=4 ttl=64 time=12.5 ms
64 bytes from 10.1.1.1: icmp_seq=5 ttl=64 time=14.7 ms
64 bytes from 10.1.1.1: icmp_seq=6 ttl=64 time=9.12 ms
64 bytes from 10.1.1.1: icmp_seq=7 ttl=64 time=12.5 ms
64 bytes from 10.1.1.1: icmp_seq=8 ttl=64 time=6.85 ms
^C
--- 10.1.1.1 ping statistics ---
8 packets transmitted, 8 received, 0% packet loss, time 7008ms
rtt min/avg/max/mdev = 6.853/17.291/58.831/15.918 ms&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;OK, now let&amp;rsquo;s try out the other srlinux variants supported&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n 2srl-certs get cm
NAME DATA AGE
kube-root-ca.crt 1 5h33m
srlinux-kne-entrypoint 1 5h33m
srlinux-topomac-script 1 5h33m
srlinux-variants 5 5h33m

ubuntu@kates-control:~$ kubectl -n 2srl-certs describe cm srlinux-variants | grep ^ixr
ixrd1:
ixrd10:
ixrd2:
ixrd3:
ixr6:&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Create a simple lab containing only the node definitions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~/labs$ cat test-sr.pbtxt
name: &amp;#34;srl-test&amp;#34;
nodes: {
 name: &amp;#34;r1&amp;#34;
 vendor: NOKIA
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 model: &amp;#34;ixr6&amp;#34;
}

nodes: {
 name: &amp;#34;r2&amp;#34;
 vendor: NOKIA
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 model: &amp;#34;ixrd1&amp;#34;
}

nodes: {
 name: &amp;#34;r3&amp;#34;
 vendor: NOKIA
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 model: &amp;#34;ixrd2&amp;#34;
}
nodes: {
 name: &amp;#34;r4&amp;#34;
 vendor: NOKIA
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 model: &amp;#34;ixrd3&amp;#34;
}
nodes: {
 name: &amp;#34;r5&amp;#34;
 vendor: NOKIA
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
 model: &amp;#34;ixrd10&amp;#34;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And start it up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~/labs$ kne_cli create test-sr.pbtxt
INFO[0000] /home/ubuntu/labs
INFO[0000] Creating manager for: srl-test
INFO[0000] Trying in-cluster configuration
INFO[0000] Falling back to kubeconfig: &amp;#34;/home/ubuntu/.kube/config&amp;#34;
INFO[0000] Topology:
name: &amp;#34;srl-test&amp;#34;
nodes: &amp;lt;
 name: &amp;#34;r1&amp;#34;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 vendor: NOKIA
 model: &amp;#34;ixr6&amp;#34;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r2&amp;#34;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 vendor: NOKIA
 model: &amp;#34;ixrd1&amp;#34;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r3&amp;#34;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 vendor: NOKIA
 model: &amp;#34;ixrd2&amp;#34;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r4&amp;#34;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 vendor: NOKIA
 model: &amp;#34;ixrd3&amp;#34;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r5&amp;#34;
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
 vendor: NOKIA
 model: &amp;#34;ixrd10&amp;#34;
&amp;gt;

INFO[0000] Adding Node: r1:NOKIA:UNKNOWN
INFO[0000] Adding Node: r2:NOKIA:UNKNOWN
INFO[0000] Adding Node: r3:NOKIA:UNKNOWN
INFO[0000] Adding Node: r4:NOKIA:UNKNOWN
INFO[0000] Adding Node: r5:NOKIA:UNKNOWN
INFO[0000] Creating namespace for topology: &amp;#34;srl-test&amp;#34;
INFO[0000] Server Namespace: &amp;amp;Namespace{ObjectMeta:{srl-test 9209b1c5-6ea2-427f-8a2f-4f6e3705f8e8 53116 0 2022-06-08 18:41:57 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[kubernetes.io/metadata.name:srl-test] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:kubernetes.io/metadata.name&amp;#34;:{}}}}}]},Spec:NamespaceSpec{Finalizers:[kubernetes],},Status:NamespaceStatus{Phase:Active,Conditions:[]NamespaceCondition{},},}
INFO[0000] Getting topology specs for namespace srl-test
INFO[0000] Getting topology specs for node r5
INFO[0000] Getting topology specs for node r1
INFO[0000] Getting topology specs for node r2
INFO[0000] Getting topology specs for node r3
INFO[0000] Getting topology specs for node r4
INFO[0000] Creating topology for meshnet node r2
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r2 GenerateName: Namespace:srl-test SelfLink: UID:c11bdba8-4d64-4aea-b065-858907ed8271 ResourceVersion:53119 Generation:1 CreationTimestamp:2022-06-08 18:41:57 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[]}}
INFO[0000] Creating topology for meshnet node r3
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r3 GenerateName: Namespace:srl-test SelfLink: UID:3b0ca0fd-263a-400b-aec5-c2799a07f711 ResourceVersion:53120 Generation:1 CreationTimestamp:2022-06-08 18:41:57 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[]}}
INFO[0000] Creating topology for meshnet node r4
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r4 GenerateName: Namespace:srl-test SelfLink: UID:66947ac6-f55a-4082-8eee-4afcbc513c33 ResourceVersion:53121 Generation:1 CreationTimestamp:2022-06-08 18:41:57 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[]}}
INFO[0000] Creating topology for meshnet node r5
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r5 GenerateName: Namespace:srl-test SelfLink: UID:2f31adf0-3298-4709-a310-5144e1253913 ResourceVersion:53122 Generation:1 CreationTimestamp:2022-06-08 18:41:57 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[]}}
INFO[0000] Creating topology for meshnet node r1
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r1 GenerateName: Namespace:srl-test SelfLink: UID:54123e29-d30e-4c6c-8e65-a2689d8bce5f ResourceVersion:53123 Generation:1 CreationTimestamp:2022-06-08 18:41:57 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 18:41:57 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[]}}
INFO[0000] Creating Node Pods
INFO[0000] Creating Srlinux node resource r3
INFO[0000] Created SR Linux node r3 configmap
INFO[0000] Created Srlinux resource: r3
INFO[0000] Created Service:
&amp;amp;Service{ObjectMeta:{service-r3 srl-test e1b53ca4-5334-42b1-bc76-d02541fae176 53133 0 2022-06-08 18:41:58 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r3] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:58 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30482,AppProtocol:nil,},},Selector:map[string]string{app: r3,},ClusterIP:10.98.252.104,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.98.252.104],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0000] Node &amp;#34;r3&amp;#34; resource created
INFO[0000] Creating Srlinux node resource r4
INFO[0000] Created SR Linux node r4 configmap
INFO[0000] Created Srlinux resource: r4
INFO[0000] Created Service:
&amp;amp;Service{ObjectMeta:{service-r4 srl-test c83fd861-fdda-44af-984b-6fe94e3ab2b8 53151 0 2022-06-08 18:41:58 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r4] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:58 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30936,AppProtocol:nil,},},Selector:map[string]string{app: r4,},ClusterIP:10.96.239.113,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.239.113],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0000] Node &amp;#34;r4&amp;#34; resource created
INFO[0000] Creating Srlinux node resource r5
INFO[0000] Created SR Linux node r5 configmap
INFO[0000] Created Srlinux resource: r5
INFO[0001] Created Service:
&amp;amp;Service{ObjectMeta:{service-r5 srl-test 0b6ab531-b20d-45a4-ac83-d1ce10f08547 53165 0 2022-06-08 18:41:58 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r5] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:58 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:31089,AppProtocol:nil,},},Selector:map[string]string{app: r5,},ClusterIP:10.109.164.166,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.109.164.166],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0001] Node &amp;#34;r5&amp;#34; resource created
INFO[0001] Creating Srlinux node resource r1
INFO[0001] Created SR Linux node r1 configmap
INFO[0001] Created Srlinux resource: r1
INFO[0001] Created Service:
&amp;amp;Service{ObjectMeta:{service-r1 srl-test 2c60749c-43d4-498b-90c8-0bf4e319e8fc 53180 0 2022-06-08 18:41:59 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r1] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:59 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30431,AppProtocol:nil,},},Selector:map[string]string{app: r1,},ClusterIP:10.99.13.223,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.99.13.223],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0001] Node &amp;#34;r1&amp;#34; resource created
INFO[0001] Creating Srlinux node resource r2
INFO[0001] Created SR Linux node r2 configmap
INFO[0001] Created Srlinux resource: r2
INFO[0001] Created Service:
&amp;amp;Service{ObjectMeta:{service-r2 srl-test 0ee27dd3-5e80-429a-afb1-f13f9b99555c 53198 0 2022-06-08 18:41:59 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r2] map[] [] [] [{kne_cli Update v1 2022-06-08 18:41:59 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30699,AppProtocol:nil,},},Selector:map[string]string{app: r2,},ClusterIP:10.106.39.51,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.106.39.51],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0001] Node &amp;#34;r2&amp;#34; resource created
INFO[0003] Node &amp;#34;r2&amp;#34;: Status RUNNING
INFO[0003] Node &amp;#34;r1&amp;#34;: Status RUNNING
INFO[0003] Node &amp;#34;r3&amp;#34;: Status RUNNING
INFO[0004] Node &amp;#34;r4&amp;#34;: Status RUNNING
INFO[0004] Node &amp;#34;r5&amp;#34;: Status RUNNING
INFO[0004] Topology &amp;#34;srl-test&amp;#34; created
INFO[0006] Pods:
INFO[0006] r5
INFO[0006] r1
INFO[0006] r2
INFO[0006] r3
INFO[0006] r4&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s see what we have on k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n srl-test get all -owide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
pod/r1 0/1 CrashLoopBackOff 2 (28s ago) 70s 10.244.1.20 kates-node-01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/r2 1/1 Running 0 70s 10.244.2.22 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/r3 1/1 Running 0 71s 10.244.2.20 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/r4 1/1 Running 0 71s 10.244.1.19 kates-node-01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/r5 0/1 CrashLoopBackOff 2 (22s ago) 71s 10.244.2.21 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR
service/service-r1 LoadBalancer 10.99.13.223 192.168.1.53 22:30431/TCP 70s app=r1
service/service-r2 LoadBalancer 10.106.39.51 192.168.1.54 22:30699/TCP 70s app=r2
service/service-r3 LoadBalancer 10.98.252.104 192.168.1.50 22:30482/TCP 71s app=r3
service/service-r4 LoadBalancer 10.96.239.113 192.168.1.51 22:30936/TCP 71s app=r4
service/service-r5 LoadBalancer 10.109.164.166 192.168.1.52 22:31089/TCP 71s app=r5
ubuntu@kates-control:~$&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So, r1 and r5 are loop crashing and from the logs it seems something hardware related.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n srl-test logs r1
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
Wed Jun 8 18:59:10 UTC 2022: entrypoint.sh called
Wed Jun 8 18:59:10 UTC 2022: renaming docker interface eth0 to mgmt0
Cannot find device &amp;#34;eth0&amp;#34;
Device &amp;#34;eth0&amp;#34; does not exist.
Cannot find device &amp;#34;eth0&amp;#34;
Cannot find device &amp;#34;eth0&amp;#34;
Wed Jun 8 18:59:10 UTC 2022: turning off checksum offloading on mgmt0
Wed Jun 8 18:59:10 UTC 2022: starting sshd
ssh-keygen: generating new host keys: RSA DSA ECDSA ED25519
Wed Jun 8 18:59:11 UTC 2022: Calling boot_run script
cat: /sys/class/dmi/id/board_name: No such file or directory
/opt/srlinux/bin/bootscript/01_sr_bdb_arbitration.sh: line 9: 97 Aborted (core dumped) ${dev_mgr} --hw-details --matelink --log-stdout &amp;gt; ${arbitration_log}
cat: /sys/class/dmi/id/board_name: No such file or directory
/opt/srlinux/bin/bootscript/05_sr_createuser.sh: line 270: !srl_is_running_on_nokia_rootfs: command not found
/opt/srlinux/bin/bootscript/05_sr_createuser.sh: line 282: python: command not found
chmod: cannot access &amp;#39;/dev/console&amp;#39;: No such file or directory
chmod: missing operand after &amp;#39;0664&amp;#39;
Try &amp;#39;chmod --help&amp;#39; for more information.
/usr/bin/find: &amp;#39;/var/log/srlinux/file&amp;#39;: No such file or directory
logmgr_set_env.sh: plain_bootup_start
Wed Jun 8 18:59:13 UTC 2022 logmgr_set_env.sh: restart of rsyslogd
which: no python in (/opt/srlinux/bin:/opt/srlinux/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin)
readlink: missing operand
Try &amp;#39;readlink --help&amp;#39; for more information.
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: /mnt/nokiaos: No such file or directory
setfacl: Option -m: Invalid argument near character 5
setfacl: Option -m: Invalid argument near character 3
setfacl: Option -m: Invalid argument near character 5
setfacl: Option -m: Invalid argument near character 3
System has not been booted with systemd as init system (PID 1). Can&amp;#39;t operate.
Failed to connect to bus: Host is down
Failed to open connection to &amp;#34;system&amp;#34; message bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory
System has not been booted with systemd as init system (PID 1). Can&amp;#39;t operate.
Failed to connect to bus: Host is down
findfs: unable to resolve &amp;#39;LABEL=EFI-System&amp;#39;
No disk with label EFI-System is found
Failed to set capabilities on file `/usr/sbin/tcpdump&amp;#39; (No such file or directory)
usage: setcap [-q] [-v] [-n &amp;lt;rootid&amp;gt;] (-r|-|&amp;lt;caps&amp;gt;) &amp;lt;filename&amp;gt; [ ... (-r|-|&amp;lt;capsN&amp;gt;) &amp;lt;filenameN&amp;gt; ]

 Note &amp;lt;filename&amp;gt; must be a regular (non-symlink) file.
Wed Jun 8 18:59:15 UTC 2022: entrypoint.sh done, executing sudo bash -c touch /.dockerenv &amp;amp;&amp;amp; /opt/srlinux/bin/sr_linux
No/Invalid license found!
Not starting in a named namespace, giving it the name &amp;#34;srbase&amp;#34;
Unix domain socket directory is /opt/srlinux/var/run/
Log directory is /var/log/srlinux/stdout
 Started supportd: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_supportd --server-mode&amp;#34; &amp;gt;/var/log/srlinux/stdout/supportd.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application supportd is running: PID 1474
 Started dev_mgr: source /etc/profile.d/sr_app_env.sh &amp;amp;&amp;gt;/dev/null; bash -c &amp;#34;./sr_device_mgr&amp;#34; &amp;gt;/var/log/srlinux/stdout/dev_mgr.log 2&amp;gt;&amp;amp;1 &amp;amp;
 Application dev_mgr is running: PID 1496
 Found dev_mgr: PID 1496 - killing
 Found supportd: PID 1474 - killing
 Failed to kill supportd: PID 1474. Another kill is retried&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I guess more to troubleshoot, but for another time &amp;#x1f604;. Let&amp;rsquo;s see what we got for the other variants&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;Device&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Variant&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Chassis Type&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Specs&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;r1&lt;/td&gt;
 &lt;td style="text-align: center"&gt;ixr6&lt;/td&gt;
 &lt;td style="text-align: center"&gt;NA&lt;/td&gt;
 &lt;td style="text-align: center"&gt;NA&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;r2&lt;/td&gt;
 &lt;td style="text-align: center"&gt;ixrd1&lt;/td&gt;
 &lt;td style="text-align: center"&gt;7220 IXR-D1&lt;/td&gt;
 &lt;td style="text-align: center"&gt;48x1G , 4x10G&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;r3&lt;/td&gt;
 &lt;td style="text-align: center"&gt;ixrd2&lt;/td&gt;
 &lt;td style="text-align: center"&gt;7220 IXR-D2&lt;/td&gt;
 &lt;td style="text-align: center"&gt;48x25G, 4x100G&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;r4&lt;/td&gt;
 &lt;td style="text-align: center"&gt;ixrd3&lt;/td&gt;
 &lt;td style="text-align: center"&gt;7220 IXR-D3&lt;/td&gt;
 &lt;td style="text-align: center"&gt;2x10G, 32x100G&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;r5&lt;/td&gt;
 &lt;td style="text-align: center"&gt;ixrd10&lt;/td&gt;
 &lt;td style="text-align: center"&gt;NA&lt;/td&gt;
 &lt;td style="text-align: center"&gt;NA&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="test-arista-ceos"&gt;&lt;span&gt;Test Arista cEOS&lt;/span&gt;
 &lt;a href="#test-arista-ceos" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Get the arista container image and copy it to all k8s nodes or only to the workers if you control-plane is tainted. Then import it in each node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo ctr -n k8s.io image import ceos.tgz
unpacking docker.io/library/ceos:latest (sha256:bfd3f2fea1cad2d06f0e5113cb3a1dc81f0ccbb28acf11949e15dadcf68eda9a)...done&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s create a simple lab file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~/labs$ cat ceos.pbtxt
name: &amp;#34;arista&amp;#34;
nodes: {
 name: &amp;#34;r1&amp;#34;
 type: ARISTA_CEOS
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
}
nodes: {
 name: &amp;#34;r2&amp;#34;
 type: ARISTA_CEOS
 services:{
 key: 22
 value: {
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 }
 }
}
links: {
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;eth1&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;eth1&amp;#34;
}

links: {
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;eth2&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;eth2&amp;#34;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And fire up the topology.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~/labs$ kne_cli create ceos.pbtxt
INFO[0000] /home/ubuntu/labs
INFO[0000] Creating manager for: arista
INFO[0000] Trying in-cluster configuration
INFO[0000] Falling back to kubeconfig: &amp;#34;/home/ubuntu/.kube/config&amp;#34;
INFO[0000] Topology:
name: &amp;#34;arista&amp;#34;
nodes: &amp;lt;
 name: &amp;#34;r1&amp;#34;
 type: ARISTA_CEOS
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
&amp;gt;
nodes: &amp;lt;
 name: &amp;#34;r2&amp;#34;
 type: ARISTA_CEOS
 services: &amp;lt;
 key: 22
 value: &amp;lt;
 name: &amp;#34;ssh&amp;#34;
 inside: 22
 &amp;gt;
 &amp;gt;
&amp;gt;
links: &amp;lt;
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;eth1&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;eth1&amp;#34;
&amp;gt;
links: &amp;lt;
 a_node: &amp;#34;r1&amp;#34;
 a_int: &amp;#34;eth2&amp;#34;
 z_node: &amp;#34;r2&amp;#34;
 z_int: &amp;#34;eth2&amp;#34;
&amp;gt;

INFO[0000] Adding Link: r1:eth1 r2:eth1
INFO[0000] Adding Link: r1:eth2 r2:eth2
INFO[0000] Adding Node: r1:UNKNOWN:ARISTA_CEOS
INFO[0000] Adding Node: r2:UNKNOWN:ARISTA_CEOS
INFO[0000] Creating namespace for topology: &amp;#34;arista&amp;#34;
INFO[0000] Server Namespace: &amp;amp;Namespace{ObjectMeta:{arista 82fe4826-a7dd-4fa3-bf2d-36d09236c2d7 71849 0 2022-06-08 20:49:14 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[kubernetes.io/metadata.name:arista] map[] [] [] [{kne_cli Update v1 2022-06-08 20:49:14 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:kubernetes.io/metadata.name&amp;#34;:{}}}}}]},Spec:NamespaceSpec{Finalizers:[kubernetes],},Status:NamespaceStatus{Phase:Active,Conditions:[]NamespaceCondition{},},}
INFO[0000] Getting topology specs for namespace arista
INFO[0000] Getting topology specs for node r1
INFO[0000] Getting topology specs for node r2
INFO[0000] Creating topology for meshnet node r1
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r1 GenerateName: Namespace:arista SelfLink: UID:ba43116d-1c55-4e43-9201-cd7f2c9f3259 ResourceVersion:71852 Generation:1 CreationTimestamp:2022-06-08 20:49:14 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 20:49:14 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:eth1 LocalIP: PeerIntf:eth1 PeerIP: PeerPod:r2 UID:0} {LocalIntf:eth2 LocalIP: PeerIntf:eth2 PeerIP: PeerPod:r2 UID:1}]}}
INFO[0000] Creating topology for meshnet node r2
INFO[0000] Meshnet Node:
&amp;amp;{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name:r2 GenerateName: Namespace:arista SelfLink: UID:e677078e-0dc1-4e02-8258-b759acb61cfd ResourceVersion:71853 Generation:1 CreationTimestamp:2022-06-08 20:49:14 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[{Manager:kne_cli Operation:Update APIVersion:networkop.co.uk/v1beta1 Time:2022-06-08 20:49:14 &amp;#43;0000 UTC FieldsType:FieldsV1 FieldsV1:{&amp;#34;f:spec&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:links&amp;#34;:{}}}}]} Status:{TypeMeta:{Kind: APIVersion:} ObjectMeta:{Name: GenerateName: Namespace: SelfLink: UID: ResourceVersion: Generation:0 CreationTimestamp:0001-01-01 00:00:00 &amp;#43;0000 UTC DeletionTimestamp:&amp;lt;nil&amp;gt; DeletionGracePeriodSeconds:&amp;lt;nil&amp;gt; Labels:map[] Annotations:map[] OwnerReferences:[] Finalizers:[] ClusterName: ManagedFields:[]} Skipped:[] SrcIp: NetNs:} Spec:{TypeMeta:{Kind: APIVersion:} Links:[{LocalIntf:eth1 LocalIP: PeerIntf:eth1 PeerIP: PeerPod:r1 UID:0} {LocalIntf:eth2 LocalIP: PeerIntf:eth2 PeerIP: PeerPod:r1 UID:1}]}}
INFO[0000] Creating Node Pods
INFO[0000] Creating Pod:
 name:&amp;#34;r1&amp;#34; type:ARISTA_CEOS labels:{key:&amp;#34;model&amp;#34; value:&amp;#34;&amp;#34;} labels:{key:&amp;#34;os&amp;#34; value:&amp;#34;&amp;#34;} labels:{key:&amp;#34;type&amp;#34; value:&amp;#34;ARISTA_CEOS&amp;#34;} labels:{key:&amp;#34;vendor&amp;#34; value:&amp;#34;ARISTA&amp;#34;} labels:{key:&amp;#34;version&amp;#34; value:&amp;#34;&amp;#34;} config:{command:&amp;#34;/sbin/init&amp;#34; command:&amp;#34;systemd.setenv=INTFTYPE=eth&amp;#34; command:&amp;#34;systemd.setenv=ETBA=1&amp;#34; command:&amp;#34;systemd.setenv=SKIP_ZEROTOUCH_BARRIER_IN_SYSDBINIT=1&amp;#34; command:&amp;#34;systemd.setenv=CEOS=1&amp;#34; command:&amp;#34;systemd.setenv=EOS_PLATFORM=ceoslab&amp;#34; command:&amp;#34;systemd.setenv=container=docker&amp;#34; image:&amp;#34;ceos:latest&amp;#34; env:{key:&amp;#34;CEOS&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;EOS_PLATFORM&amp;#34; value:&amp;#34;ceoslab&amp;#34;} env:{key:&amp;#34;ETBA&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;INTFTYPE&amp;#34; value:&amp;#34;eth&amp;#34;} env:{key:&amp;#34;SKIP_ZEROTOUCH_BARRIER_IN_SYSDBINIT&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;container&amp;#34; value:&amp;#34;docker&amp;#34;} entry_command:&amp;#34;kubectl exec -it r1 -- Cli&amp;#34; config_path:&amp;#34;/mnt/flash&amp;#34; config_file:&amp;#34;startup-config&amp;#34;} services:{key:22 value:{name:&amp;#34;ssh&amp;#34; inside:22}} constraints:{key:&amp;#34;cpu&amp;#34; value:&amp;#34;0.5&amp;#34;} constraints:{key:&amp;#34;memory&amp;#34; value:&amp;#34;1Gi&amp;#34;} interfaces:{key:&amp;#34;eth1&amp;#34; value:{name:&amp;#34;Ethernet1&amp;#34; int_name:&amp;#34;eth1&amp;#34; peer_name:&amp;#34;r2&amp;#34; peer_int_name:&amp;#34;eth1&amp;#34;}} interfaces:{key:&amp;#34;eth2&amp;#34; value:{name:&amp;#34;Ethernet2&amp;#34; int_name:&amp;#34;eth2&amp;#34; peer_name:&amp;#34;r2&amp;#34; peer_int_name:&amp;#34;eth2&amp;#34; uid:1}}
INFO[0000] Created Service:
&amp;amp;Service{ObjectMeta:{service-r1 arista 4c93f283-7153-4813-aca5-875e70277c9a 71860 0 2022-06-08 20:49:14 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r1] map[] [] [] [{kne_cli Update v1 2022-06-08 20:49:14 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:31088,AppProtocol:nil,},},Selector:map[string]string{app: r1,},ClusterIP:10.102.188.238,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.102.188.238],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0000] Node &amp;#34;r1&amp;#34; resource created
INFO[0000] Creating Pod:
 name:&amp;#34;r2&amp;#34; type:ARISTA_CEOS labels:{key:&amp;#34;model&amp;#34; value:&amp;#34;&amp;#34;} labels:{key:&amp;#34;os&amp;#34; value:&amp;#34;&amp;#34;} labels:{key:&amp;#34;type&amp;#34; value:&amp;#34;ARISTA_CEOS&amp;#34;} labels:{key:&amp;#34;vendor&amp;#34; value:&amp;#34;ARISTA&amp;#34;} labels:{key:&amp;#34;version&amp;#34; value:&amp;#34;&amp;#34;} config:{command:&amp;#34;/sbin/init&amp;#34; command:&amp;#34;systemd.setenv=INTFTYPE=eth&amp;#34; command:&amp;#34;systemd.setenv=ETBA=1&amp;#34; command:&amp;#34;systemd.setenv=SKIP_ZEROTOUCH_BARRIER_IN_SYSDBINIT=1&amp;#34; command:&amp;#34;systemd.setenv=CEOS=1&amp;#34; command:&amp;#34;systemd.setenv=EOS_PLATFORM=ceoslab&amp;#34; command:&amp;#34;systemd.setenv=container=docker&amp;#34; image:&amp;#34;ceos:latest&amp;#34; env:{key:&amp;#34;CEOS&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;EOS_PLATFORM&amp;#34; value:&amp;#34;ceoslab&amp;#34;} env:{key:&amp;#34;ETBA&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;INTFTYPE&amp;#34; value:&amp;#34;eth&amp;#34;} env:{key:&amp;#34;SKIP_ZEROTOUCH_BARRIER_IN_SYSDBINIT&amp;#34; value:&amp;#34;1&amp;#34;} env:{key:&amp;#34;container&amp;#34; value:&amp;#34;docker&amp;#34;} entry_command:&amp;#34;kubectl exec -it r2 -- Cli&amp;#34; config_path:&amp;#34;/mnt/flash&amp;#34; config_file:&amp;#34;startup-config&amp;#34;} services:{key:22 value:{name:&amp;#34;ssh&amp;#34; inside:22}} constraints:{key:&amp;#34;cpu&amp;#34; value:&amp;#34;0.5&amp;#34;} constraints:{key:&amp;#34;memory&amp;#34; value:&amp;#34;1Gi&amp;#34;} interfaces:{key:&amp;#34;eth1&amp;#34; value:{name:&amp;#34;Ethernet1&amp;#34; int_name:&amp;#34;eth1&amp;#34; peer_name:&amp;#34;r1&amp;#34; peer_int_name:&amp;#34;eth1&amp;#34;}} interfaces:{key:&amp;#34;eth2&amp;#34; value:{name:&amp;#34;Ethernet2&amp;#34; int_name:&amp;#34;eth2&amp;#34; peer_name:&amp;#34;r1&amp;#34; peer_int_name:&amp;#34;eth2&amp;#34; uid:1}}
INFO[0000] Created Service:
&amp;amp;Service{ObjectMeta:{service-r2 arista 1ff432b7-ddd9-4ee4-9a07-dc28be6053d8 71872 0 2022-06-08 20:49:14 &amp;#43;0000 UTC &amp;lt;nil&amp;gt; &amp;lt;nil&amp;gt; map[pod:r2] map[] [] [] [{kne_cli Update v1 2022-06-08 20:49:14 &amp;#43;0000 UTC FieldsV1 {&amp;#34;f:metadata&amp;#34;:{&amp;#34;f:labels&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:pod&amp;#34;:{}}},&amp;#34;f:spec&amp;#34;:{&amp;#34;f:allocateLoadBalancerNodePorts&amp;#34;:{},&amp;#34;f:externalTrafficPolicy&amp;#34;:{},&amp;#34;f:internalTrafficPolicy&amp;#34;:{},&amp;#34;f:ports&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;k:{\&amp;#34;port\&amp;#34;:22,\&amp;#34;protocol\&amp;#34;:\&amp;#34;TCP\&amp;#34;}&amp;#34;:{&amp;#34;.&amp;#34;:{},&amp;#34;f:name&amp;#34;:{},&amp;#34;f:port&amp;#34;:{},&amp;#34;f:protocol&amp;#34;:{},&amp;#34;f:targetPort&amp;#34;:{}}},&amp;#34;f:selector&amp;#34;:{},&amp;#34;f:sessionAffinity&amp;#34;:{},&amp;#34;f:type&amp;#34;:{}}}}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:ssh,Protocol:TCP,Port:22,TargetPort:{0 22 },NodePort:30761,AppProtocol:nil,},},Selector:map[string]string{app: r2,},ClusterIP:10.110.58.235,Type:LoadBalancer,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:Cluster,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,TopologyKeys:[],IPFamilyPolicy:*SingleStack,ClusterIPs:[10.110.58.235],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:*true,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}
INFO[0000] Node &amp;#34;r2&amp;#34; resource created
INFO[0004] Node &amp;#34;r2&amp;#34;: Status RUNNING
INFO[0004] Node &amp;#34;r1&amp;#34;: Status RUNNING
INFO[0004] Topology &amp;#34;arista&amp;#34; created
INFO[0005] Pods:
INFO[0005] r1
INFO[0005] r2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check on k8s.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl -n arista get all -o wide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
pod/r1 1/1 Running 0 62s 10.244.1.23 kates-node-01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/r2 1/1 Running 0 62s 10.244.2.25 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR
service/service-r1 LoadBalancer 10.102.188.238 192.168.1.50 22:31088/TCP 62s app=r1
service/service-r2 LoadBalancer 10.110.58.235 192.168.1.51 22:30761/TCP 62s app=r2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Seems good. Let&amp;rsquo;s perform the initial configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# For r1
ubuntu@kates-control:~$ kubectl -n arista exec -it r1 -- Cli
Defaulted container &amp;#34;r1&amp;#34; out of: r1, init-r1 (init)
localhost&amp;gt;en
localhost#conf
localhost(config)#hostname r1
r1(config)#interface ethernet 1
r1(config-if-Et1)#no switchport
r1(config-if-Et1)#ip address 10.1.1.1/30
r1(config-if-Et1)#interface ethernet 2
r1(config-if-Et2)#no switchport
r1(config-if-Et2)#ip address 10.2.2.1/30
r1(config-if-Et2)#end
r1#conf
r1(config)#username admin privilege 15 secret admin
r1(config)#end
r1#write
Copy completed successfully.
r1#show interfaces status
Port Name Status Vlan Duplex Speed Type Flags Encapsulation
Et1 connected routed full 1G EbraTestPhyPort
Et2 connected routed full 1G EbraTestPhyPort

# For r2
ubuntu@kates-control:~$ kubectl -n arista exec -it r2 -- Cli
Defaulted container &amp;#34;r2&amp;#34; out of: r2, init-r2 (init)
localhost&amp;gt;en
localhost#conf
localhost(config)#hostname r2
r2(config)#username admin privilege 15 secret admin
r2(config)#interface ethernet 1
r2(config-if-Et1)#no switchport
r2(config-if-Et1)#ip address 10.1.1.2/30
r2(config-if-Et1)#interface ethernet 2
r2(config-if-Et2)#no switchport
r2(config-if-Et2)#ip address 10.2.2.2/30
r2(config-if-Et2)#end
r2#write
Copy completed successfully.

# Check connectivity

r2#ping 10.1.1.1
PING 10.1.1.1 (10.1.1.1) 72(100) bytes of data.
80 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=1.36 ms
80 bytes from 10.1.1.1: icmp_seq=2 ttl=64 time=0.482 ms
80 bytes from 10.1.1.1: icmp_seq=3 ttl=64 time=0.621 ms
80 bytes from 10.1.1.1: icmp_seq=4 ttl=64 time=0.452 ms
80 bytes from 10.1.1.1: icmp_seq=5 ttl=64 time=1.26 ms

--- 10.1.1.1 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4ms
rtt min/avg/max/mdev = 0.452/0.836/1.362/0.397 ms, ipg/ewma 1.118/1.106 ms
r2#ping 10.2.2.1
PING 10.2.2.1 (10.2.2.1) 72(100) bytes of data.
80 bytes from 10.2.2.1: icmp_seq=1 ttl=64 time=1.14 ms
80 bytes from 10.2.2.1: icmp_seq=2 ttl=64 time=0.512 ms
80 bytes from 10.2.2.1: icmp_seq=3 ttl=64 time=0.555 ms
80 bytes from 10.2.2.1: icmp_seq=4 ttl=64 time=0.556 ms
80 bytes from 10.2.2.1: icmp_seq=5 ttl=64 time=0.490 ms

--- 10.2.2.1 ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 4ms
rtt min/avg/max/mdev = 0.490/0.650/1.140/0.247 ms, ipg/ewma 1.064/0.886 ms

# Test OOB SSH access
ubuntu@kates-control:~$ ssh admin@192.168.1.50
Password:
r1&amp;gt;en
r1#conf
r1(config)#interface ethernet 1 - 2
r1(config-if-Et1-2)#shutdown
r1(config-if-Et1-2)#end
r1#show user de
Session Username Roles TTY State Duration Auth Remote Host
------------- -------------- ------------------- ---------- ----------- -------------- ----------- -----------
13 admin network-admin vty5 E 0:00:24 local 10.244.0.0
r1#show interfaces status
Port Name Status Vlan Duplex Speed Type Flags Encapsulation
Et1 disabled routed full 1G EbraTestPhyPort
Et2 disabled routed full 1G EbraTestPhyPort&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Seems we are ready now for some serious labbing. &amp;#x1f604;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="references-and-influences"&gt;&lt;span&gt;References and influences&lt;/span&gt;
 &lt;a href="#references-and-influences" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/google/kne" target="_blank" rel="external nofollow noopener noreferrer"&gt;KNE on github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.itsalwaysthe.network/posts/kubernetes-based-network-emulation/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Inspired by this Blog post&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://metallb.universe.tf/installation/" target="_blank" rel="external nofollow noopener noreferrer"&gt;metallb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/srl-labs/srl-controller#readme" target="_blank" rel="external nofollow noopener noreferrer"&gt;srl-labs on github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learn.srlinux.dev/" target="_blank" rel="external nofollow noopener noreferrer"&gt;srlinux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;Outro&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;Well, this was just a bare miminum and focused on how to set things up. I hope my post will help someone to start kicking the tyres with KNE. I also hope the project gets traction and evolves since the applications of it seem endless &amp;#x1f604; from all aspects. Thanking you, for reading the post, as well as all people sharing and contributing to the community making it sustainable and strong.&lt;/p&gt;
&lt;p align="right"&gt;...till next time...&lt;em&gt;have fun!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Kube my router up! - Part Two</title><link>https://net4fungr.github.io/posts/kube-my-router-pt2/</link><pubDate>Tue, 31 May 2022 12:40:24 +0300</pubDate><guid>https://net4fungr.github.io/posts/kube-my-router-pt2/</guid><category domain="https://net4fungr.github.io/categories/art-of-labbing/">Art of Labbing</category><description>&lt;img src="https://net4fungr.github.io/posts/kube-my-router-pt2/featured-image-preview.png" alt="featured image" referrerpolicy="no-referrer"&gt;&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1/#intro"&gt;Intro&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="part-one---setting-up-the-k8s-vms-in-eve-ng"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1/"&gt;Part One - Setting up the k8s VMs in EVE-NG&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#part-one---setting-up-the-k8s-vms-in-eve-ng" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="part-two---deploying-the-k8s-cluster-with-kubeadm"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt2/"&gt;Part Two - Deploying the k8s cluster with kubeadm&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#part-two---deploying-the-k8s-cluster-with-kubeadm" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="the-intent"&gt;&lt;span&gt;The Intent&lt;/span&gt;
 &lt;a href="#the-intent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Deploy k8s cluster with kubeadm&lt;/li&gt;
&lt;li&gt;Single control plane, two workers&lt;/li&gt;
&lt;li&gt;Use containerd as the container runtime&lt;/li&gt;
&lt;li&gt;Flannel as network overlay CNI plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;The main question points while preparing the k8s cluster for KNE where which CRI and which CNI to use, since I am not very deep in to k8s. A brief research done on the kind container that KNE uses to deploy the cluster and run the simulations in it revealed that it uses containerd as the CRI.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ kubectl get nodes -owide
NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME
kne-control-plane Ready control-plane,master 14d v1.22.1 172.19.0.2 &amp;lt;none&amp;gt; Ubuntu Impish Indri (development branch) 5.4.0-107-generic containerd://1.5.5&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Kindnet as the primary the CNI.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ kubectl get ds -n kube-system
NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
kindnet 1 1 1 1 1 &amp;lt;none&amp;gt; 14d
kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 14d&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In terms of network configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;❯ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
a099e5c3f7d3 kindest/node:v1.22.1 &amp;#34;/usr/local/bin/entr…&amp;#34; 2 weeks ago Up 2 weeks 127.0.0.1:34459-&amp;gt;6443/tcp kne-control-plane

❯ docker exec -it a099e5c3f7d3 bash
root@kne-control-plane:/#

root@kne-control-plane:/# ll /etc/cni/net.d/
total 16
drwx------ 2 root root 4096 May 22 22:16 ./
drwx------ 3 root root 4096 May 22 22:14 ../
-r--r--r-- 1 root root 518 May 22 22:16 00-meshnet.conflist
-rw-r--r-- 1 root root 409 May 22 22:15 10-kindnet.conflist

root@kne-control-plane:/# cat /etc/cni/net.d/10-kindnet.conflist

{
 &amp;#34;cniVersion&amp;#34;: &amp;#34;0.3.1&amp;#34;,
 &amp;#34;name&amp;#34;: &amp;#34;kindnet&amp;#34;,
 &amp;#34;plugins&amp;#34;: [
 {
 &amp;#34;type&amp;#34;: &amp;#34;ptp&amp;#34;,
 &amp;#34;ipMasq&amp;#34;: false,
 &amp;#34;ipam&amp;#34;: {
 &amp;#34;type&amp;#34;: &amp;#34;host-local&amp;#34;,
 &amp;#34;dataDir&amp;#34;: &amp;#34;/run/cni-ipam-state&amp;#34;,
 &amp;#34;routes&amp;#34;: [


 { &amp;#34;dst&amp;#34;: &amp;#34;0.0.0.0/0&amp;#34; }
 ],
 &amp;#34;ranges&amp;#34;: [


 [ { &amp;#34;subnet&amp;#34;: &amp;#34;10.244.0.0/24&amp;#34; } ]
 ]
 }
 ,
 &amp;#34;mtu&amp;#34;: 1500

 },
 {
 &amp;#34;type&amp;#34;: &amp;#34;portmap&amp;#34;,
 &amp;#34;capabilities&amp;#34;: {
 &amp;#34;portMappings&amp;#34;: true
 }
 }
 ]
}
root@kne-control-plane:/# cat /etc/cni/net.d/00-meshnet.conflist
{
 &amp;#34;cniVersion&amp;#34;: &amp;#34;0.3.1&amp;#34;,
 &amp;#34;name&amp;#34;: &amp;#34;kindnet&amp;#34;,
 &amp;#34;plugins&amp;#34;: [
 {
 &amp;#34;ipMasq&amp;#34;: false,
 &amp;#34;ipam&amp;#34;: {
 &amp;#34;dataDir&amp;#34;: &amp;#34;/run/cni-ipam-state&amp;#34;,
 &amp;#34;ranges&amp;#34;: [
 [
 {
 &amp;#34;subnet&amp;#34;: &amp;#34;10.244.0.0/24&amp;#34;
 }
 ]
 ],
 &amp;#34;routes&amp;#34;: [
 {
 &amp;#34;dst&amp;#34;: &amp;#34;0.0.0.0/0&amp;#34;
 }
 ],
 &amp;#34;type&amp;#34;: &amp;#34;host-local&amp;#34;
 },
 &amp;#34;mtu&amp;#34;: 1500,
 &amp;#34;type&amp;#34;: &amp;#34;ptp&amp;#34;
 },
 {
 &amp;#34;capabilities&amp;#34;: {
 &amp;#34;portMappings&amp;#34;: true
 },
 &amp;#34;type&amp;#34;: &amp;#34;portmap&amp;#34;
 },
 {
 &amp;#34;name&amp;#34;: &amp;#34;meshnet&amp;#34;,
 &amp;#34;type&amp;#34;: &amp;#34;meshnet&amp;#34;,
 &amp;#34;ipam&amp;#34;: {},
 &amp;#34;dns&amp;#34;: {}
 }
 ]
}root@kne-control-plane:/#&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So it is a simple Layer 3 CNI, and meshnet will be installed on top of it. Let&amp;rsquo;s use a more common CNI, like flannel for our use case.&lt;/p&gt;
&lt;div class="details admonition note"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Using flannel&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;When using flannel, the main drawback was the interface MTU inside the device container, seen on srlinux. Flannel, since it uses VXLAN, will inherit the MTU of the main ethernet interface of the host and create its bridge interface flannel.1 with an MTU of minus 50, i.e. 1450 by default. When spinning up the containers, they use this MTU and from what I saw, srlinux cannot bring up its interfaces that need a minimum of 1500 MTU. The only way of mitigating this easily is to use higher MTU on the host interface, so flannel can inherit this, which I presume in a &lt;em&gt;production&lt;/em&gt; environment should be something common and the network underlay would of course support jumbo&amp;rsquo;s. More on this during final part.&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let&amp;rsquo;s change gears now and deploy the k8s cluster on the three VMs that are running on the two EVE-NG servers. Here&amp;rsquo;s what we have up and running:&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;EVE-NG node&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Role&lt;/th&gt;
 &lt;th style="text-align: center"&gt;VM name&lt;/th&gt;
 &lt;th style="text-align: center"&gt;IP address&lt;/th&gt;
 &lt;th style="text-align: center"&gt;CPU&lt;/th&gt;
 &lt;th style="text-align: center"&gt;RAM&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;control-node&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-control&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.30&lt;/td&gt;
 &lt;td style="text-align: center"&gt;4&lt;/td&gt;
 &lt;td style="text-align: center"&gt;4096&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;worker&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-node-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.31&lt;/td&gt;
 &lt;td style="text-align: center"&gt;8&lt;/td&gt;
 &lt;td style="text-align: center"&gt;28672&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-02&lt;/td&gt;
 &lt;td style="text-align: center"&gt;worker&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-node-02&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.32&lt;/td&gt;
 &lt;td style="text-align: center"&gt;8&lt;/td&gt;
 &lt;td style="text-align: center"&gt;28672&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We are going to deploy a single control node with two workers using kubeadm and also use the containerd container runtime.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="prepare-all-nodes-for-kubeadm"&gt;&lt;span&gt;Prepare all nodes for kubeadm&lt;/span&gt;
 &lt;a href="#prepare-all-nodes-for-kubeadm" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;In all nodes, fix the &lt;mark class="mark-default"&gt;/etc/hosts&lt;/mark&gt; since we are not using proper DNS resolution and we need to statically be able to resolve.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diff /etc/hosts.orig /etc/hosts -p
*** /etc/hosts.orig 2022-05-30 19:28:32.679321412 &amp;#43;0000
--- /etc/hosts 2022-05-30 19:29:04.931472825 &amp;#43;0000
***************
*** 1,4 ****
--- 1,7 ----
 127.0.0.1 localhost
&amp;#43; 192.168.1.30 kates-control
&amp;#43; 192.168.1.31 kates-node-01
&amp;#43; 192.168.1.32 kates-node-02&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Install the pre-requisite packages if missing and add the k8s sources in apt.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt -y install vim git curl wget apt-transport-https ca-certificates

$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
OK

$ echo &amp;#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&amp;#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main

$ sudo apt update&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You may upgrade any packages needed after the last apt update.&lt;/p&gt;
&lt;p&gt;Next, we are now ready to install &lt;strong&gt;kubeadm&lt;/strong&gt; along with &lt;strong&gt;kubelet&lt;/strong&gt; and &lt;strong&gt;kubectl&lt;/strong&gt; packages&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt -y install kubeadm kubelet kubectl

# Lock the software version on these packages to avoid any accidental upgrade
$ sudo apt-mark hold kubelet kubeadm kubectl

# This is the version used while I was deploying
$ kubectl version --output=yaml --client &amp;amp;&amp;amp; kubeadm version -o yaml
clientVersion:
 buildDate: &amp;#34;2022-05-24T12:26:19Z&amp;#34;
 compiler: gc
 gitCommit: 3ddd0f45aa91e2f30c70734b175631bec5b5825a
 gitTreeState: clean
 gitVersion: v1.24.1
 goVersion: go1.18.2
 major: &amp;#34;1&amp;#34;
 minor: &amp;#34;24&amp;#34;
 platform: linux/amd64
kustomizeVersion: v4.5.4

clientVersion:
 buildDate: &amp;#34;2022-05-24T12:24:38Z&amp;#34;
 compiler: gc
 gitCommit: 3ddd0f45aa91e2f30c70734b175631bec5b5825a
 gitTreeState: clean
 gitVersion: v1.24.1
 goVersion: go1.18.2
 major: &amp;#34;1&amp;#34;
 minor: &amp;#34;24&amp;#34;
 platform: linux/amd64&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition note"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Specific Version&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;&lt;p&gt;If you want to deploy a specific version of the packages and not the latest available you could execute:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt list -a kubelet kubeadm kubectl | grep 1.22.2

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

kubeadm/kubernetes-xenial 1.22.2-00 amd64
kubectl/kubernetes-xenial 1.22.2-00 amd64
kubelet/kubernetes-xenial 1.22.2-00 amd64&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then install with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt -y install kubeadm=1.22.2-00 kubelet=1.22.2-00 kubectl=1.22.2-00&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Remember that if you are using a specific version you will have to specify that while downloading the k8s images and/or during kubeadm init bootstrap of the control node.&lt;/p&gt;
&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We now need to disable swap if we are using any (cloud images do not by default), since kubelet will not run unless swap is disabled.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo swapoff -a

# Comment out the relevant line in fstab to disable swap from loading on boot (usually last line)
$ sudo vi /etc/fstab&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Enable kernel modules and bridge NF to iptables chains.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo modprobe overlay
ubuntu@kates-control:~$ sudo modprobe br_netfilter

ubuntu@kates-control:~$ cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/k8s-cri.conf
&amp;gt; overlay
&amp;gt; br_netfilter
&amp;gt; EOF
overlay
br_netfilter

ubuntu@kates-control:~$ sudo tee /etc/sysctl.d/99-k8s-cri.conf&amp;lt;&amp;lt;EOF
&amp;gt; net.bridge.bridge-nf-call-ip6tables = 1
&amp;gt; net.bridge.bridge-nf-call-iptables = 1
&amp;gt; net.ipv4.ip_forward = 1
&amp;gt; EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1


# Reload sysctl to apply changes
ubuntu@kates-control:~$ sudo sysctl --system&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="install-a-container-runtime"&gt;&lt;span&gt;Install a container runtime&lt;/span&gt;
 &lt;a href="#install-a-container-runtime" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;As far as CRI, there are three options available. Go with either &lt;strong&gt;docker&lt;/strong&gt;, &lt;strong&gt;containerd&lt;/strong&gt; or use &lt;strong&gt;CRI-O&lt;/strong&gt;. For this post we are going with containerd, so the first step is to add the repo to our nodes and install the service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
OK

ubuntu@kates-control:~$ sudo add-apt-repository &amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;#34;

ubuntu@kates-control:~$ sudo apt update -y

ubuntu@kates-control:~$ sudo apt install -y containerd.io&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, put in place a default configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo mv /etc/containerd/config.toml /etc/containerd/config.toml.orig

ubuntu@kates-control:~$ containerd config default | sudo tee /etc/containerd/config.toml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, set the cgroup to use systemd and re-start the service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo sed -i s/&amp;#34;SystemdCgroup = false&amp;#34;/&amp;#34;SystemdCgroup = true&amp;#34;/g /etc/containerd/config.toml

ubuntu@kates-control:~$ sudo systemctl restart containerd&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Test that pulling images works.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo ctr image pull docker.io/library/nginx:latest

ubuntu@kates-control:~$ sudo ctr image ls -q
docker.io/library/nginx:latest

# Delete the image
ubuntu@kates-control:~$ sudo ctr image rm docker.io/library/nginx:latest
docker.io/library/nginx:latest&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition note"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Access via proxy&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;&lt;p&gt;If you are behind a proxy, you can expose the proxy environment variables to the daemon.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo mkdir /etc/systemd/system/containerd.service.d/

$ sudo tee /etc/systemd/system/containerd.service.d/http-proxy.conf&amp;lt;&amp;lt;EOF
&amp;gt; [Service]
&amp;gt; Environment=&amp;#34;HTTP_PROXY=http://&amp;lt;your_proxy&amp;gt;:&amp;lt;port&amp;gt;&amp;#34;
&amp;gt; Environment=&amp;#34;HTTPS_PROXY=http://&amp;lt;your_proxy&amp;gt;:&amp;lt;port&amp;gt;&amp;#34;
&amp;gt; Environment=&amp;#34;NO_PROXY=localhost,127.0.0.1,.domain.com&amp;#34;
&amp;gt; EOF

$ sudo systemctl daemon-reload
$ sudo systemctl restart containerd&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The &lt;strong&gt;no_proxy&lt;/strong&gt; variable will not accept subnet masks, only full /32 ip addresses.&lt;/p&gt;
&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="bootstrap-k8s-control-node"&gt;&lt;span&gt;Bootstrap k8s control node&lt;/span&gt;
 &lt;a href="#bootstrap-k8s-control-node" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;We are ready now to initialise the control node on the first VM. First we need to enable the &lt;strong&gt;kubelet&lt;/strong&gt; service if not already on.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ systemctl is-enabled kubelet &amp;gt;/dev/null \
 &amp;amp;&amp;amp; echo Service is already enabled \
 || echo Enabling kubelet \
 &amp;amp;&amp;amp; sudo systemctl enable kubelet
Service is already enabled&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;No worries if the service does not load correctly, it will, after kubeadm finishes configuring the control node.
Download k8s images from the registry, optionally, specifying the k8s version.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Check for the images first
ubuntu@kates-control:~$ sudo kubeadm config images list --kubernetes-version stable-1.24
k8s.gcr.io/kube-apiserver:v1.24.1
k8s.gcr.io/kube-controller-manager:v1.24.1
k8s.gcr.io/kube-scheduler:v1.24.1
k8s.gcr.io/kube-proxy:v1.24.1
k8s.gcr.io/pause:3.7
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/coredns/coredns:v1.8.6

# and then pull them
ubuntu@kates-control:~$ sudo kubeadm config images pull --kubernetes-version stable-1.24 --cri-socket unix:///run/containerd/containerd.sock
[config/images] Pulled k8s.gcr.io/kube-apiserver:v1.24.1
[config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.24.1
[config/images] Pulled k8s.gcr.io/kube-scheduler:v1.24.1
[config/images] Pulled k8s.gcr.io/kube-proxy:v1.24.1
[config/images] Pulled k8s.gcr.io/pause:3.7
[config/images] Pulled k8s.gcr.io/etcd:3.5.3-0
[config/images] Pulled k8s.gcr.io/coredns/coredns:v1.8.6

ubuntu@kates-control:~$ sudo ctr -n k8s.io image ls -q | grep -v sha
k8s.gcr.io/coredns/coredns:v1.8.6
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/kube-apiserver:v1.24.1
k8s.gcr.io/kube-controller-manager:v1.24.1
k8s.gcr.io/kube-proxy:v1.24.1
k8s.gcr.io/kube-scheduler:v1.24.1
k8s.gcr.io/pause:3.7&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition note"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Using crictl instead&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;&lt;p&gt;If you prefer to use crictl, you can create a configuration file for containerd to avoid the warnings&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo tee cat /etc/crictl.yaml &amp;lt;&amp;lt;EOF
&amp;gt; runtime-endpoint: unix:///var/run/containerd/containerd.sock
&amp;gt; image-endpoint: unix:///run/containerd/containerd.sock
&amp;gt; timeout: 10
&amp;gt; debug: false
&amp;gt; EOF
runtime-endpoint: unix:///var/run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false

ubuntu@kates-control:~$ sudo crictl images
IMAGE TAG IMAGE ID SIZE
k8s.gcr.io/coredns/coredns v1.8.6 a4ca41631cc7a 13.6MB
k8s.gcr.io/etcd 3.5.3-0 aebe758cef4cd 102MB
k8s.gcr.io/kube-apiserver v1.24.1 e9f4b425f9192 33.8MB
k8s.gcr.io/kube-controller-manager v1.24.1 b4ea7e648530d 31MB
k8s.gcr.io/kube-proxy v1.24.1 beb86f5d8e6cd 39.5MB
k8s.gcr.io/kube-scheduler v1.24.1 18688a72645c5 15.5MB
k8s.gcr.io/pause 3.7 221177c6082a8 311kB&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we can use kubeadm to bootstrap the node setting the POD network and, again, by optionally specifying the version. The init process will get the appropriate images if they do not exist locally already.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --cri-socket /run/containerd/containerd.sock --kubernetes-version stable-1.24
W0606 09:39:22.344649 33934 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme &amp;#34;unix&amp;#34; to the &amp;#34;criSocket&amp;#34; with value &amp;#34;/run/containerd/containerd.sock&amp;#34;. Please update your configuration!
[init] Using Kubernetes version: v1.24.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using &amp;#39;kubeadm config images pull&amp;#39;
[certs] Using certificateDir folder &amp;#34;/etc/kubernetes/pki&amp;#34;
[certs] Generating &amp;#34;ca&amp;#34; certificate and key
[certs] Generating &amp;#34;apiserver&amp;#34; certificate and key
[certs] apiserver serving cert is signed for DNS names [kates-control kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.30]
[certs] Generating &amp;#34;apiserver-kubelet-client&amp;#34; certificate and key
[certs] Generating &amp;#34;front-proxy-ca&amp;#34; certificate and key
[certs] Generating &amp;#34;front-proxy-client&amp;#34; certificate and key
[certs] Generating &amp;#34;etcd/ca&amp;#34; certificate and key
[certs] Generating &amp;#34;etcd/server&amp;#34; certificate and key
[certs] etcd/server serving cert is signed for DNS names [kates-control localhost] and IPs [192.168.1.30 127.0.0.1 ::1]
[certs] Generating &amp;#34;etcd/peer&amp;#34; certificate and key
[certs] etcd/peer serving cert is signed for DNS names [kates-control localhost] and IPs [192.168.1.30 127.0.0.1 ::1]
[certs] Generating &amp;#34;etcd/healthcheck-client&amp;#34; certificate and key
[certs] Generating &amp;#34;apiserver-etcd-client&amp;#34; certificate and key
[certs] Generating &amp;#34;sa&amp;#34; key and public key
[kubeconfig] Using kubeconfig folder &amp;#34;/etc/kubernetes&amp;#34;
[kubeconfig] Writing &amp;#34;admin.conf&amp;#34; kubeconfig file
[kubeconfig] Writing &amp;#34;kubelet.conf&amp;#34; kubeconfig file
[kubeconfig] Writing &amp;#34;controller-manager.conf&amp;#34; kubeconfig file
[kubeconfig] Writing &amp;#34;scheduler.conf&amp;#34; kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;
[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder &amp;#34;/etc/kubernetes/manifests&amp;#34;
[control-plane] Creating static Pod manifest for &amp;#34;kube-apiserver&amp;#34;
[control-plane] Creating static Pod manifest for &amp;#34;kube-controller-manager&amp;#34;
[control-plane] Creating static Pod manifest for &amp;#34;kube-scheduler&amp;#34;
[etcd] Creating static Pod manifest for local etcd in &amp;#34;/etc/kubernetes/manifests&amp;#34;
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &amp;#34;/etc/kubernetes/manifests&amp;#34;. This can take up to 4m0s
[apiclient] All control plane components are healthy after 9.004673 seconds
[upload-config] Storing the configuration used in ConfigMap &amp;#34;kubeadm-config&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace
[kubelet] Creating a ConfigMap &amp;#34;kubelet-config&amp;#34; in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node kates-control as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node kates-control as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: kggzqq.5vz1esxhxfw1wgxf
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the &amp;#34;cluster-info&amp;#34; ConfigMap in the &amp;#34;kube-public&amp;#34; namespace
[kubelet-finalize] Updating &amp;#34;/etc/kubernetes/kubelet.conf&amp;#34; to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

 mkdir -p $HOME/.kube
 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

 export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34; with one of the options listed at:
 https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.30:6443 --token kggzqq.5vz1esxhxfw1wgxf \
 --discovery-token-ca-cert-hash sha256:d83d4dd95515623997f68d12a5bb19adda871ba8d81dc389ac787746d49ea9e2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;div class="details admonition tip open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-regular fa-lightbulb" aria-hidden="true"&gt;&lt;/i&gt;Join Token&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;The join token created by kubeadm will last I think for 24hrs, so if you are joining workers sooner you could copy the join command in a text pad or something for later use.&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
Now as instructed by the init process, copy the admin.conf into your users directory in order to be able to use kubectl to operate your cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ mkdir -p $HOME/.kube
ubuntu@kates-control:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
ubuntu@kates-control:~$ sudo chown $(id -u):$(id -g) $HOME/.kube/config&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And run some kubectl to check your control-plane.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl cluster-info
Kubernetes control plane is running at https://192.168.1.30:6443
CoreDNS is running at https://192.168.1.30:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use &amp;#39;kubectl cluster-info dump&amp;#39;.

ubuntu@kates-control:~$ kubectl get nodes -owide
NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME
kates-control NotReady control-plane 104s v1.24.1 192.168.1.30 &amp;lt;none&amp;gt; Ubuntu 20.04.4 LTS 5.4.0-117-generic containerd://1.6.6

ubuntu@kates-control:~$ kubectl get all -A
NAMESPACE NAME READY STATUS RESTARTS AGE
kube-system pod/coredns-6d4b75cb6d-r5k7h 0/1 Pending 0 2m8s
kube-system pod/coredns-6d4b75cb6d-xwfnq 0/1 Pending 0 2m8s
kube-system pod/etcd-kates-control 1/1 Running 0 2m23s
kube-system pod/kube-apiserver-kates-control 1/1 Running 0 2m23s
kube-system pod/kube-controller-manager-kates-control 1/1 Running 0 2m25s
kube-system pod/kube-proxy-gnq29 1/1 Running 0 2m8s
kube-system pod/kube-scheduler-kates-control 1/1 Running 0 2m23s

NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
default service/kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 2m25s
kube-system service/kube-dns ClusterIP 10.96.0.10 &amp;lt;none&amp;gt; 53/UDP,53/TCP,9153/TCP 2m23s

NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
kube-system daemonset.apps/kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 2m23s

NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE
kube-system deployment.apps/coredns 0/2 2 0 2m23s

NAMESPACE NAME DESIRED CURRENT READY AGE
kube-system replicaset.apps/coredns-6d4b75cb6d 2 2 0 2m9s

# componentstatus seems old :smile:
ubuntu@kates-control:~$ kubectl get cs -A
Warning: v1 ComponentStatus is deprecated in v1.19&amp;#43;
NAME STATUS MESSAGE ERROR
scheduler Healthy ok
controller-manager Healthy ok
etcd-0 Healthy {&amp;#34;health&amp;#34;:&amp;#34;true&amp;#34;,&amp;#34;reason&amp;#34;:&amp;#34;&amp;#34;}&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="install-network-cni"&gt;&lt;span&gt;Install network CNI&lt;/span&gt;
 &lt;a href="#install-network-cni" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Now, still on the control node, we are going to deploy the Flannel CNI plugin.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21&amp;#43;, unavailable in v1.25&amp;#43;
podsecuritypolicy.policy/psp.flannel.unprivileged created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds created&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check how it looks on control-plane.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl get all -A
NAMESPACE NAME READY STATUS RESTARTS AGE
kube-system pod/coredns-6d4b75cb6d-fvskj 1/1 Running 0 8m12s
kube-system pod/coredns-6d4b75cb6d-xrflm 1/1 Running 0 8m12s
kube-system pod/etcd-kates-control 1/1 Running 0 8m25s
kube-system pod/kube-apiserver-kates-control 1/1 Running 0 8m27s
kube-system pod/kube-controller-manager-kates-control 1/1 Running 0 8m25s
kube-system pod/kube-flannel-ds-55st2 1/1 Running 0 65s
kube-system pod/kube-proxy-8wjpp 1/1 Running 0 8m13s
kube-system pod/kube-scheduler-kates-control 1/1 Running 0 8m25s

NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
default service/kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 8m27s
kube-system service/kube-dns ClusterIP 10.96.0.10 &amp;lt;none&amp;gt; 53/UDP,53/TCP,9153/TCP 8m25s

NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE
kube-system daemonset.apps/kube-flannel-ds 1 1 1 1 1 &amp;lt;none&amp;gt; 65s
kube-system daemonset.apps/kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 8m25s

NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE
kube-system deployment.apps/coredns 2/2 2 2 8m25s

NAMESPACE NAME DESIRED CURRENT READY AGE
kube-system replicaset.apps/coredns-6d4b75cb6d 2 2 2 8m13s&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And from the network side.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ ip ro ; ip add
default via 192.168.1.1 dev ens3 proto static
10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1
192.168.1.0/24 dev ens3 proto kernel scope link src 192.168.1.30
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
 inet 127.0.0.1/8 scope host lo
 valid_lft forever preferred_lft forever
 inet6 ::1/128 scope host
 valid_lft forever preferred_lft forever
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
 link/ether 00:50:02:00:01:00 brd ff:ff:ff:ff:ff:ff
 inet 192.168.1.30/24 brd 192.168.1.255 scope global ens3
 valid_lft forever preferred_lft forever
 inet6 2a02:587:e44a:d37:250:2ff:fe00:100/64 scope global dynamic mngtmpaddr noprefixroute
 valid_lft 604763sec preferred_lft 86363sec
 inet6 fe80::250:2ff:fe00:100/64 scope link
 valid_lft forever preferred_lft forever
3: flannel.1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN group default
 link/ether f2:64:03:ac:1f:68 brd ff:ff:ff:ff:ff:ff
 inet 10.244.0.0/32 scope global flannel.1
 valid_lft forever preferred_lft forever
 inet6 fe80::f064:3ff:feac:1f68/64 scope link
 valid_lft forever preferred_lft forever
4: cni0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP group default qlen 1000
 link/ether e2:92:cd:73:85:3d brd ff:ff:ff:ff:ff:ff
 inet 10.244.0.1/24 brd 10.244.0.255 scope global cni0
 valid_lft forever preferred_lft forever
 inet6 fe80::e092:cdff:fe73:853d/64 scope link
 valid_lft forever preferred_lft forever
5: vethdc5600c6@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP group default
 link/ether f2:8f:bd:a7:dc:82 brd ff:ff:ff:ff:ff:ff link-netns cni-0155810e-5cb5-58a5-22c4-dc8038081174
 inet6 fe80::f08f:bdff:fea7:dc82/64 scope link
 valid_lft forever preferred_lft forever
6: vethe9a1a648@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP group default
 link/ether aa:09:c5:8c:bb:66 brd ff:ff:ff:ff:ff:ff link-netns cni-d71bf00b-ba62-2a8d-548a-9430a25d8dcd
 inet6 fe80::a809:c5ff:fe8c:bb66/64 scope link
 valid_lft forever preferred_lft forever&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="add-worker-nodes"&gt;&lt;span&gt;Add worker nodes&lt;/span&gt;
 &lt;a href="#add-worker-nodes" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Let&amp;rsquo;s go and add the two other nodes to our cluster now. We can do this either by using the init token or we could create a new one.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubeadm token create --print-join-command
kubeadm join 192.168.1.30:6443 --token r8ydn9.nkbo1b94w7a6s8em --discovery-token-ca-cert-hash sha256:42a47eb0e4872ebdd7ebbd6935a6e1c42f51a67d29d80fd53098d27323c59b2e&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now on both worker nodes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-node-01:~$ sudo kubeadm join 192.168.1.30:6443 --token r8ydn9.nkbo1b94w7a6s8em --discovery-token-ca-cert-hash sha256:42a47eb0e4872ebdd7ebbd6935a6e1c42f51a67d29d80fd53098d27323c59b2e
[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with &amp;#39;kubectl -n kube-system get cm kubeadm-config -o yaml&amp;#39;
[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
[kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run &amp;#39;kubectl get nodes&amp;#39; on the control-plane to see this node join the cluster.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If all went well then we should have a 3 node k8s cluster &amp;#x1f604;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl get nodes -owide
NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME
kates-control Ready control-plane 11m v1.24.1 192.168.1.30 &amp;lt;none&amp;gt; Ubuntu 20.04.4 LTS 5.4.0-117-generic containerd://1.6.6
kates-node-01 Ready &amp;lt;none&amp;gt; 66s v1.24.1 192.168.1.31 &amp;lt;none&amp;gt; Ubuntu 20.04.4 LTS 5.4.0-117-generic containerd://1.6.6
kates-node-02 Ready &amp;lt;none&amp;gt; 59s v1.24.1 192.168.1.32 &amp;lt;none&amp;gt; Ubuntu 20.04.4 LTS 5.4.0-117-generic containerd://1.6.6&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Final touch is to set the &lt;em&gt;worker&lt;/em&gt; role to the workers and, if you like to run pods on the control node as well, untaint the node.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-control:~$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
kates-control Ready control-plane 4h37m v1.24.1
kates-node-01 Ready &amp;lt;none&amp;gt; 139m v1.24.1
kates-node-02 Ready &amp;lt;none&amp;gt; 138m v1.24.1

ubuntu@kates-control:~$ kubectl label nodes kates-node-01 kubernetes.io/role=worker
node/kates-node-01 labeled

ubuntu@kates-control:~$ kubectl label nodes kates-node-02 kubernetes.io/role=worker
node/kates-node-02 labeled

ubuntu@kates-control:~$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
kates-control Ready control-plane 4h37m v1.24.1
kates-node-01 Ready worker 140m v1.24.1
kates-node-02 Ready worker 138m v1.24.1
ubuntu@kates-control:~$

# Untaint the control plane to run pods if you wish
ubuntu@kates-control:~$ kubectl taint nodes kates-control node-role.kubernetes.io/control-plane=:NoSchedule- node-role.kubernetes.io/master=:NoSchedule-
node/kates-control untainted&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="testing-applications"&gt;&lt;span&gt;Testing applications&lt;/span&gt;
 &lt;a href="#testing-applications" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Let&amp;rsquo;s deploy a test application to verify the cluster is running fine. We can create a deployment of nginx demo image with three replicas and test connectivity. The three pods will normaly be distributed across the three nodes, so we can use a Loadbalancer service to expose the deployment and check the operation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Create a 3 replica deployment of nginx demo image
ubuntu@kates-control:~$ kubectl create deployment web --image=nginxdemos/hello --replicas=3 --port 80
deployment.apps/web created

# Check to see that pods are distributed across the three nodes
ubuntu@kates-control:~$ kubectl get all -owide
NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES
pod/web-54b75887bb-2glrx 1/1 Running 0 11s 10.244.2.3 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/web-54b75887bb-7jrf4 1/1 Running 0 11s 10.244.1.2 kates-node-01 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;
pod/web-54b75887bb-j76kz 1/1 Running 0 11s 10.244.2.2 kates-node-02 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;

NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR
service/kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 12m &amp;lt;none&amp;gt;

NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR
deployment.apps/web 3/3 3 3 11s hello nginxdemos/hello app=web

NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR
replicaset.apps/web-54b75887bb 3 3 3 11s hello nginxdemos/hello app=web,pod-template-hash=54b75887bb

# Create a LoadBalancer service
ubuntu@kates-control:~$ kubectl expose deployment web --type=LoadBalancer --name=web-service
service/web-service exposed

ubuntu@kates-control:~$ kubectl get svc -o wide
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR
kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 13m &amp;lt;none&amp;gt;
web-service LoadBalancer 10.101.141.116 &amp;lt;pending&amp;gt; 80:30721/TCP 10s app=web

# Test communication to each pod
ubuntu@kates-control:~$ curl -s 10.244.2.3 | grep Server
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;name:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;web-54b75887bb-2glrx&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;

ubuntu@kates-control:~$ curl -s 10.244.1.2 | grep Server
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.1.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;name:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;web-54b75887bb-7jrf4&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;

ubuntu@kates-control:~$ curl -s 10.244.2.2 | grep Server
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;name:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;web-54b75887bb-j76kz&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;

# Now test on the exposed port on the k8s hosts 
ubuntu@kates-control:~$ for server in kates-control kates-node-01 kates-node-02 ; \
&amp;gt; do \
&amp;gt; echo &amp;#34;*** $server ***&amp;#34; ; \
&amp;gt; for i in {1..5}; \
&amp;gt; do \
&amp;gt; curl -s $server:30721 | grep address ; \
&amp;gt; done ; \
&amp;gt; done
*** kates-control ***
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
*** kates-node-01 ***
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.1.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.1.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
*** kates-node-02 ***
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.1.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.3:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.1.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;span&amp;gt;Server&amp;amp;nbsp;address:&amp;lt;/span&amp;gt; &amp;lt;span&amp;gt;10.244.2.2:80&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Perfect! It is working &amp;#x1f604;
You can always test it from multiple web browser tabs pointing to &lt;strong&gt;http://&amp;lt;k8s-node&amp;gt;:30721/&lt;/strong&gt; and refreshing several times&lt;/p&gt;
&lt;hr&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kube-my-router-pt2/nginx.png" title="/posts/kube-my-router-pt2/nginx.png" data-thumbnail="/posts/kube-my-router-pt2/nginx.png" data-sub-html="&lt;h2&gt;LoadBalancer testing of nginxdemos images&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kube-my-router-pt2/nginx.png' alt="/posts/kube-my-router-pt2/nginx.png" height="895" width="400"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;LoadBalancer testing of nginxdemos images&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="references-and-influences"&gt;&lt;span&gt;References and influences&lt;/span&gt;
 &lt;a href="#references-and-influences" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Bootstrapping clusters with kubeadm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://computingforgeeks.com/deploy-kubernetes-cluster-on-ubuntu-with-kubeadm/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Install Kubernetes Cluster on Ubuntu 20.04 with kubeadm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kubesimplify.com/kubernetes-containerd-setup" target="_blank" rel="external nofollow noopener noreferrer"&gt;Kubernetes 1.23 + containerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://learnk8s.io/kubernetes-network-packets" target="_blank" rel="external nofollow noopener noreferrer"&gt;Tracing the path of network traffic in Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Exposing an External IP Address to Access an Application in a Cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="last-part---installing-and-testing-kne"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/"&gt;Last Part - Installing and testing KNE&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#last-part---installing-and-testing-kne" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/#outro"&gt;Outro&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;</description></item><item><title>Kube my router up! - Part One</title><link>https://net4fungr.github.io/posts/kube-my-router-pt1/</link><pubDate>Sat, 28 May 2022 10:36:24 +0300</pubDate><guid>https://net4fungr.github.io/posts/kube-my-router-pt1/</guid><category domain="https://net4fungr.github.io/categories/art-of-labbing/">Art of Labbing</category><description>&lt;img src="https://net4fungr.github.io/posts/kube-my-router-pt1/k8s.jpg" alt="featured image" referrerpolicy="no-referrer"&gt;&lt;h2 class="heading-element" id="intro"&gt;&lt;span&gt;Intro&lt;/span&gt;
 &lt;a href="#intro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;While I was ramping up my skills in k8s, I bumped into google&amp;rsquo;s Kubernetes based Network Emulation (&lt;a href="https://github.com/google/kne" target="_blank" rel="external nofollow noopener noreferrer"&gt;KNE&lt;/a&gt;), and since I&amp;rsquo;ve been a fool for network emulation software over the last twenty years, I knew I had to give it a go and see where it can get me. I first heard of KNE during episode #015 of this &lt;a href="https://anchor.fm/netauto-hangout" target="_blank" rel="external nofollow noopener noreferrer"&gt;podcast&lt;/a&gt; and it seemed very promising to me since it is a way to spin up network topologies from devices running in containers orchestrated by a kubernetes cluster that, guess what, can span more than one host.&lt;/p&gt;
&lt;p&gt;So, in these series of posts I will try to document my experiences setting it up and having fun with it &amp;#x1f604; since up to now there is too little documentation around it and also I think this &lt;a href="https://blog.itsalwaysthe.network/posts/kubernetes-based-network-emulation/" target="_blank" rel="external nofollow noopener noreferrer"&gt;blog post&lt;/a&gt; was the first to cover a basic orientation but still it covers running it inside a kind k8s node, i.e. in a container, where as my intent was to have the k8s spanning more than one machine since network devices are expensive in resources and my home lab is limited to 2x32GB EVE-NG servers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt1/"&gt;Part One - Setting up the k8s VMs in EVE-NG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt2/"&gt;Part Two - Deploying the k8s cluster with kubeadm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/"&gt;Last Part - Installing and testing KNE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="part-one---setting-up-the-vms"&gt;&lt;span&gt;Part One - Setting up the VMs&lt;/span&gt;
 &lt;a href="#part-one---setting-up-the-vms" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="the-intent"&gt;&lt;span&gt;The Intent&lt;/span&gt;
 &lt;a href="#the-intent" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;EVE-NG for hosting linux VMs&lt;/li&gt;
&lt;li&gt;Ubuntu 20.04 cloud image as base&lt;/li&gt;
&lt;li&gt;2xEVE-NG servers, 2.0.3-112 community edition - 3 VMs in total&lt;/li&gt;
&lt;li&gt;Deployment of 3xLinux VMs for our k8s cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Well the first step towards testing KNE is to set up a k8s cluster. I have two EVE-NG bare metal servers at home so I could spin up three VMs split in those two servers of 32GM RAM each. I&amp;rsquo;ve chosen Ubuntu 20.04 linux flavor and decided to start by deploying the VMs using the cloud-image files. The approach followed here is to download the cloud image in both EVE-NG servers and create a seed file in order to pass the user password during first boot. This will be used as the base ubuntu image for all VMs. Finally, once the base VM is ready, the topology can be created and all the VMs can be brought up and configured with the appropriate settings.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="prepare-ubuntu-base-image-in-eve-ng"&gt;&lt;span&gt;Prepare Ubuntu base image in EVE-NG&lt;/span&gt;
 &lt;a href="#prepare-ubuntu-base-image-in-eve-ng" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Download Ubuntu 20.04 cloud image and place it into a temporary directory on the first server, optionally, verifying the md5sum.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01# mkdir -p /opt/cloud &amp;amp;&amp;amp; cd !$
mkdir -p /opt/cloud &amp;amp;&amp;amp; cd /opt/cloud/

root@eve-01# wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img

&amp;lt; ...omitted... &amp;gt;

root@eve-01# ll
total 581388
drwxr-xr-x 2 root root 4096 May 29 21:19 ./
drwxr-xr-x 16 root root 4096 May 29 21:19 ../
-rw-r--r-- 1 root root 595329024 May 24 01:51 focal-server-cloudimg-amd64.img

root@eve-01# curl -ks https://cloud-images.ubuntu.com/focal/current/MD5SUMS | md5sum -c --ignore-missing
focal-server-cloudimg-amd64.img: OK&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Copy the image to the appropriate &lt;strong&gt;linux-&lt;/strong&gt; directory of EVE-NG in so that is categorised as a linux image. You can resize the image to your linking as well.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01# mkdir -p /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/

root@eve-01# cp focal-server-cloudimg-amd64.img !$hda.qcow2
cp focal-server-cloudimg-amd64.img /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/hda.qcow2

root@eve-01# cd /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/

root@eve-01# ll
total 581384
drwxr-xr-x 2 root root 4096 May 29 21:46 ./
drwxr-xr-x 12 root root 4096 May 29 21:45 ../
-rw-r--r-- 1 root root 595329024 May 29 21:46 hda.qcow2

root@eve-01# qemu-img info hda.qcow2
image: hda.qcow2
file format: qcow2
virtual size: 2.2G (2361393152 bytes)
disk size: 568M
cluster_size: 65536
Format specific information:
 compat: 0.10
 refcount bits: 16

root@eve-01# qemu-img resize hda.qcow2 50G
Image resized.
root@eve-01# qemu-img info hda.qcow2
image: hda.qcow2
file format: qcow2
virtual size: 50G (53687091200 bytes)
disk size: 568M
cluster_size: 65536
Format specific information:
 compat: 0.10
 refcount bits: 16&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="install-cloud-image-utilities-and-prepare-the-seed-file"&gt;&lt;span&gt;Install cloud-image utilities and prepare the seed file&lt;/span&gt;
 &lt;a href="#install-cloud-image-utilities-and-prepare-the-seed-file" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Install the required package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01# cd /opt/cloud/

root@eve-01# apt install cloud-image-utils
&amp;lt; ...omitted...&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Prepare the seed file and copy it to the base image location.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01# cat &amp;lt;&amp;lt;EOF &amp;gt; cloud-config
#cloud-config
system_info:
 default_user:
 name: &amp;#34;ubuntu&amp;#34;
 home: /home/ubuntu

password: &amp;#34;ubuntu123&amp;#34;
chpasswd: { expire: False }
hostname: &amp;#34;ubuntu&amp;#34;
ssh_pwauth: True
EOF

root@eve-01# cloud-localds seed cloud-config

root@eve-01# qemu-img info seed
image: seed
file format: raw
virtual size: 366K (374784 bytes)
disk size: 368K
root@eve-01# cp seed /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/cdrom.iso&lt;/code&gt;&lt;/pre&gt;&lt;div class="details admonition warning open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-exclamation-triangle" aria-hidden="true"&gt;&lt;/i&gt;Heads Up&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;Make sure you include the comment #cloud-config in the seed file&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="build-the-vm-topology-in-eve-ng"&gt;&lt;span&gt;Build the VM topology in EVE-NG&lt;/span&gt;
 &lt;a href="#build-the-vm-topology-in-eve-ng" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;Once both boot disk and seed cdrom files are in place, copy them onto the other node and run the &lt;strong&gt;fixpermissions&lt;/strong&gt; script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@eve-01# cd /opt/unetlab/addons/qemu/linux-focal-server-cloudimg/

root@eve-01# ll
total 581760
drwxr-xr-x 2 root root 4096 May 29 22:02 ./
drwxr-xr-x 12 root root 4096 May 29 21:45 ../
-rw-r--r-- 1 root root 374784 May 29 22:02 cdrom.iso
-rw-r--r-- 1 root root 595330048 May 29 21:47 hda.qcow2

root@eve-01# /opt/unetlab/wrappers/unl_wrapper -a fixpermissions

root@eve-01# ssh eve-02 &amp;#34;mkdir -p /opt/unetlab/addons/qemu/linux-focal-server-cloudimg&amp;#34;

root@eve-01# scp hda.qcow2 eve-02:/opt/unetlab/addons/qemu/linux-focal-server-cloudimg/

root@eve-01# scp cdrom.iso 192.168.1.22:/opt/unetlab/addons/qemu/linux-focal-server-cloudimg/

root@eve-01# ssh eve-02 &amp;#34;/opt/unetlab/wrappers/unl_wrapper -a fixpermissions&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now everything is ready to start creating the topology via the GUI. The following table lists the planning for my deployment:&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th style="text-align: center"&gt;EVE-NG node&lt;/th&gt;
 &lt;th style="text-align: center"&gt;Role&lt;/th&gt;
 &lt;th style="text-align: center"&gt;VM name&lt;/th&gt;
 &lt;th style="text-align: center"&gt;IP address&lt;/th&gt;
 &lt;th style="text-align: center"&gt;CPU&lt;/th&gt;
 &lt;th style="text-align: center"&gt;RAM&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;control-node&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-control&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.30&lt;/td&gt;
 &lt;td style="text-align: center"&gt;4&lt;/td&gt;
 &lt;td style="text-align: center"&gt;4096&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;worker&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-node-01&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.31&lt;/td&gt;
 &lt;td style="text-align: center"&gt;8&lt;/td&gt;
 &lt;td style="text-align: center"&gt;28672&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td style="text-align: center"&gt;eve-02&lt;/td&gt;
 &lt;td style="text-align: center"&gt;worker&lt;/td&gt;
 &lt;td style="text-align: center"&gt;kates-node-02&lt;/td&gt;
 &lt;td style="text-align: center"&gt;192.168.1.32&lt;/td&gt;
 &lt;td style="text-align: center"&gt;8&lt;/td&gt;
 &lt;td style="text-align: center"&gt;28672&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is how it looks like from GUI perspective:&lt;/p&gt;
&lt;p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kube-my-router-pt1/eve-01.png" title="/posts/kube-my-router-pt1/eve-01.png" data-thumbnail="/posts/kube-my-router-pt1/eve-01.png" data-sub-html="&lt;h2&gt;EVE-01 Topology&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kube-my-router-pt1/eve-01.png' alt="/posts/kube-my-router-pt1/eve-01.png" height="507" width="500"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;EVE-01 Topology&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kube-my-router-pt1/eve-02.png" title="/posts/kube-my-router-pt1/eve-02.png" data-thumbnail="/posts/kube-my-router-pt1/eve-02.png" data-sub-html="&lt;h2&gt;EVE-02 Topology&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kube-my-router-pt1/eve-02.png' alt="/posts/kube-my-router-pt1/eve-02.png" height="406" width="500"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;EVE-02 Topology&lt;/figcaption&gt;
 &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;You can also download the lab exports for &lt;a href="eve-01.zip"&gt;eve-01&lt;/a&gt; and &lt;a href="eve-02.zip"&gt;eve-02&lt;/a&gt;&lt;/p&gt;
&lt;div class="details admonition danger open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-bolt" aria-hidden="true"&gt;&lt;/i&gt;Heads Up&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;&lt;p&gt;Due to the fact that EVE-NG allocates MAC addresses sequentially from a pool which is allocated per-POD and if you are using the same LAB POD on both servers, &lt;strong&gt;kates-control&lt;/strong&gt; and &lt;strong&gt;kates-node-02&lt;/strong&gt; (i.e. the first VMs on each node, since only EVE-01 has two nodes) will end up having the same MAC address. In order to avoid this, we can either use &lt;em&gt;dummy&lt;/em&gt; VMs, i.e. powered off VMs or we can specify the value for the first MAC address on the &lt;strong&gt;kates-node-02&lt;/strong&gt; VM to cause EVE-NG to allocate a different MAC to the NIC, or simply we can use different EVE-NG PODs across the two servers to create the lab &amp;#x1f604;. I went for the latter and simpler method.&lt;/p&gt;
&lt;figure&gt;&lt;a class="lightgallery" target="_blank" href="https://net4fungr.github.io/posts/kube-my-router-pt1/kates2.png" title="/posts/kube-my-router-pt1/kates2.png" data-thumbnail="/posts/kube-my-router-pt1/kates2.png" data-sub-html="&lt;h2&gt;Change MAC address of VM on second EVE server&lt;/h2&gt;"&gt;&lt;img loading="lazy" src='https://net4fungr.github.io/posts/kube-my-router-pt1/kates2.png' alt="/posts/kube-my-router-pt1/kates2.png" height="950" width="400"&gt;&lt;/a&gt;&lt;figcaption class="image-caption"&gt;Change MAC address of VM on second EVE server&lt;/figcaption&gt;
 &lt;/figure&gt;
Have this also in mind for all your other labs and topologies. The MAC allocation is per lab POD.&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h3 class="heading-element" id="start-the-labs-and-perform-initial-configuration"&gt;&lt;span&gt;Start the labs and perform initial configuration&lt;/span&gt;
 &lt;a href="#start-the-labs-and-perform-initial-configuration" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;All VMs are ready to start. Once all nodes are booted you can access them from the VNC or HTML5 console and perform the initial configuration, which includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Disabling cloud-init&lt;/li&gt;
&lt;li&gt;Setting the hostname&lt;/li&gt;
&lt;li&gt;Configuring network addresses&lt;/li&gt;
&lt;li&gt;Updating and Upgrading&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But, let&amp;rsquo;s first check that all VMs are different and also the MAC addresses are not the same. The outputs shown are when using the same LAB POD in EVE-NG.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# On kates-control
ubuntu@ubuntu:~$ sudo dmidecode -s system-uuid &amp;amp;&amp;amp; cat /etc/machine-id &amp;amp;&amp;amp; ip link
df8f1876-080b-4bb0-b000-f63819c781f3
df8f1876080b4bb0b000f63819c781f3
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
 link/ether 00:50:00:00:01:00 brd ff:ff:ff:ff:ff:ff&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;# On kates-node-01
ubuntu@ubuntu:~$ sudo dmidecode -s system-uuid &amp;amp;&amp;amp; cat /etc/machine-id &amp;amp;&amp;amp; ip link
2b748bae-16c2-4abe-b65e-21a359658480
2b748bae16c24abeb65e21a359658480
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
 link/ether 00:50:00:00:02:00 brd ff:ff:ff:ff:ff:ff&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;# On kates-node-02
ubuntu@ubuntu:~$ sudo dmidecode -s system-uuid &amp;amp;&amp;amp; cat /etc/machine-id &amp;amp;&amp;amp; ip link
9ba9c500-5d18-40e8-98e4-3e027f84e971
9ba9c5005d1840e898e43e027f84e971
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: ens3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
 link/ether 00:60:00:00:01:00 brd ff:ff:ff:ff:ff:ff&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Okay, now it is time to perform the initial configuration by disabling first the cloud-init service and then moving on.&lt;/p&gt;
&lt;div class="details admonition note open"&gt;
 &lt;div class="details-summary admonition-title"&gt;&lt;i class="icon fa-solid fa-pencil-alt" aria-hidden="true"&gt;&lt;/i&gt;Note that&lt;i class="details-icon fa-solid fa-angle-right" aria-hidden="true"&gt;&lt;/i&gt;&lt;/div&gt;&lt;div class="details-content"&gt;
 &lt;div class="admonition-content"&gt;If the cloud-init service is not disabled, then we will not be able to change the hostname, so either we disable cloud init or modify the appropriate config file in order not to reset the hostname according to the seed file&lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;So from the VM console:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@ubuntu:~$ sudo touch /etc/cloud/cloud-init.disabled

ubuntu@ubuntu:~$ sudo hostnamectl set-hostname kates-control&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Adjust the netplan file according to your environment and apply the configuration. I prefer to remove the static MAC assignment to the NIC&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-bash" data-lang="bash"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;ubuntu@ubuntu:~$ sudo vi /etc/netplan/50-cloud-init.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;ubuntu@ubuntu:~$ cat /etc/netplan/50-cloud-init.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;network:
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ethernets:
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; ens3:
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; dhcp4: &lt;span class="nb"&gt;false&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; dhcp6: &lt;span class="nb"&gt;false&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; addresses: &lt;span class="o"&gt;[&lt;/span&gt;192.168.1.30/24&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; gateway4: 192.168.1.1
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; nameservers:
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; addresses: &lt;span class="o"&gt;[&lt;/span&gt;192.168.1.1, 8.8.8.8&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; version: &lt;span class="m"&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;ubuntu@ubuntu:~$ sudo netplan apply&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that the basic config has been done for all 3 nodes, we can reboot and login from a proper SSH terminal &amp;#x1f604; to verify network connectivity and by the next single command we perform any upgrade available and reboot the nodes if needed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ubuntu@kates-*:~$ sudo apt update \
 &amp;amp;&amp;amp; sudo apt -y full-upgrade \
 &amp;amp;&amp;amp; [ -f /var/run/reboot-required ] \
 &amp;amp;&amp;amp; sudo reboot -f&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 class="heading-element" id="references-and-influences"&gt;&lt;span&gt;References and influences&lt;/span&gt;
 &lt;a href="#references-and-influences" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h3&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.eve-ng.net/" target="_blank" rel="external nofollow noopener noreferrer"&gt;EVE-NG official site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloudinit.readthedocs.io/en/latest/topics/examples.html" target="_blank" rel="external nofollow noopener noreferrer"&gt;Cloud config examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.theurbanpenguin.com/using-cloud-images-in-kvm/" target="_blank" rel="external nofollow noopener noreferrer"&gt;Using Cloud Images in KVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 class="heading-element" id="part-two---deploying-the-k8s-cluster-with-kubeadm"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt2/"&gt;Part Two - Deploying the k8s cluster with kubeadm&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#part-two---deploying-the-k8s-cluster-with-kubeadm" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="last-part---installing-and-testing-kne"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/"&gt;Last Part - Installing and testing KNE&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#last-part---installing-and-testing-kne" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;
&lt;h2 class="heading-element" id="outro"&gt;&lt;span&gt;&lt;a href="https://net4fungr.github.io/posts/kube-my-router-pt3/#outro"&gt;Outro&lt;/a&gt;&lt;/span&gt;
 &lt;a href="#outro" class="heading-mark"&gt;
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"&gt;&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"&gt;&lt;/path&gt;&lt;/svg&gt;
 &lt;/a&gt;
&lt;/h2&gt;&lt;hr&gt;</description></item><item><title>Mutable vs. Immutable</title><link>https://net4fungr.github.io/posts/mutable-immutable/</link><pubDate>Sat, 30 Apr 2022 15:36:24 +0300</pubDate><guid>https://net4fungr.github.io/posts/mutable-immutable/</guid><category domain="https://net4fungr.github.io/categories/humour/">Humour</category><description>&lt;img src="https://net4fungr.github.io/posts/mutable-immutable/featured-image-preview.png" alt="featured image" referrerpolicy="no-referrer"&gt;&lt;p&gt;Have you noticed that in some parts of the world, in some cafeterias, especially when the weather is hot, after you take your seat, a waiter comes and serves you a glass of water? Furthermore, in these places, the waiter has a frequent task to have this glass filled several times during your stay. Hence, we could say that the waiter has a task every once in a while to take a jug of water and re-fill the glasses of those customers that are not full, even if they are half-empty or half-full.&lt;/p&gt;
&lt;p&gt;We can say that the glass of water, in that case, is a &lt;strong&gt;mutable&lt;/strong&gt; object, i.e. the glass is brought full at first and then its status can be changed by refilling it again. In addition, the task is &lt;strong&gt;idempotent&lt;/strong&gt; because every time it is executed, the result would be the same, i.e. all glasses are full - unless someone asks no to have it filled &amp;#x1f604;.&lt;/p&gt;
&lt;p&gt;This drinking water idempotency task can also be seen in expensive restaurants, where again there is a waiter (maybe call him idempotent) that takes care of re-filling your glass and in such places it happens much more often and usually it happens per-table rather than for all customers at the same time &amp;#x1f604;. Now, this glass idempotency thing does not only apply to drinking water, but also to the wine glasses if you have ordered a bottle of wine, that is.&lt;/p&gt;
&lt;p&gt;But, what happens if you have only ordered and consumed a single glass of wine? Your glass is empty and the waiter will come and ask you if you&amp;rsquo;d like another one. You say yes, and then it happens. The waiter will take the empty glass and will go and fetch a new glass of wine for you, i.e. replacing the previous one. At this moment, you realize that the wine glass is not a mutable object, but it is &lt;strong&gt;immutable&lt;/strong&gt; &amp;#x1f604;. It cannot be re-filled, it cannot be changed and it has to be replaced by another glass of wine that could be the same or some other type, or something completely different, but they all will refer to the &lt;em&gt;object&lt;/em&gt; you drink.&lt;/p&gt;
&lt;p&gt;You enjoyed your wine, it fulfilled its purpose, but if you want it to serve it&amp;rsquo;s purpose again, it has to be replaced with a new one or a new drink &amp;#x1f604;&lt;/p&gt;</description></item></channel></rss>